{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 0: REQUIRED PACKAGES\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import scipy\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "from dsgepy import DSGE\n",
    "from fredapi import Fred\n",
    "from sympy import symbols, Matrix\n",
    "import pickle\n",
    "from scipy import stats, signal, linalg\n",
    "from scipy.stats import chi2, invgamma, norm, beta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.mlemodel import MLEModel\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import scipy.linalg as slinalg\n",
    "from scipy.linalg import solve_discrete_lyapunov, kron\n",
    "from scipy.signal import savgol_filter\n",
    "from darts import TimeSeries\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import TimeSeriesSplit, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.optimize import minimize, minimize_scalar, differential_evolution\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Fetching data with realistic shock proxies...\n",
      "Using sample period: 1990-01-01 to 2025-06-30\n",
      "Raw data shape: (142, 6)\n",
      "\n",
      "üîß Creating proper output gap using HP filter...\n",
      "\n",
      "üîß Using Core CPI for inflation...\n",
      "\n",
      "üîß FIXED: TFP transformation with proper scaling...\n",
      "\n",
      "üîß NEW: Processing shock proxies...\n",
      "\n",
      "‚úÖ Data ingestion with shock proxies complete.\n",
      "\n",
      "üèóÔ∏è  Enhanced DSGE model - adding realistic shocks to working structure...\n",
      "üìù Enhanced state equations with realistic shocks...\n",
      "\n",
      "üéõÔ∏è  Enhanced calibration based on working original:\n",
      "--------------------------------------------------\n",
      "\n",
      "üîç Model Solution Check:\n",
      "   Existence & Uniqueness: [1, 1]\n",
      "\n",
      "üéØ Running DSGE estimation for acceptance rate and priors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metropolis-Hastings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2999/2999 [06:45<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptance rate: 15.5 percent\n",
      "‚úÖ Estimation completed successfully!\n",
      "\n",
      "============================================================\n",
      "DSGE ESTIMATION RESULTS\n",
      "============================================================\n",
      "\n",
      "üìä ACCEPTANCE RATE: Available in chain diagnostics\n",
      "\n",
      "üìã POSTERIOR ESTIMATES (DSGE-ESTIMATED COEFFICIENT PRIORS):\n",
      "------------------------------------------------------------\n",
      "        prior dist prior mean prior std  posterior mode  posterior mean  \\\n",
      "sigma       normal        1.3       0.2        1.339170        1.355637   \n",
      "theta         beta   0.837091       0.1        0.154051        0.208095   \n",
      "phi_pi      normal        1.5      0.35        2.812820        2.772075   \n",
      "phi_y        gamma       0.25       0.1        0.210660        0.320874   \n",
      "rho_a         beta        0.8      0.15        0.219071        0.201246   \n",
      "sigma_a   invgamma        0.5      0.25        0.255921        0.600514   \n",
      "rho_v         beta        0.5       0.2        0.454664        0.553591   \n",
      "sigma_v   invgamma       0.25      0.15        0.183908        0.176113   \n",
      "rho_d         beta        0.6      0.25        0.896433        0.745880   \n",
      "sigma_d   invgamma        0.4      0.25        0.262087        0.191316   \n",
      "rho_s         beta        0.5      0.25        0.364198        0.510335   \n",
      "sigma_s   invgamma       0.35       0.2        0.071957        0.102766   \n",
      "\n",
      "         posterior 5.0%  posterior 95.0%  \n",
      "sigma          1.215630         1.894244  \n",
      "theta          0.150979         0.296482  \n",
      "phi_pi         2.612470         2.872029  \n",
      "phi_y          0.205115         0.522576  \n",
      "rho_a          0.098528         0.685470  \n",
      "sigma_a        0.231355         1.295812  \n",
      "rho_v          0.410888         0.740305  \n",
      "sigma_v        0.150341         0.194167  \n",
      "rho_d          0.387391         0.910711  \n",
      "sigma_d        0.014161         0.302812  \n",
      "rho_s          0.352261         0.634765  \n",
      "sigma_s        0.007057         0.235742  \n",
      "\n",
      "============================================================\n",
      "ESTIMATION COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STREAMLINED DSGE MODEL - ACCEPTANCE RATE AND PRIORS OUTPUT ONLY\n",
    "# ============================================================================\n",
    "\n",
    "def hp_filter(x, lambda_hp=1600):\n",
    "    \"\"\"HP filter implementation for proper output gap extraction.\"\"\"\n",
    "    T = len(x)\n",
    "    if T < 4:\n",
    "        return x, np.zeros(T)\n",
    "        \n",
    "    D2 = np.zeros((T-2, T))\n",
    "    for i in range(T-2):\n",
    "        D2[i, i] = 1\n",
    "        D2[i, i+1] = -2\n",
    "        D2[i, i+2] = 1\n",
    "    \n",
    "    I = np.eye(T)\n",
    "    A = I + lambda_hp * D2.T @ D2\n",
    "    try:\n",
    "        trend = np.linalg.solve(A, x)\n",
    "        cycle = x - trend\n",
    "        return trend, cycle\n",
    "    except np.linalg.LinAlgError:\n",
    "        t = np.arange(T)\n",
    "        coeffs = np.polyfit(t, x, 1)\n",
    "        trend = np.polyval(coeffs, t)\n",
    "        cycle = x - trend\n",
    "        return trend, cycle\n",
    "\n",
    "# Monkey-patch for HDF compatibility\n",
    "class DummyStore:\n",
    "    def __init__(self, path):\n",
    "        self.path = path.replace('.h5', '.pkl')\n",
    "        self.data = {}\n",
    "    def __setitem__(self, key, value):\n",
    "        self.data[key] = value\n",
    "    def __getitem__(self, key):\n",
    "        return self.data[key]\n",
    "    def close(self):\n",
    "        with open(self.path, 'wb') as f:\n",
    "            pickle.dump(self.data, f)\n",
    "\n",
    "pd.HDFStore = DummyStore\n",
    "pd.read_hdf = lambda path, key=None, **kwargs: pickle.load(open(path.replace('.h5','.pkl'), 'rb'))[key]\n",
    "pd.DataFrame.to_hdf = lambda self, path, key=None, **kwargs: pickle.dump({key: self}, open(path.replace('.h5','.pkl'),'wb'))\n",
    "\n",
    "# ============================================================================\n",
    "# DATA PREPARATION\n",
    "# ============================================================================\n",
    "\n",
    "# FRED API setup\n",
    "afkey = 'ada1a8ba0569ed784226f2c26db44ab1'\n",
    "fred = Fred(api_key=afkey)\n",
    "\n",
    "start = '1990-01-01'\n",
    "end = pd.Timestamp.today().strftime('%Y-%m-%d')\n",
    "\n",
    "print(\"üîÑ Fetching data with realistic shock proxies...\")\n",
    "\n",
    "# ENHANCED series - adding shock proxies but keeping core structure\n",
    "series = {\n",
    "    # Original core series\n",
    "    'gdp': fred.get_series('GDPC1', start, end),\n",
    "    'cpi': fred.get_series('CPILFESL', start, end), # Using Core CPI\n",
    "    'fed': fred.get_series('FEDFUNDS', start, end),\n",
    "    'tfp': fred.get_series('A191RL1Q225SBEA', start, end),\n",
    "    \n",
    "    # NEW: Realistic shock proxies\n",
    "    'sentiment': fred.get_series('UMCSENT', start, end),     # Demand shock proxy\n",
    "    'oil_price': fred.get_series('DCOILWTICO', start, end),  # Supply shock proxy\n",
    "}\n",
    "\n",
    "# Combine and then drop NaNs. This ensures we get the most recent date\n",
    "# where ALL series have a value.\n",
    "raw_data = pd.DataFrame(series).resample('Q-DEC').last().dropna()  # Calendar quarters\n",
    "\n",
    "# Get the actual end date from the cleaned raw_data\n",
    "end = raw_data.index[-1].strftime('%Y-%m-%d')\n",
    "print(f\"Using sample period: {start} to {end}\")\n",
    "print(f\"Raw data shape: {raw_data.shape}\")\n",
    "\n",
    "# ===== TRANSFORMATIONS WITH SHOCK PROXIES =====\n",
    "\n",
    "# 1. PROPER OUTPUT GAP using HP filter (UNCHANGED)\n",
    "print(\"\\nüîß Creating proper output gap using HP filter...\")\n",
    "log_gdp = np.log(raw_data['gdp'])\n",
    "gdp_trend, output_gap = hp_filter(log_gdp.values, lambda_hp=1600)\n",
    "output_gap = pd.Series(output_gap, index=raw_data.index)\n",
    "\n",
    "# 2. INFLATION using Core CPI (UNCHANGED)\n",
    "print(\"\\nüîß Using Core CPI for inflation...\")\n",
    "inflation_quarterly = np.log(raw_data['cpi']).diff()\n",
    "\n",
    "# 3. INTEREST RATE TRANSFORMATION (UNCHANGED)\n",
    "fed_funds = raw_data['fed']\n",
    "fed_trend = fed_funds.rolling(window=20, min_periods=10).mean()\n",
    "fed_trend = fed_trend.bfill().ffill()\n",
    "interest_gap = fed_funds - fed_trend\n",
    "\n",
    "# 4. TFP (FIXED SCALING)\n",
    "print(\"\\nüîß FIXED: TFP transformation with proper scaling...\")\n",
    "tfp_demeaned = raw_data['tfp'] - raw_data['tfp'].mean()\n",
    "tfp_scaled = tfp_demeaned / raw_data['tfp'].std()  # Standardize to unit variance\n",
    "\n",
    "# 5. NEW: Transform shock proxies for later analysis\n",
    "print(\"\\nüîß NEW: Processing shock proxies...\")\n",
    "# Demand shock proxy from consumer sentiment\n",
    "sentiment_detrended = (raw_data['sentiment'] - raw_data['sentiment'].rolling(20).mean()) / raw_data['sentiment'].std()\n",
    "\n",
    "# Supply shock proxy from oil prices\n",
    "oil_changes = np.log(raw_data['oil_price']).diff()\n",
    "oil_shock_proxy = (oil_changes - oil_changes.mean()) / oil_changes.std()\n",
    "\n",
    "# Combine into dataset (SAME STRUCTURE AS ORIGINAL)\n",
    "data = pd.DataFrame({\n",
    "    'y':  output_gap,\n",
    "    'pi': inflation_quarterly,\n",
    "    'i':  interest_gap,\n",
    "    'a':  tfp_demeaned,\n",
    "    # NEW: Add shock proxies for later analysis\n",
    "    'demand_proxy': sentiment_detrended,\n",
    "    'supply_proxy': oil_shock_proxy\n",
    "})\n",
    "\n",
    "# Drop missing values *after* all transformations\n",
    "data = data.dropna()\n",
    "\n",
    "# Create the df_obs variable used by the forecasting functions (SAME AS ORIGINAL)\n",
    "df_obs = data[['y', 'pi', 'i']].copy()\n",
    "\n",
    "print(\"\\n‚úÖ Data ingestion with shock proxies complete.\")\n",
    "\n",
    "# ============================================================================\n",
    "# DSGE MODEL SPECIFICATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüèóÔ∏è  Enhanced DSGE model - adding realistic shocks to working structure...\")\n",
    "\n",
    "# --- Define symbols (ENHANCED but stable) ---\n",
    "# endogenous variables at t - ADDING demand and supply shocks\n",
    "y, pi, i, a, d, s, v, exp_y, exp_pi = symbols('y, pi, i, a, d, s, v, exp_y, exp_pi')\n",
    "endog = Matrix([y, pi, i, a, d, s, v, exp_y, exp_pi])\n",
    "\n",
    "# endogenous variables at t-1\n",
    "yl, pil, il, al, dl, sl, vl, exp_yl, exp_pil = symbols('yl, pil, il, al, dl, sl, vl, exp_yl, exp_pil')\n",
    "endogl = Matrix([yl, pil, il, al, dl, sl, vl, exp_yl, exp_pil])\n",
    "\n",
    "# exogenous shocks - ENHANCED\n",
    "eps_a, eps_d, eps_s, eps_v = symbols('eps_a, eps_d, eps_s, eps_v')\n",
    "exog = Matrix([eps_a, eps_d, eps_s, eps_v])\n",
    "\n",
    "# expectational shocks (UNCHANGED)\n",
    "eta_y, eta_pi = symbols('eta_y, eta_pi')\n",
    "expec = Matrix([eta_y, eta_pi])\n",
    "\n",
    "# parameters - ENHANCED\n",
    "sigma, varphi, alpha, beta, theta, phi_pi, phi_y, rho_a, sigma_a, rho_d, sigma_d, rho_s, sigma_s, rho_v, sigma_v = \\\n",
    "    symbols('sigma varphi alpha beta theta phi_pi phi_y rho_a sigma_a rho_d sigma_d rho_s sigma_s rho_v sigma_v')\n",
    "\n",
    "# summary parameters (UNCHANGED)\n",
    "psi_nya = (1 + varphi) / (sigma * (1 - alpha) + varphi + alpha)\n",
    "kappa = (1 - theta) * (1 - theta * beta) * (sigma * (1 - alpha) + varphi + alpha) / theta\n",
    "\n",
    "# ENHANCED STATE EQUATIONS - using sigma_pi for supply shock to match your original\n",
    "print(\"üìù Enhanced state equations with realistic shocks...\")\n",
    "\n",
    "# 1. IS Curve WITH demand shock\n",
    "eq1 = y - exp_y + (1/sigma)*(i - exp_pi) - psi_nya*(rho_a - 1)*a - d\n",
    "\n",
    "# 2. Phillips Curve WITH supply shock (using same structure as your original sigma_pi*eps_pi)\n",
    "eq2 = pi - beta*exp_pi - kappa*y - s\n",
    "\n",
    "# 3. Taylor Rule WITH monetary policy shock (UNCHANGED)\n",
    "eq3 = i - phi_pi*pi - phi_y*y - v\n",
    "\n",
    "# 4. Technology shock (UNCHANGED)\n",
    "eq4 = a - rho_a*al - sigma_a*eps_a\n",
    "\n",
    "# 5. NEW: Demand shock process\n",
    "eq5 = d - rho_d*dl - sigma_d*eps_d\n",
    "\n",
    "# 6. NEW: Supply shock process\n",
    "eq6 = s - rho_s*sl - sigma_s*eps_s\n",
    "\n",
    "# 7. Monetary policy shock (UNCHANGED)\n",
    "eq7 = v - rho_v*vl - sigma_v*eps_v\n",
    "\n",
    "# 8-9. Expectational equations (UNCHANGED)\n",
    "eq8 = y - exp_yl - eta_y\n",
    "eq9 = pi - exp_pil - eta_pi\n",
    "\n",
    "equations = Matrix([eq1, eq2, eq3, eq4, eq5, eq6, eq7, eq8, eq9])\n",
    "\n",
    "# observation equations (UNCHANGED - CRITICAL FOR STABILITY)\n",
    "obs01 = y\n",
    "obs02 = pi\n",
    "obs03 = i\n",
    "obs_equations = Matrix([obs01, obs02, obs03])\n",
    "obs_names = ['Output Gap', 'Inflation', 'Interest Rate']\n",
    "\n",
    "# ============================================================================\n",
    "# CONSERVATIVE CALIBRATION\n",
    "# ============================================================================\n",
    "\n",
    "def solve_calvo_parameter(target_kappa, sigma_val, varphi_val, alpha_val, beta_val):\n",
    "    slope_factor = (sigma_val * (1 - alpha_val) + varphi_val + alpha_val)\n",
    "    \n",
    "    A = beta_val * slope_factor\n",
    "    B = -(1 + beta_val) * slope_factor - target_kappa\n",
    "    C = slope_factor\n",
    "    \n",
    "    discriminant = B**2 - 4*A*C\n",
    "    if discriminant >= 0:\n",
    "        theta1 = (-B - np.sqrt(discriminant)) / (2*A)\n",
    "        theta2 = (-B + np.sqrt(discriminant)) / (2*A)\n",
    "        \n",
    "        valid_solutions = [theta for theta in [theta1, theta2] if 0 < theta < 1]\n",
    "        if valid_solutions:\n",
    "            return valid_solutions[0]\n",
    "    \n",
    "    return min(0.99, max(0.01, 1 - target_kappa/slope_factor))\n",
    "\n",
    "# CALIBRATION - keeping your working values, just adding new shock parameters\n",
    "print(\"\\nüéõÔ∏è  Enhanced calibration based on working original:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "target_kappa = 0.10  # Same as your working version\n",
    "theta_target = solve_calvo_parameter(target_kappa, 1.0, 2.0, 0.33, 0.99)\n",
    "\n",
    "calib = {\n",
    "    # ORIGINAL WORKING PARAMETERS (UNCHANGED)\n",
    "    sigma:   1.0,      \n",
    "    varphi:  2.0,      \n",
    "    alpha:   0.33,     \n",
    "    beta:    0.99,     \n",
    "    theta:   theta_target,  \n",
    "    phi_pi:  2.0,      \n",
    "    phi_y:   0.5,      \n",
    "    rho_a:   0.9,      \n",
    "    sigma_a: 0.8,      \n",
    "    rho_v:   0.3,      \n",
    "    sigma_v: 0.25,     \n",
    "    \n",
    "    # FIXED: Much smaller shock volatilities for numerical stability\n",
    "    rho_d:   0.5,      # Demand shock persistence\n",
    "    sigma_d: 0.02,     # Demand shock volatility (VERY SMALL)\n",
    "    rho_s:   0.4,      # Supply shock persistence  \n",
    "    sigma_s: 0.01      # Supply shock volatility (TINY)\n",
    "}\n",
    "\n",
    "# Instantiate DSGE model for solution check\n",
    "model = DSGE(\n",
    "    endog=endog,\n",
    "    endogl=endogl,\n",
    "    exog=exog,\n",
    "    expec=expec,\n",
    "    state_equations=equations,\n",
    "    obs_equations=obs_equations,\n",
    "    obs_names=obs_names,\n",
    "    calib_dict=calib\n",
    ")\n",
    "\n",
    "# Check existence and uniqueness\n",
    "print(f'\\nüîç Model Solution Check:')\n",
    "print(f'   Existence & Uniqueness: {model.eu}')\n",
    "\n",
    "if model.eu != [1, 1]:\n",
    "    print('   ‚ö†Ô∏è  Model solution issues - using more conservative parameters...')\n",
    "    # More conservative fallback parameters\n",
    "    calib[sigma_d] = 0.001\n",
    "    calib[sigma_s] = 0.001\n",
    "    calib[rho_d] = 0.1\n",
    "    calib[rho_s] = 0.1\n",
    "    \n",
    "    model = DSGE(\n",
    "        endog=endog, endogl=endogl, exog=exog, expec=expec,\n",
    "        state_equations=equations, obs_equations=obs_equations,\n",
    "        obs_names=obs_names, calib_dict=calib\n",
    "    )\n",
    "    print(f'   Conservative fallback solution check: {model.eu}')\n",
    "\n",
    "# ============================================================================\n",
    "# ENHANCED DSGE MODEL ESTIMATION\n",
    "# ============================================================================\n",
    "\n",
    "# Use actual observed data (not simulated) - SAME AS ORIGINAL\n",
    "df_obs = data[['y', 'pi', 'i']].copy()\n",
    "\n",
    "# ENHANCED PARAMETER SETUP - keeping your working structure\n",
    "calib_param = {\n",
    "    varphi: 2.0,       # SAME AS ORIGINAL\n",
    "    alpha: 0.33,       # SAME AS ORIGINAL  \n",
    "    beta: 0.99         # SAME AS ORIGINAL\n",
    "}\n",
    "\n",
    "# ENHANCED estimation parameters (adding new shock parameters)\n",
    "estimate_param = Matrix([\n",
    "    sigma,     # Risk aversion [ORIGINAL]\n",
    "    theta,     # Price stickiness [ORIGINAL]\n",
    "    phi_pi,    # Taylor rule: inflation [ORIGINAL]\n",
    "    phi_y,     # Taylor rule: output [ORIGINAL]\n",
    "    rho_a,     # TFP shock persistence [ORIGINAL]\n",
    "    sigma_a,   # TFP shock volatility [ORIGINAL]\n",
    "    rho_v,     # Monetary shock persistence [ORIGINAL]\n",
    "    sigma_v,   # Monetary shock volatility [ORIGINAL]\n",
    "    rho_d,     # NEW: Demand shock persistence\n",
    "    sigma_d,   # NEW: Demand shock volatility\n",
    "    rho_s,     # NEW: Supply shock persistence\n",
    "    sigma_s    # NEW: Supply shock volatility\n",
    "])\n",
    "\n",
    "# FIXED Priors for Bayesian estimation - the key fix!\n",
    "prior_dict = {\n",
    "    # ORIGINAL priors (keep working ones)\n",
    "    sigma:    {'dist': 'normal',   'mean':  1.30, 'std': 0.20, 'label': '$\\\\sigma$'},\n",
    "    theta:    {'dist': 'beta',     'mean':  theta_target, 'std': 0.10, 'label': '$\\\\theta$'},\n",
    "    phi_pi:   {'dist': 'normal',   'mean':  1.50, 'std': 0.35, 'label': '$\\\\phi_{\\\\pi}$'},\n",
    "    phi_y:    {'dist': 'gamma',    'mean':  0.25, 'std': 0.10, 'label': '$\\\\phi_{y}$'},\n",
    "    rho_a:    {'dist': 'beta',     'mean':  0.80, 'std': 0.15, 'label': '$\\\\rho_a$'},\n",
    "    sigma_a:  {'dist': 'invgamma', 'mean':  0.50, 'std': 0.25, 'label': '$\\\\sigma_a$'},\n",
    "    rho_v:    {'dist': 'beta',     'mean':  0.50, 'std': 0.20, 'label': '$\\\\rho_v$'},\n",
    "    sigma_v:  {'dist': 'invgamma', 'mean':  0.25, 'std': 0.15, 'label': '$\\\\sigma_v$'},\n",
    "    \n",
    "    # FIXED: Much more reasonable priors for new shock parameters\n",
    "    rho_d:    {'dist': 'beta',     'mean':  0.60, 'std': 0.25, 'label': '$\\\\rho_d$'},\n",
    "    sigma_d:  {'dist': 'invgamma', 'mean':  0.40, 'std': 0.25, 'label': '$\\\\sigma_d$'},\n",
    "    rho_s:    {'dist': 'beta',     'mean':  0.50, 'std': 0.25, 'label': '$\\\\rho_s$'}, \n",
    "    sigma_s:  {'dist': 'invgamma', 'mean':  0.35, 'std': 0.20, 'label': '$\\\\sigma_s$'}\n",
    "}\n",
    "\n",
    "# Instantiate the DSGE model (SAME API as original)\n",
    "dsge = DSGE(\n",
    "    endog=endog,\n",
    "    endogl=endogl,\n",
    "    exog=exog,\n",
    "    expec=expec,\n",
    "    state_equations=equations,\n",
    "    estimate_params=estimate_param,\n",
    "    calib_dict=calib_param,\n",
    "    obs_equations=obs_equations,\n",
    "    prior_dict=prior_dict,\n",
    "    obs_data=df_obs,\n",
    "    obs_names=['y', 'pi', 'i'],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nüéØ Running DSGE estimation for acceptance rate and priors...\")\n",
    "\n",
    "# Run estimation (SAME as original)\n",
    "dsge.estimate(file_path='enhanced_example_snkm.pkl', nsim=3000, ck=0.3)\n",
    "\n",
    "print(\"‚úÖ Estimation completed successfully!\")\n",
    "\n",
    "# Extract results\n",
    "dsge.eval_chains(burnin=0.1, show_charts=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DSGE ESTIMATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìä ACCEPTANCE RATE: Available in chain diagnostics\")\n",
    "\n",
    "print(f\"\\nüìã POSTERIOR ESTIMATES (DSGE-ESTIMATED COEFFICIENT PRIORS):\")\n",
    "print(\"-\" * 60)\n",
    "print(dsge.posterior_table)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ESTIMATION COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sigma': {'mean': 1.3556370879752022, 'std': 0.20626582964649523},\n",
       " 'theta': {'mean': 0.20809459869685257, 'std': 0.04422556482937241},\n",
       " 'phi_pi': {'mean': 2.772075466811264, 'std': 0.07889314492838308},\n",
       " 'phi_y': {'mean': 0.32087362248079543, 'std': 0.09649278056218742},\n",
       " 'rho_a': {'mean': 0.2012461230275492, 'std': 0.17840187388143014},\n",
       " 'sigma_a': {'mean': 0.600514079811355, 'std': 0.32354307673570587},\n",
       " 'rho_v': {'mean': 0.5535913127783123, 'std': 0.10012655055969089},\n",
       " 'sigma_v': {'mean': 0.17611315612483597, 'std': 0.01332117734018096},\n",
       " 'rho_d': {'mean': 0.7458799317478219, 'std': 0.15906394417821443},\n",
       " 'sigma_d': {'mean': 0.19131571253191917, 'std': 0.087735946611838},\n",
       " 'rho_s': {'mean': 0.510334723621336, 'std': 0.0858674143111458},\n",
       " 'sigma_s': {'mean': 0.10276576757863215, 'std': 0.06950924911500318}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add to END of Document 1 (after dsge.eval_chains())\n",
    "def extract_posteriors_for_dfm(dsge_model):\n",
    "    \"\"\"Extract DSGE posterior estimates for DFM\"\"\"\n",
    "    posterior_table = dsge_model.posterior_table\n",
    "    dsge_posteriors = {}\n",
    "    \n",
    "    for param_name in posterior_table.index:\n",
    "        row = posterior_table.loc[param_name]\n",
    "        posterior_mean = row['posterior mean']\n",
    "        ci_5 = row['posterior 5.0%'] \n",
    "        ci_95 = row['posterior 95.0%']\n",
    "        posterior_std = (ci_95 - ci_5) / 3.29  # Approx std from 90% CI\n",
    "        \n",
    "        dsge_posteriors[param_name] = {\n",
    "            'mean': posterior_mean,\n",
    "            'std': posterior_std\n",
    "        }\n",
    "    \n",
    "    return dsge_posteriors\n",
    "\n",
    "dsge_posteriors = extract_posteriors_for_dfm(dsge)\n",
    "\n",
    "dsge_posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSGE-INFORMED VAR-DFM ANALYSIS\n",
      "================================================================================\n",
      "Using DSGE-estimated priors for VAR coefficient restrictions\n",
      "PREPARING ECONOMETRIC DATA FOR DSGE-INFORMED DFM\n",
      "============================================================\n",
      "Fetching economic data from FRED...\n",
      "\n",
      "Fetching Demand_Block:\n",
      "  GDPC1 ‚úì (102 obs)\n",
      "  PAYEMS ‚úì (308 obs)\n",
      "  INDPRO ‚úì (308 obs)\n",
      "  ICSA ‚úì (1341 obs)\n",
      "\n",
      "Fetching Supply_Block:\n",
      "  CPIAUCSL ‚úì (308 obs)\n",
      "  PCEPI ‚úì (307 obs)\n",
      "  AHETPI ‚úì (308 obs)\n",
      "  DCOILWTICO ‚úì (6441 obs)\n",
      "\n",
      "Fetching Monetary_Block:\n",
      "  FEDFUNDS ‚úì (308 obs)\n",
      "  DGS10 ‚úì (6429 obs)\n",
      "  M2SL ‚úì (307 obs)\n",
      "  AAA ‚úì (308 obs)\n",
      "\n",
      "Successfully fetched 12 series\n",
      "Common date range: 2000-01 to 2025-04\n",
      "Quarterly observations: 101\n",
      "Final dataset shape: (97, 12)\n",
      "Date range: 2001-Qq to 2025-Qq\n",
      "Demand_Block: ['GDPC1', 'PAYEMS', 'INDPRO', 'ICSA']\n",
      "Supply_Block: ['CPIAUCSL', 'PCEPI', 'AHETPI', 'DCOILWTICO']\n",
      "Monetary_Block: ['FEDFUNDS', 'DGS10', 'M2SL', 'AAA']\n",
      "\n",
      "INITIALIZING DSGE-INFORMED DFM\n",
      "============================================================\n",
      "DSGE priors available: ['sigma', 'theta', 'phi_pi', 'phi_y', 'rho_a', 'sigma_a', 'rho_v', 'sigma_v', 'rho_d', 'sigma_d', 'rho_s', 'sigma_s']\n",
      "\n",
      "DSGE-Informed DFM Setup:\n",
      "  Variables: 12\n",
      "  Observations: 97\n",
      "  Factors: 3\n",
      "  DSGE priors: 12 parameters\n",
      "DSGE-INFORMED DYNAMIC FACTOR MODEL - COMPLETE ESTIMATION\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "STEP 1: FACTOR EXTRACTION VIA PCA\n",
      "============================================================\n",
      "PCA explained variance: [0.30592539 0.21848175 0.18527255]\n",
      "Cumulative explained variance: [0.30592539 0.52440713 0.70967969]\n",
      "\n",
      "============================================================\n",
      "STEP 2: FACTOR LOADING ESTIMATION\n",
      "============================================================\n",
      "\n",
      "Factor Loading Results:\n",
      "======================================================================\n",
      "Variable     R¬≤     Demand     Supply     Monetary  \n",
      "----------------------------------------------------------------------\n",
      "GDPC1        0.736  0.220      -0.370     -0.299    \n",
      "PAYEMS       0.863  0.304      -0.381     -0.253    \n",
      "INDPRO       0.592  0.193      -0.335     -0.269    \n",
      "ICSA         0.581  0.373      -0.065     -0.162    \n",
      "CPIAUCSL     0.888  0.380      -0.053     0.397     \n",
      "PCEPI        0.903  0.389      -0.069     0.389     \n",
      "AHETPI       0.701  0.194      0.043      0.501     \n",
      "DCOILWTICO   0.291  0.183      -0.212     0.150     \n",
      "FEDFUNDS     0.708  0.336      0.334      0.002     \n",
      "DGS10        0.878  0.289      0.429      -0.200    \n",
      "M2SL         0.581  -0.312     -0.186     0.244     \n",
      "AAA          0.794  0.148      0.465      -0.257    \n",
      "\n",
      "Average R¬≤: 0.710\n",
      "\n",
      "============================================================\n",
      "STEP 3: DSGE-INFORMED FACTOR VAR ESTIMATION\n",
      "============================================================\n",
      "Optimal lag selected: 1 (using BIC)\n",
      "\n",
      "üìã Constructing DSGE-informed priors for VAR(1)...\n",
      "   Prior mean range: [-0.074, 0.554]\n",
      "   Prior variance range: [0.050, 1.000]\n",
      "üéØ Using DSGE-informed Bayesian estimation\n",
      "Bayesian VAR(1) estimation completed:\n",
      "  Effective sample: 96\n",
      "  Log-likelihood: -328.56\n",
      "  DSGE prior influence: Moderate\n",
      "\n",
      "Bayesian VAR Stability Check:\n",
      "  Maximum eigenvalue modulus: 0.8963\n",
      "  Model is stable ‚úì\n",
      "\n",
      "============================================================\n",
      "VAR FORECASTING WITH COMPANION FORM\n",
      "============================================================\n",
      "Forecasting 3 factors for 8 periods using Bayesian VAR(1)\n",
      "\n",
      "Forecast Summary (1-quarter ahead):\n",
      "--------------------------------------------------\n",
      "Demand_Factor:   1.233 ¬± 1.161\n",
      "Supply_Factor:   1.178 ¬± 0.985\n",
      "Monetary_Factor:  -0.232 ¬± 0.978\n",
      "\n",
      "============================================================\n",
      "VARIABLE FORECASTING VIA FACTOR MODEL\n",
      "============================================================\n",
      "Generated forecasts for 12 variables\n",
      "\n",
      "====================================================================================================\n",
      "5-FOLD CROSS-VALIDATION WITH COMPREHENSIVE METRICS\n",
      "====================================================================================================\n",
      "Total observations: 97\n",
      "Fold size: 19\n",
      "Forecast horizon: 4\n",
      "\n",
      "Processing Fold 1/5...\n",
      "  Train: 0 to 19 (20 obs)\n",
      "  Test: 20 to 23 (4 obs)\n",
      "\n",
      "DSGE-Informed DFM Setup:\n",
      "  Variables: 12\n",
      "  Observations: 20\n",
      "  Factors: 3\n",
      "  DSGE priors: 12 parameters\n",
      "\n",
      "============================================================\n",
      "STEP 1: FACTOR EXTRACTION VIA PCA\n",
      "============================================================\n",
      "PCA explained variance: [0.50549909 0.24050851 0.09553986]\n",
      "Cumulative explained variance: [0.50549909 0.7460076  0.84154746]\n",
      "\n",
      "============================================================\n",
      "STEP 2: FACTOR LOADING ESTIMATION\n",
      "============================================================\n",
      "\n",
      "Factor Loading Results:\n",
      "======================================================================\n",
      "Variable     R¬≤     Demand     Supply     Monetary  \n",
      "----------------------------------------------------------------------\n",
      "GDPC1        0.555  0.215      -0.292     0.157     \n",
      "PAYEMS       0.904  0.382      0.031      0.126     \n",
      "INDPRO       0.773  0.171      -0.282     0.565     \n",
      "ICSA         0.919  0.349      0.188      0.265     \n",
      "CPIAUCSL     0.830  0.207      0.433      -0.159    \n",
      "PCEPI        0.879  0.313      0.284      -0.211    \n",
      "AHETPI       0.836  -0.255     0.390      -0.026    \n",
      "DCOILWTICO   0.921  0.375      0.150      0.056     \n",
      "FEDFUNDS     0.889  -0.024     0.538      0.206     \n",
      "DGS10        0.825  -0.197     0.218      0.627     \n",
      "M2SL         0.883  -0.381     -0.009     -0.040    \n",
      "AAA          0.885  -0.355     0.138      0.242     \n",
      "\n",
      "Average R¬≤: 0.842\n",
      "\n",
      "============================================================\n",
      "STEP 3: DSGE-INFORMED FACTOR VAR ESTIMATION\n",
      "============================================================\n",
      "Optimal lag selected: 1 (using BIC)\n",
      "\n",
      "üìã Constructing DSGE-informed priors for VAR(1)...\n",
      "   Prior mean range: [-0.074, 0.554]\n",
      "   Prior variance range: [0.050, 1.000]\n",
      "üéØ Using DSGE-informed Bayesian estimation\n",
      "Bayesian VAR(1) estimation completed:\n",
      "  Effective sample: 19\n",
      "  Log-likelihood: -58.99\n",
      "  DSGE prior influence: Moderate\n",
      "\n",
      "Bayesian VAR Stability Check:\n",
      "  Maximum eigenvalue modulus: 0.7983\n",
      "  Model is stable ‚úì\n",
      "\n",
      "============================================================\n",
      "VAR FORECASTING WITH COMPANION FORM\n",
      "============================================================\n",
      "Forecasting 3 factors for 4 periods using Bayesian VAR(1)\n",
      "\n",
      "Forecast Summary (1-quarter ahead):\n",
      "--------------------------------------------------\n",
      "Demand_Factor:   2.619 ¬± 0.487\n",
      "Supply_Factor:   1.659 ¬± 0.836\n",
      "Monetary_Factor:   0.841 ¬± 1.042\n",
      "\n",
      "============================================================\n",
      "VARIABLE FORECASTING VIA FACTOR MODEL\n",
      "============================================================\n",
      "Generated forecasts for 12 variables\n",
      "  Fold 1 completed successfully\n",
      "\n",
      "Processing Fold 2/5...\n",
      "  Train: 0 to 38 (39 obs)\n",
      "  Test: 39 to 42 (4 obs)\n",
      "\n",
      "DSGE-Informed DFM Setup:\n",
      "  Variables: 12\n",
      "  Observations: 39\n",
      "  Factors: 3\n",
      "  DSGE priors: 12 parameters\n",
      "\n",
      "============================================================\n",
      "STEP 1: FACTOR EXTRACTION VIA PCA\n",
      "============================================================\n",
      "PCA explained variance: [0.39695425 0.24998253 0.17266303]\n",
      "Cumulative explained variance: [0.39695425 0.64693678 0.8195998 ]\n",
      "\n",
      "============================================================\n",
      "STEP 2: FACTOR LOADING ESTIMATION\n",
      "============================================================\n",
      "\n",
      "Factor Loading Results:\n",
      "======================================================================\n",
      "Variable     R¬≤     Demand     Supply     Monetary  \n",
      "----------------------------------------------------------------------\n",
      "GDPC1        0.794  0.290      -0.251     -0.315    \n",
      "PAYEMS       0.916  0.410      -0.158     -0.140    \n",
      "INDPRO       0.682  0.194      -0.291     -0.347    \n",
      "ICSA         0.878  0.420      0.113      0.011     \n",
      "CPIAUCSL     0.766  0.359      0.135      0.217     \n",
      "PCEPI        0.826  0.390      0.043      0.217     \n",
      "AHETPI       0.794  0.037      0.441      0.313     \n",
      "DCOILWTICO   0.790  0.096      -0.185     0.557     \n",
      "FEDFUNDS     0.815  0.309      0.335      0.103     \n",
      "DGS10        0.872  0.282      0.315      -0.307    \n",
      "M2SL         0.861  -0.260     0.409      -0.136    \n",
      "AAA          0.842  -0.008     0.432      -0.368    \n",
      "\n",
      "Average R¬≤: 0.820\n",
      "\n",
      "============================================================\n",
      "STEP 3: DSGE-INFORMED FACTOR VAR ESTIMATION\n",
      "============================================================\n",
      "Optimal lag selected: 1 (using BIC)\n",
      "\n",
      "üìã Constructing DSGE-informed priors for VAR(1)...\n",
      "   Prior mean range: [-0.074, 0.554]\n",
      "   Prior variance range: [0.050, 1.000]\n",
      "üéØ Using DSGE-informed Bayesian estimation\n",
      "Bayesian VAR(1) estimation completed:\n",
      "  Effective sample: 38\n",
      "  Log-likelihood: -127.60\n",
      "  DSGE prior influence: Moderate\n",
      "\n",
      "Bayesian VAR Stability Check:\n",
      "  Maximum eigenvalue modulus: 0.8702\n",
      "  Model is stable ‚úì\n",
      "\n",
      "============================================================\n",
      "VAR FORECASTING WITH COMPANION FORM\n",
      "============================================================\n",
      "Forecasting 3 factors for 4 periods using Bayesian VAR(1)\n",
      "\n",
      "Forecast Summary (1-quarter ahead):\n",
      "--------------------------------------------------\n",
      "Demand_Factor:  -0.487 ¬± 1.056\n",
      "Supply_Factor:  -3.126 ¬± 0.608\n",
      "Monetary_Factor:   0.865 ¬± 0.647\n",
      "\n",
      "============================================================\n",
      "VARIABLE FORECASTING VIA FACTOR MODEL\n",
      "============================================================\n",
      "Generated forecasts for 12 variables\n",
      "  Fold 2 completed successfully\n",
      "\n",
      "Processing Fold 3/5...\n",
      "  Train: 0 to 57 (58 obs)\n",
      "  Test: 58 to 61 (4 obs)\n",
      "\n",
      "DSGE-Informed DFM Setup:\n",
      "  Variables: 12\n",
      "  Observations: 58\n",
      "  Factors: 3\n",
      "  DSGE priors: 12 parameters\n",
      "\n",
      "============================================================\n",
      "STEP 1: FACTOR EXTRACTION VIA PCA\n",
      "============================================================\n",
      "PCA explained variance: [0.32347913 0.29919616 0.13021873]\n",
      "Cumulative explained variance: [0.32347913 0.6226753  0.75289403]\n",
      "\n",
      "============================================================\n",
      "STEP 2: FACTOR LOADING ESTIMATION\n",
      "============================================================\n",
      "\n",
      "Factor Loading Results:\n",
      "======================================================================\n",
      "Variable     R¬≤     Demand     Supply     Monetary  \n",
      "----------------------------------------------------------------------\n",
      "GDPC1        0.719  -0.041     0.372      -0.372    \n",
      "PAYEMS       0.881  -0.099     0.482      -0.081    \n",
      "INDPRO       0.662  -0.097     0.295      -0.448    \n",
      "ICSA         0.575  0.066      0.393      0.048     \n",
      "CPIAUCSL     0.830  0.293      0.284      0.366     \n",
      "PCEPI        0.853  0.269      0.337      0.322     \n",
      "AHETPI       0.791  0.419      -0.144     0.150     \n",
      "DCOILWTICO   0.708  -0.221     0.195      0.494     \n",
      "FEDFUNDS     0.805  0.443      0.109      0.033     \n",
      "DGS10        0.935  0.461      0.023      -0.264    \n",
      "M2SL         0.365  -0.026     -0.308     0.116     \n",
      "AAA          0.910  0.428      -0.167     -0.251    \n",
      "\n",
      "Average R¬≤: 0.753\n",
      "\n",
      "============================================================\n",
      "STEP 3: DSGE-INFORMED FACTOR VAR ESTIMATION\n",
      "============================================================\n",
      "Optimal lag selected: 1 (using BIC)\n",
      "\n",
      "üìã Constructing DSGE-informed priors for VAR(1)...\n",
      "   Prior mean range: [-0.074, 0.554]\n",
      "   Prior variance range: [0.050, 1.000]\n",
      "üéØ Using DSGE-informed Bayesian estimation\n",
      "Bayesian VAR(1) estimation completed:\n",
      "  Effective sample: 57\n",
      "  Log-likelihood: -171.81\n",
      "  DSGE prior influence: Moderate\n",
      "\n",
      "Bayesian VAR Stability Check:\n",
      "  Maximum eigenvalue modulus: 0.9379\n",
      "  Model is stable ‚úì\n",
      "\n",
      "============================================================\n",
      "VAR FORECASTING WITH COMPANION FORM\n",
      "============================================================\n",
      "Forecasting 3 factors for 4 periods using Bayesian VAR(1)\n",
      "\n",
      "Forecast Summary (1-quarter ahead):\n",
      "--------------------------------------------------\n",
      "Demand_Factor:  -2.314 ¬± 0.630\n",
      "Supply_Factor:   0.753 ¬± 0.872\n",
      "Monetary_Factor:  -0.194 ¬± 0.753\n",
      "\n",
      "============================================================\n",
      "VARIABLE FORECASTING VIA FACTOR MODEL\n",
      "============================================================\n",
      "Generated forecasts for 12 variables\n",
      "  Fold 3 completed successfully\n",
      "\n",
      "Processing Fold 4/5...\n",
      "  Train: 0 to 76 (77 obs)\n",
      "  Test: 77 to 80 (4 obs)\n",
      "\n",
      "DSGE-Informed DFM Setup:\n",
      "  Variables: 12\n",
      "  Observations: 77\n",
      "  Factors: 3\n",
      "  DSGE priors: 12 parameters\n",
      "\n",
      "============================================================\n",
      "STEP 1: FACTOR EXTRACTION VIA PCA\n",
      "============================================================\n",
      "PCA explained variance: [0.30066193 0.28838524 0.11921408]\n",
      "Cumulative explained variance: [0.30066193 0.58904717 0.70826125]\n",
      "\n",
      "============================================================\n",
      "STEP 2: FACTOR LOADING ESTIMATION\n",
      "============================================================\n",
      "\n",
      "Factor Loading Results:\n",
      "======================================================================\n",
      "Variable     R¬≤     Demand     Supply     Monetary  \n",
      "----------------------------------------------------------------------\n",
      "GDPC1        0.740  -0.110     0.391      0.341     \n",
      "PAYEMS       0.817  -0.208     0.437      0.013     \n",
      "INDPRO       0.720  -0.119     0.319      0.470     \n",
      "ICSA         0.520  -0.140     0.338      -0.193    \n",
      "CPIAUCSL     0.791  0.295      0.313      -0.312    \n",
      "PCEPI        0.802  0.276      0.354      -0.256    \n",
      "AHETPI       0.678  0.398      -0.062     -0.255    \n",
      "DCOILWTICO   0.386  -0.148     0.196      -0.349    \n",
      "FEDFUNDS     0.757  0.417      0.184      -0.090    \n",
      "DGS10        0.942  0.448      0.110      0.349     \n",
      "M2SL         0.442  0.045      -0.353     -0.053    \n",
      "AAA          0.904  0.436      -0.063     0.379     \n",
      "\n",
      "Average R¬≤: 0.708\n",
      "\n",
      "============================================================\n",
      "STEP 3: DSGE-INFORMED FACTOR VAR ESTIMATION\n",
      "============================================================\n",
      "Optimal lag selected: 1 (using BIC)\n",
      "\n",
      "üìã Constructing DSGE-informed priors for VAR(1)...\n",
      "   Prior mean range: [-0.074, 0.554]\n",
      "   Prior variance range: [0.050, 1.000]\n",
      "üéØ Using DSGE-informed Bayesian estimation\n",
      "Bayesian VAR(1) estimation completed:\n",
      "  Effective sample: 76\n",
      "  Log-likelihood: -244.89\n",
      "  DSGE prior influence: Moderate\n",
      "\n",
      "Bayesian VAR Stability Check:\n",
      "  Maximum eigenvalue modulus: 0.9362\n",
      "  Model is stable ‚úì\n",
      "\n",
      "============================================================\n",
      "VAR FORECASTING WITH COMPANION FORM\n",
      "============================================================\n",
      "Forecasting 3 factors for 4 periods using Bayesian VAR(1)\n",
      "\n",
      "Forecast Summary (1-quarter ahead):\n",
      "--------------------------------------------------\n",
      "Demand_Factor:  -0.839 ¬± 0.617\n",
      "Supply_Factor:  -5.614 ¬± 1.107\n",
      "Monetary_Factor:  -0.864 ¬± 0.666\n",
      "\n",
      "============================================================\n",
      "VARIABLE FORECASTING VIA FACTOR MODEL\n",
      "============================================================\n",
      "Generated forecasts for 12 variables\n",
      "  Fold 4 completed successfully\n",
      "\n",
      "Processing Fold 5/5...\n",
      "  Train: 0 to 95 (96 obs)\n",
      "  Test: 96 to 96 (1 obs)\n",
      "\n",
      "DSGE-Informed DFM Setup:\n",
      "  Variables: 12\n",
      "  Observations: 96\n",
      "  Factors: 3\n",
      "  DSGE priors: 12 parameters\n",
      "\n",
      "============================================================\n",
      "STEP 1: FACTOR EXTRACTION VIA PCA\n",
      "============================================================\n",
      "PCA explained variance: [0.30557063 0.218366   0.18564966]\n",
      "Cumulative explained variance: [0.30557063 0.52393663 0.70958629]\n",
      "\n",
      "============================================================\n",
      "STEP 2: FACTOR LOADING ESTIMATION\n",
      "============================================================\n",
      "\n",
      "Factor Loading Results:\n",
      "======================================================================\n",
      "Variable     R¬≤     Demand     Supply     Monetary  \n",
      "----------------------------------------------------------------------\n",
      "GDPC1        0.735  0.226      -0.365     -0.299    \n",
      "PAYEMS       0.863  0.307      -0.378     -0.252    \n",
      "INDPRO       0.591  0.194      -0.334     -0.268    \n",
      "ICSA         0.580  0.373      -0.067     -0.162    \n",
      "CPIAUCSL     0.891  0.382      -0.047     0.396     \n",
      "PCEPI        0.903  0.390      -0.063     0.388     \n",
      "AHETPI       0.702  0.193      0.045      0.502     \n",
      "DCOILWTICO   0.292  0.182      -0.214     0.151     \n",
      "FEDFUNDS     0.705  0.333      0.337      0.003     \n",
      "DGS10        0.879  0.285      0.433      -0.201    \n",
      "M2SL         0.578  -0.310     -0.187     0.244     \n",
      "AAA          0.796  0.144      0.467      -0.258    \n",
      "\n",
      "Average R¬≤: 0.710\n",
      "\n",
      "============================================================\n",
      "STEP 3: DSGE-INFORMED FACTOR VAR ESTIMATION\n",
      "============================================================\n",
      "Optimal lag selected: 1 (using BIC)\n",
      "\n",
      "üìã Constructing DSGE-informed priors for VAR(1)...\n",
      "   Prior mean range: [-0.074, 0.554]\n",
      "   Prior variance range: [0.050, 1.000]\n",
      "üéØ Using DSGE-informed Bayesian estimation\n",
      "Bayesian VAR(1) estimation completed:\n",
      "  Effective sample: 95\n",
      "  Log-likelihood: -325.72\n",
      "  DSGE prior influence: Moderate\n",
      "\n",
      "Bayesian VAR Stability Check:\n",
      "  Maximum eigenvalue modulus: 0.8962\n",
      "  Model is stable ‚úì\n",
      "\n",
      "============================================================\n",
      "VAR FORECASTING WITH COMPANION FORM\n",
      "============================================================\n",
      "Forecasting 3 factors for 1 periods using Bayesian VAR(1)\n",
      "\n",
      "Forecast Summary (1-quarter ahead):\n",
      "--------------------------------------------------\n",
      "Demand_Factor:   1.561 ¬± 1.172\n",
      "Supply_Factor:   1.231 ¬± 0.977\n",
      "Monetary_Factor:  -0.133 ¬± 0.978\n",
      "\n",
      "============================================================\n",
      "VARIABLE FORECASTING VIA FACTOR MODEL\n",
      "============================================================\n",
      "Generated forecasts for 12 variables\n",
      "  Fold 5 completed successfully\n",
      "\n",
      "============================================================================================================================================\n",
      "DSGE-INFORMED DFM CROSS-VALIDATION SUMMARY\n",
      "============================================================================================================================================\n",
      "Variable        CV RMSE    CV MAE     CV MAPE    CV SMAPE   CV Theil_U1  CV Theil_U2  CV MdAPE   CV MASE    CV R¬≤   \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GDPC1           5.9885     4.9396     325.66     124.56     0.7630       0.9861       197.16     0.7701     -1.566  \n",
      "PAYEMS          3.9595     3.1250     52.47      74.24      0.4281       0.6061       47.83      1.0366     -3.369  \n",
      "INDPRO          5.3687     4.5204     233.24     127.09     0.7844       2.7479       112.54     0.7541     -0.740  \n",
      "ICSA            0.3224     0.2994     2.23       2.27       0.0173       5.0049       1.96       7.3995     -221.540\n",
      "CPIAUCSL        1.1183     1.0526     894.74     77.81      0.4554       1.5863       70.29      1.8047     -2.536  \n",
      "PCEPI           0.8815     0.8386     173.02     73.46      0.4199       1.7629       89.75      2.1544     -4.007  \n",
      "AHETPI          1.0925     1.0671     27.56      32.25      0.2271       2.1035       28.01      8.2216     -98.729 \n",
      "DCOILWTICO      0.3021     0.2868     7.26       6.99       0.0520       5.6122       7.14       2.2973     -10.568 \n",
      "FEDFUNDS        0.9961     0.9466     451.26     97.42      0.5722       5.1452       446.87     31.3552    -2306.207\n",
      "DGS10           0.6394     0.5534     40.85      26.95      0.1920       1.1378       39.75      1.7860     -2.859  \n",
      "M2SL            4.0145     3.8420     26.71      35.03      0.2606       4.2875       26.88      5.4678     -106.039\n",
      "AAA             0.6992     0.6573     22.16      16.96      0.1221       1.8834       22.77      2.5008     -9.022  \n",
      "\n",
      "======================================================================\n",
      "DSGE-INFORMED MODEL SUMMARY STATISTICS\n",
      "======================================================================\n",
      "Average CV RMSE: 2.1152\n",
      "Median CV RMSE: 1.0443\n",
      "Average CV MAE: 1.8441\n",
      "Average CV R¬≤: -230.598\n",
      "Average CV Theil's U1: 0.3579\n",
      "Average CV Theil's U2: 2.7386\n",
      "Average CV MASE: 5.4624\n",
      "Median CV MASE: 2.2258\n",
      "Variables with valid metrics: 12/12\n",
      "DSGE priors used: 12 structural parameters\n",
      "Model uses Bayesian VAR with DSGE-informed coefficient restrictions\n",
      "\n",
      "================================================================================\n",
      "DSGE-INFORMED DFM ESTIMATION COMPLETED SUCCESSFULLY\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "DSGE-INFORMED ANALYSIS COMPLETED SUCCESSFULLY\n",
      "================================================================================\n",
      "Model Summary:\n",
      "  ‚Ä¢ 12 macroeconomic variables\n",
      "  ‚Ä¢ 97 quarterly observations\n",
      "  ‚Ä¢ 3 economic factors extracted\n",
      "  ‚Ä¢ VAR(1) dynamics estimated (DSGE-Informed Bayesian)\n",
      "  ‚Ä¢ 8 quarter forecasts generated\n",
      "  ‚Ä¢ DSGE structural priors: 12 parameters\n",
      "\n",
      "üéØ INTEGRATION SUMMARY:\n",
      "   DSGE parameters used: 12\n",
      "   VAR estimation method: Bayesian (DSGE-informed)\n",
      "   Model stability: True\n",
      "\n",
      "================================================================================\n",
      "DSGE-DFM INTEGRATION COMPLETED SUCCESSFULLY\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Core Dynamic Factor Model with DSGE-Informed VAR Priors\n",
    "# Minimal modification to incorporate DSGE-estimated coefficient priors\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# FRED API Setup\n",
    "afkey = 'ada1a8ba0569ed784226f2c26db44ab1'  # Replace with your FRED API key\n",
    "fred = Fred(api_key=afkey)\n",
    "\n",
    "# Economically structured blocks with consistent shock treatment\n",
    "economic_blocks = {\n",
    "    'Demand_Block': {\n",
    "        'trend_cyclical': ['GDPC1', 'PAYEMS', 'INDPRO'],  # Growth rates\n",
    "        'shock': ['ICSA']  # Level (inverse shock indicator)\n",
    "    },\n",
    "\n",
    "    'Supply_Block': {\n",
    "        'trend_cyclical': ['CPIAUCSL', 'PCEPI', 'AHETPI'],  # Growth rates\n",
    "        'shock': ['DCOILWTICO']  # Level (supply shock)\n",
    "    },\n",
    "\n",
    "    'Monetary_Block': {\n",
    "        'trend_cyclical': ['FEDFUNDS', 'DGS10', 'M2SL'],  # Mix of levels and growth\n",
    "        'shock': ['AAA']  # Level (financial stress indicator)\n",
    "    }\n",
    "}\n",
    "\n",
    "def fetch_series_robust(series_id, start_date, fred_api):\n",
    "    \"\"\"Robust series fetching with comprehensive error handling\"\"\"\n",
    "    try:\n",
    "        series = fred_api.get_series(series_id, start_date)\n",
    "        if series.empty or len(series) < 20:\n",
    "            print(f\"Warning: {series_id} insufficient data\")\n",
    "            return None\n",
    "\n",
    "        series = series.dropna()\n",
    "        series = series.to_frame(name=series_id)\n",
    "        series.index = pd.to_datetime(series.index)\n",
    "        return series\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch {series_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "def prepare_econometric_data(start_date=\"2000-01-01\"):\n",
    "    \"\"\"Prepare data with econometrically consistent transformations\"\"\"\n",
    "    print(\"Fetching economic data from FRED...\")\n",
    "\n",
    "    all_series = {}\n",
    "\n",
    "    # Fetch all series\n",
    "    for block_name, block_data in economic_blocks.items():\n",
    "        print(f\"\\nFetching {block_name}:\")\n",
    "\n",
    "        for var_type in ['trend_cyclical', 'shock']:\n",
    "            for series_id in block_data[var_type]:\n",
    "                data = fetch_series_robust(series_id, start_date, fred)\n",
    "                if data is not None:\n",
    "                    all_series[series_id] = data\n",
    "                    print(f\"  {series_id} ‚úì ({len(data)} obs)\")\n",
    "                else:\n",
    "                    print(f\"  {series_id} ‚úó\")\n",
    "\n",
    "    if len(all_series) < 8:  # Need most variables for robust estimation\n",
    "        raise ValueError(f\"Only {len(all_series)} series fetched. Need at least 8.\")\n",
    "\n",
    "    print(f\"\\nSuccessfully fetched {len(all_series)} series\")\n",
    "\n",
    "    # Find common time range\n",
    "    all_start_dates = [s.index.min() for s in all_series.values()]\n",
    "    all_end_dates = [s.index.max() for s in all_series.values()]\n",
    "\n",
    "    common_start = max(all_start_dates)\n",
    "    common_end = min(all_end_dates)\n",
    "\n",
    "    print(f\"Common date range: {common_start.strftime('%Y-%m')} to {common_end.strftime('%Y-%m')}\")\n",
    "\n",
    "    # Create quarterly index\n",
    "    quarterly_index = pd.date_range(\n",
    "        start=common_start.replace(day=1),\n",
    "        end=common_end,\n",
    "        freq='Q'\n",
    "    )\n",
    "\n",
    "    print(f\"Quarterly observations: {len(quarterly_index)}\")\n",
    "\n",
    "    # Process series with econometrically consistent transformations\n",
    "    quarterly_data = pd.DataFrame(index=quarterly_index)\n",
    "\n",
    "    for series_id, series_data in all_series.items():\n",
    "        series_trimmed = series_data[common_start:common_end].copy()\n",
    "\n",
    "        # Determine transformation based on economic theory\n",
    "        if series_id in ['GDPC1', 'PAYEMS', 'INDPRO']:\n",
    "            # Real activity: QoQ annualized growth rates\n",
    "            quarterly_last = series_trimmed.resample('Q').last()\n",
    "            quarterly_series = (quarterly_last.pct_change(1) * 400)  # Annualized QoQ\n",
    "\n",
    "        elif series_id in ['CPIAUCSL', 'PCEPI', 'AHETPI']:\n",
    "            # Prices/wages: YoY growth rates (standard for inflation)\n",
    "            quarterly_last = series_trimmed.resample('Q').last()\n",
    "            quarterly_series = quarterly_last.pct_change(4) * 100  # YoY %\n",
    "\n",
    "        elif series_id == 'M2SL':\n",
    "            # Money supply: YoY growth rate\n",
    "            quarterly_last = series_trimmed.resample('Q').last()\n",
    "            quarterly_series = quarterly_last.pct_change(4) * 100  # YoY %\n",
    "\n",
    "        elif series_id in ['FEDFUNDS', 'DGS10']:\n",
    "            # Interest rates: levels (already in percentage terms)\n",
    "            quarterly_series = series_trimmed.resample('Q').last()\n",
    "\n",
    "        elif series_id == 'ICSA':\n",
    "            # Initial claims: level (weekly average, inverse demand shock)\n",
    "            quarterly_series = series_trimmed.resample('Q').mean()\n",
    "            # Transform to make it a positive demand indicator\n",
    "            quarterly_series = -np.log(quarterly_series)  # Negative log for inverse relationship\n",
    "\n",
    "        elif series_id == 'DCOILWTICO':\n",
    "            # Oil prices: log level (shock variable, variance stabilized)\n",
    "            quarterly_last = series_trimmed.resample('Q').last()\n",
    "            quarterly_series = np.log(quarterly_last.replace(0, np.nan))  # Log level\n",
    "\n",
    "        elif series_id == 'AAA':\n",
    "            # Credit spread: level (financial stress indicator)\n",
    "            quarterly_series = series_trimmed.resample('Q').last()\n",
    "\n",
    "        # Align to quarterly index\n",
    "        quarterly_data[series_id] = quarterly_series.reindex(quarterly_index)\n",
    "\n",
    "    # Remove rows with too many missing values\n",
    "    quarterly_data = quarterly_data.dropna(thresh=len(quarterly_data.columns) * 0.7)\n",
    "\n",
    "    # Forward fill remaining missing values\n",
    "    quarterly_data = quarterly_data.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "    print(f\"Final dataset shape: {quarterly_data.shape}\")\n",
    "    print(f\"Date range: {quarterly_data.index[0].strftime('%Y-Q%q')} to {quarterly_data.index[-1].strftime('%Y-Q%q')}\")\n",
    "\n",
    "    # Organize into blocks based on what we actually got\n",
    "    organized_blocks = {}\n",
    "    for block_name, block_data in economic_blocks.items():\n",
    "        all_block_vars = block_data['trend_cyclical'] + block_data['shock']\n",
    "        available_vars = [v for v in all_block_vars if v in quarterly_data.columns]\n",
    "\n",
    "        if len(available_vars) > 0:\n",
    "            organized_blocks[block_name] = quarterly_data[available_vars]\n",
    "            print(f\"{block_name}: {available_vars}\")\n",
    "    return organized_blocks, quarterly_data\n",
    "\n",
    "\n",
    "class EconometricDFM:\n",
    "    \"\"\"\n",
    "    DSGE-Informed Dynamic Factor Model\n",
    "    \n",
    "    Key addition: Uses DSGE posterior estimates as Bayesian priors for VAR coefficients\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, organized_blocks, combined_data, dsge_priors=None):\n",
    "        self.organized_blocks = organized_blocks\n",
    "        self.combined_data = combined_data.copy()\n",
    "        \n",
    "        # NEW: Store DSGE-estimated priors\n",
    "        self.dsge_priors = dsge_priors\n",
    "\n",
    "        # Store block structure for identification\n",
    "        self.block_structure = {}\n",
    "        var_counter = 0\n",
    "\n",
    "        for block_name, block_data in organized_blocks.items():\n",
    "            n_vars = len(block_data.columns)\n",
    "            self.block_structure[block_name] = {\n",
    "                'variables': list(block_data.columns),\n",
    "                'start_idx': var_counter,\n",
    "                'end_idx': var_counter + n_vars,\n",
    "                'size': n_vars\n",
    "            }\n",
    "            var_counter += n_vars\n",
    "\n",
    "        self.N_vars = len(self.combined_data.columns)\n",
    "        self.T_obs = len(self.combined_data)\n",
    "        self.n_factors = min(3, len(self.block_structure))  # One factor per block\n",
    "\n",
    "        print(f\"\\nDSGE-Informed DFM Setup:\")\n",
    "        print(f\"  Variables: {self.N_vars}\")\n",
    "        print(f\"  Observations: {self.T_obs}\")\n",
    "        print(f\"  Factors: {self.n_factors}\")\n",
    "        if dsge_priors is not None:\n",
    "            print(f\"  DSGE priors: {len(dsge_priors)} parameters\")\n",
    "\n",
    "        # Standardize data properly\n",
    "        self.scaler = StandardScaler()\n",
    "        self.data_standardized = pd.DataFrame(\n",
    "            self.scaler.fit_transform(self.combined_data),\n",
    "            index=self.combined_data.index,\n",
    "            columns=self.combined_data.columns\n",
    "        )\n",
    "\n",
    "        # Define variable scales and types for cross-validation output\n",
    "        self.variable_info = {\n",
    "            'GDPC1': {'name': 'GDP (Billions $)', 'typical_scale': 20000, 'type': 'level'},\n",
    "            'PAYEMS': {'name': 'EMPLOYMENT (Thousands)', 'typical_scale': 150000, 'type': 'level'},\n",
    "            'INDPRO': {'name': 'INDUSTRIAL PRODUCTION (Index)', 'typical_scale': 100, 'type': 'index'},\n",
    "            'ICSA': {'name': 'INITIAL CLAIMS (Thousands)', 'typical_scale': 300, 'type': 'level'},\n",
    "            'CPIAUCSL': {'name': 'INFLATION (Index)', 'typical_scale': 250, 'type': 'index'},\n",
    "            'PCEPI': {'name': 'PCE INFLATION (Index)', 'typical_scale': 110, 'type': 'index'},\n",
    "            'AHETPI': {'name': 'WAGES (Dollars/Hour)', 'typical_scale': 25, 'type': 'level'},\n",
    "            'DCOILWTICO': {'name': 'OIL PRICES ($/Barrel)', 'typical_scale': 60, 'type': 'level'},\n",
    "            'FEDFUNDS': {'name': 'INTEREST RATE (Percent)', 'typical_scale': 5, 'type': 'rate'},\n",
    "            'DGS10': {'name': '10Y TREASURY (Percent)', 'typical_scale': 5, 'type': 'rate'},\n",
    "            'M2SL': {'name': 'MONEY SUPPLY (Billions $)', 'typical_scale': 15000, 'type': 'level'},\n",
    "            'AAA': {'name': 'CREDIT SPREAD (Percent)', 'typical_scale': 4, 'type': 'rate'}\n",
    "        }\n",
    "\n",
    "        # Results storage\n",
    "        self.factors = None\n",
    "        self.loadings = None\n",
    "        self.factor_var = None\n",
    "        self.idiosyncratic_var = None\n",
    "\n",
    "    def extract_factors_pca(self):\n",
    "        \"\"\"Extract factors using Principal Component Analysis\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"STEP 1: FACTOR EXTRACTION VIA PCA\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        # Apply PCA to standardized data\n",
    "        pca = PCA(n_components=self.n_factors)\n",
    "        factors_pca = pca.fit_transform(self.data_standardized)\n",
    "\n",
    "        # Store factors with economic names\n",
    "        factor_names = ['Demand_Factor', 'Supply_Factor', 'Monetary_Factor'][:self.n_factors]\n",
    "\n",
    "        self.factors = pd.DataFrame(\n",
    "            factors_pca,\n",
    "            index=self.data_standardized.index,\n",
    "            columns=factor_names\n",
    "        )\n",
    "\n",
    "        # Store loadings (PCA components)\n",
    "        self.pca_loadings = pd.DataFrame(\n",
    "            pca.components_.T,\n",
    "            index=self.combined_data.columns,\n",
    "            columns=factor_names\n",
    "        )\n",
    "\n",
    "        print(f\"PCA explained variance: {pca.explained_variance_ratio_}\")\n",
    "        print(f\"Cumulative explained variance: {np.cumsum(pca.explained_variance_ratio_)}\")\n",
    "\n",
    "        return self.factors\n",
    "\n",
    "    def estimate_factor_loadings(self):\n",
    "        \"\"\"Estimate factor loadings via regression\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"STEP 2: FACTOR LOADING ESTIMATION\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        if self.factors is None:\n",
    "            raise ValueError(\"Must extract factors first\")\n",
    "\n",
    "        # Estimate loadings: X_t = Œõ F_t + Œµ_t\n",
    "        X = self.data_standardized.values  # T x N\n",
    "        F = self.factors.values           # T x r\n",
    "\n",
    "        # OLS: Œõ = (F'F)^(-1) F'X'\n",
    "        FtF_inv = np.linalg.inv(F.T @ F)\n",
    "        Lambda = (FtF_inv @ F.T @ X).T  # N x r\n",
    "\n",
    "        # Calculate residuals and fit statistics\n",
    "        X_fitted = F @ Lambda.T\n",
    "        residuals = X - X_fitted\n",
    "\n",
    "        # R-squared for each variable\n",
    "        r_squared = np.zeros(self.N_vars)\n",
    "        idiosyncratic_var = np.zeros(self.N_vars)\n",
    "\n",
    "        for i in range(self.N_vars):\n",
    "            ss_res = np.sum(residuals[:, i]**2)\n",
    "            ss_tot = np.sum((X[:, i] - np.mean(X[:, i]))**2)\n",
    "            r_squared[i] = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "            idiosyncratic_var[i] = np.var(residuals[:, i])\n",
    "\n",
    "        self.loadings = pd.DataFrame(\n",
    "            Lambda,\n",
    "            index=self.combined_data.columns,\n",
    "            columns=self.factors.columns\n",
    "        )\n",
    "\n",
    "        self.idiosyncratic_var = pd.Series(\n",
    "            idiosyncratic_var,\n",
    "            index=self.combined_data.columns\n",
    "        )\n",
    "\n",
    "        # Print basic results\n",
    "        print(\"\\nFactor Loading Results:\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"{'Variable':<12} {'R¬≤':<6} {'Demand':<10} {'Supply':<10} {'Monetary':<10}\")\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "        for i, var in enumerate(self.combined_data.columns):\n",
    "            loadings_row = [Lambda[i, j] if j < Lambda.shape[1] else 0 for j in range(3)]\n",
    "            print(f\"{var:<12} {r_squared[i]:<6.3f} \"\n",
    "                  f\"{loadings_row[0]:<10.3f} {loadings_row[1]:<10.3f} {loadings_row[2]:<10.3f}\")\n",
    "\n",
    "        print(f\"\\nAverage R¬≤: {np.mean(r_squared):.3f}\")\n",
    "        return self.loadings\n",
    "\n",
    "    def _construct_dsge_priors(self, optimal_lag):\n",
    "        \"\"\"\n",
    "        NEW METHOD: Construct Bayesian VAR priors from DSGE estimates\n",
    "        \n",
    "        Maps DSGE structural parameters to reduced-form VAR coefficient priors\n",
    "        \"\"\"\n",
    "        if self.dsge_priors is None:\n",
    "            return None\n",
    "            \n",
    "        print(f\"\\nüìã Constructing DSGE-informed priors for VAR({optimal_lag})...\")\n",
    "        \n",
    "        K = self.n_factors\n",
    "        n_coeffs = K * K * optimal_lag + K  # VAR coeffs + constants\n",
    "        \n",
    "        # Extract key DSGE parameters (using median/mode from posterior)\n",
    "        dsge_params = {}\n",
    "        for param_name in ['sigma', 'theta', 'phi_pi', 'phi_y', 'rho_a', 'rho_v']:\n",
    "            if param_name in self.dsge_priors:\n",
    "                # Get posterior mean as point estimate\n",
    "                dsge_params[param_name] = self.dsge_priors[param_name].get('mean', 1.0)\n",
    "        \n",
    "        # Construct theory-consistent priors\n",
    "        prior_mean = np.zeros(n_coeffs)\n",
    "        prior_var = np.ones(n_coeffs)\n",
    "        \n",
    "        # Constants (intercepts) - weakly informative\n",
    "        prior_var[:K] = 1.0\n",
    "        \n",
    "        # VAR coefficient priors based on DSGE structure\n",
    "        coeff_start = K\n",
    "        \n",
    "        for lag in range(1, optimal_lag + 1):\n",
    "            for i in range(K):  # Each factor equation\n",
    "                for j in range(K):  # Each factor lag\n",
    "                    coeff_idx = coeff_start + (lag-1)*K*K + i*K + j\n",
    "                    \n",
    "                    if i == j:  # Own lags\n",
    "                        if lag == 1:\n",
    "                            # First own lag - use DSGE persistence parameters\n",
    "                            if i == 0:  # Demand factor - related to output persistence\n",
    "                                prior_mean[coeff_idx] = dsge_params.get('rho_a', 0.5) * 0.7\n",
    "                                prior_var[coeff_idx] = 0.1\n",
    "                            elif i == 1:  # Supply factor - related to price stickiness\n",
    "                                stickiness = dsge_params.get('theta', 0.7)\n",
    "                                prior_mean[coeff_idx] = min(0.9, stickiness * 1.2)\n",
    "                                prior_var[coeff_idx] = 0.1\n",
    "                            else:  # Monetary factor - use monetary persistence\n",
    "                                prior_mean[coeff_idx] = dsge_params.get('rho_v', 0.3)\n",
    "                                prior_var[coeff_idx] = 0.15\n",
    "                        else:\n",
    "                            # Higher order own lags - decay\n",
    "                            prior_mean[coeff_idx] = prior_mean[coeff_start + (i*K + j)] * 0.5\n",
    "                            prior_var[coeff_idx] = 0.2\n",
    "                    else:  # Cross-lags\n",
    "                        if lag == 1:\n",
    "                            # Theory-based cross-effects\n",
    "                            if (i == 0 and j == 2):  # Monetary -> Demand (IS curve)\n",
    "                                prior_mean[coeff_idx] = -1.0 / dsge_params.get('sigma', 1.0) * 0.1\n",
    "                                prior_var[coeff_idx] = 0.05\n",
    "                            elif (i == 1 and j == 0):  # Demand -> Supply (Phillips curve)  \n",
    "                                prior_mean[coeff_idx] = dsge_params.get('phi_y', 0.5) * 0.2\n",
    "                                prior_var[coeff_idx] = 0.05\n",
    "                            elif (i == 2 and j == 1):  # Supply -> Monetary (Taylor rule)\n",
    "                                prior_mean[coeff_idx] = dsge_params.get('phi_pi', 1.5) * 0.1\n",
    "                                prior_var[coeff_idx] = 0.05\n",
    "                            else:\n",
    "                                prior_mean[coeff_idx] = 0.0\n",
    "                                prior_var[coeff_idx] = 0.1\n",
    "                        else:\n",
    "                            # Higher order cross-lags - shrink to zero\n",
    "                            prior_mean[coeff_idx] = 0.0\n",
    "                            prior_var[coeff_idx] = 0.1 / lag\n",
    "        \n",
    "        print(f\"   Prior mean range: [{np.min(prior_mean):.3f}, {np.max(prior_mean):.3f}]\")\n",
    "        print(f\"   Prior variance range: [{np.min(prior_var):.3f}, {np.max(prior_var):.3f}]\")\n",
    "        \n",
    "        return {\n",
    "            'mean': prior_mean,\n",
    "            'variance': prior_var,\n",
    "            'dsge_params': dsge_params\n",
    "        }\n",
    "\n",
    "    def estimate_factor_var(self, max_lags=6, ic='bic'):\n",
    "        \"\"\"\n",
    "        MODIFIED: Estimate VAR model with optional DSGE-informed priors\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"STEP 3: DSGE-INFORMED FACTOR VAR ESTIMATION\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        if self.factors is None:\n",
    "            raise ValueError(\"Must extract factors first\")\n",
    "\n",
    "        F = self.factors.values\n",
    "        T, K = F.shape\n",
    "\n",
    "        # Lag selection using information criteria\n",
    "        optimal_lag = self._select_optimal_lag(F, max_lags, ic)\n",
    "        print(f\"Optimal lag selected: {optimal_lag} (using {ic.upper()})\")\n",
    "\n",
    "        # Construct DSGE priors if available\n",
    "        dsge_prior_info = self._construct_dsge_priors(optimal_lag)\n",
    "        \n",
    "        # Estimate VAR model (Bayesian if priors available, OLS otherwise)\n",
    "        if dsge_prior_info is not None:\n",
    "            print(\"üéØ Using DSGE-informed Bayesian estimation\")\n",
    "            self.factor_var = self._estimate_bayesian_var(F, optimal_lag, dsge_prior_info)\n",
    "        else:\n",
    "            print(\"üìä Using standard OLS estimation\")\n",
    "            self.factor_var = self._estimate_var_model(F, optimal_lag)\n",
    "\n",
    "        # Check model stability\n",
    "        self._check_var_stability()\n",
    "\n",
    "        return self.factor_var\n",
    "\n",
    "    def _estimate_bayesian_var(self, data, lags, prior_info, verbose=True):\n",
    "        \"\"\"\n",
    "        NEW METHOD: Bayesian VAR estimation with DSGE-informed priors\n",
    "        \"\"\"\n",
    "        T, K = data.shape\n",
    "        \n",
    "        # Construct regression matrices\n",
    "        Y = data[lags:, :]  # Dependent variables\n",
    "        T_eff = Y.shape[0]\n",
    "        \n",
    "        # Design matrix\n",
    "        X = np.ones((T_eff, 1))  # Constant\n",
    "        for lag in range(1, lags + 1):\n",
    "            X = np.hstack([X, data[lags-lag:-lag, :]])\n",
    "        \n",
    "        n_regressors = X.shape[1]\n",
    "        \n",
    "        # Prior parameters\n",
    "        beta_prior = prior_info['mean'].reshape(-1, 1)\n",
    "        V_prior = np.diag(prior_info['variance'])\n",
    "        \n",
    "        # Bayesian updating\n",
    "        V_prior_inv = np.linalg.inv(V_prior)\n",
    "        XtX = X.T @ X\n",
    "        \n",
    "        # Posterior covariance for coefficients\n",
    "        V_posterior_inv = V_prior_inv + np.kron(np.eye(K), XtX)\n",
    "        V_posterior = np.linalg.inv(V_posterior_inv)\n",
    "        \n",
    "        # Posterior mean for coefficients  \n",
    "        XtY = X.T @ Y\n",
    "        beta_posterior_vec = V_posterior @ (V_prior_inv @ beta_prior + XtY.flatten('F').reshape(-1, 1))\n",
    "        beta_posterior = beta_posterior_vec.reshape((n_regressors, K), order='F')\n",
    "        \n",
    "        # Residual sum of squares (for residual covariance)\n",
    "        Y_fitted = X @ beta_posterior\n",
    "        residuals = Y - Y_fitted\n",
    "        \n",
    "        # Residual covariance matrix (ML estimate)\n",
    "        sigma_u = (residuals.T @ residuals) / T_eff\n",
    "        \n",
    "        # Coefficient matrices\n",
    "        const = beta_posterior[0, :]\n",
    "        var_coeffs = beta_posterior[1:, :].T\n",
    "        \n",
    "        # Model statistics\n",
    "        log_likelihood = self._compute_log_likelihood(residuals, sigma_u)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Bayesian VAR({lags}) estimation completed:\")\n",
    "            print(f\"  Effective sample: {T_eff}\")\n",
    "            print(f\"  Log-likelihood: {log_likelihood:.2f}\")\n",
    "            print(f\"  DSGE prior influence: {'High' if np.max(prior_info['variance']) < 0.5 else 'Moderate'}\")\n",
    "        \n",
    "        return {\n",
    "            'coefficients': var_coeffs,\n",
    "            'constant': const, \n",
    "            'sigma_u': sigma_u,\n",
    "            'residuals': residuals,\n",
    "            'log_likelihood': log_likelihood,\n",
    "            'lags': lags,\n",
    "            'T_eff': T_eff,\n",
    "            'X_design': X,\n",
    "            'Y_data': Y,\n",
    "            'bayesian': True,\n",
    "            'prior_info': prior_info,\n",
    "            'posterior_beta': beta_posterior,\n",
    "            'posterior_cov': V_posterior\n",
    "        }\n",
    "\n",
    "    def _select_optimal_lag(self, data, max_lags, criterion='bic'):\n",
    "        \"\"\"Select optimal VAR lag using information criteria\"\"\"\n",
    "        T, K = data.shape\n",
    "        max_feasible_lags = min(max_lags, T // (4 * K))  # Ensure sufficient degrees of freedom\n",
    "\n",
    "        ic_values = []\n",
    "\n",
    "        for p in range(1, max_feasible_lags + 1):\n",
    "            try:\n",
    "                var_result = self._estimate_var_model(data, p, verbose=False)\n",
    "                T_eff = T - p\n",
    "\n",
    "                # Calculate information criteria\n",
    "                log_det_sigma = np.log(np.linalg.det(var_result['sigma_u']))\n",
    "                n_params = K + K**2 * p  # Constants + VAR coefficients\n",
    "\n",
    "                if criterion.lower() == 'aic':\n",
    "                    ic = log_det_sigma + (2 * n_params) / T_eff\n",
    "                elif criterion.lower() == 'bic':\n",
    "                    ic = log_det_sigma + (n_params * np.log(T_eff)) / T_eff\n",
    "                elif criterion.lower() == 'hqic':\n",
    "                    ic = log_det_sigma + (2 * n_params * np.log(np.log(T_eff))) / T_eff\n",
    "                else:\n",
    "                    raise ValueError(\"Criterion must be 'aic', 'bic', or 'hqic'\")\n",
    "\n",
    "                ic_values.append((p, ic))\n",
    "\n",
    "            except np.linalg.LinAlgError:\n",
    "                continue\n",
    "\n",
    "        if not ic_values:\n",
    "            print(f\"Warning: Could not estimate VAR models. Using lag=1\")\n",
    "            return 1\n",
    "\n",
    "        # Select lag with minimum IC\n",
    "        optimal_lag = min(ic_values, key=lambda x: x[1])[0]\n",
    "        return optimal_lag\n",
    "\n",
    "    def _estimate_var_model(self, data, lags, verbose=True):\n",
    "        \"\"\"Estimate VAR(p) model using OLS\"\"\"\n",
    "        T, K = data.shape\n",
    "\n",
    "        if T <= lags * K + K:\n",
    "            raise ValueError(f\"Insufficient observations for VAR({lags})\")\n",
    "\n",
    "        # Construct regression matrices\n",
    "        Y = data[lags:, :]  # Dependent variables (T-p) x K\n",
    "        T_eff = Y.shape[0]\n",
    "\n",
    "        # Construct regressor matrix X\n",
    "        X = np.ones((T_eff, 1))  # Constant term\n",
    "\n",
    "        for lag in range(1, lags + 1):\n",
    "            X = np.hstack([X, data[lags-lag:-lag, :]])  # Add lagged factors\n",
    "\n",
    "        # OLS estimation: Y = X Œ≤ + u\n",
    "        XtX_inv = np.linalg.inv(X.T @ X)\n",
    "        beta = XtX_inv @ X.T @ Y  # (1 + K*p) x K\n",
    "\n",
    "        # Residuals and covariance matrix\n",
    "        u = Y - X @ beta  # Residuals\n",
    "        sigma_u = (u.T @ u) / T_eff  # Residual covariance matrix\n",
    "\n",
    "        # Coefficient matrices\n",
    "        const = beta[0, :]  # Constant terms\n",
    "        var_coeffs = beta[1:, :].T  # K x (K*p) VAR coefficient matrix\n",
    "\n",
    "        # Standard errors (for diagnostics)\n",
    "        var_beta = np.kron(sigma_u, XtX_inv)\n",
    "        se_beta = np.sqrt(np.diag(var_beta)).reshape(beta.shape)\n",
    "\n",
    "        # Model statistics\n",
    "        log_likelihood = self._compute_log_likelihood(u, sigma_u)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"VAR({lags}) estimation completed:\")\n",
    "            print(f\"  Effective sample: {T_eff}\")\n",
    "            print(f\"  Log-likelihood: {log_likelihood:.2f}\")\n",
    "\n",
    "        return {\n",
    "            'coefficients': var_coeffs,      # K x (K*p)\n",
    "            'constant': const,               # K x 1\n",
    "            'sigma_u': sigma_u,             # K x K residual covariance\n",
    "            'residuals': u,                 # (T-p) x K\n",
    "            'standard_errors': se_beta,     # Full parameter standard errors\n",
    "            'log_likelihood': log_likelihood,\n",
    "            'lags': lags,\n",
    "            'T_eff': T_eff,\n",
    "            'X_design': X,                  # Design matrix\n",
    "            'Y_data': Y,                    # Dependent variable matrix\n",
    "            'bayesian': False\n",
    "        }\n",
    "\n",
    "    def _compute_log_likelihood(self, residuals, sigma_u):\n",
    "        \"\"\"Compute log-likelihood for VAR model\"\"\"\n",
    "        T, K = residuals.shape\n",
    "        log_likelihood = -0.5 * T * K * np.log(2 * np.pi)\n",
    "        log_likelihood -= 0.5 * T * np.log(np.linalg.det(sigma_u))\n",
    "        log_likelihood -= 0.5 * np.trace(residuals.T @ residuals @ np.linalg.inv(sigma_u))\n",
    "        return log_likelihood\n",
    "\n",
    "    def _check_var_stability(self):\n",
    "        \"\"\"Check VAR model stability via companion matrix eigenvalues\"\"\"\n",
    "        if self.factor_var is None:\n",
    "            return False\n",
    "\n",
    "        Phi = self.factor_var['coefficients']\n",
    "        p = self.factor_var['lags']\n",
    "        K = Phi.shape[0]\n",
    "\n",
    "        # Construct companion matrix\n",
    "        if p == 1:\n",
    "            companion = Phi\n",
    "        else:\n",
    "            # For VAR(p): K*p x K*p companion matrix\n",
    "            companion = np.zeros((K * p, K * p))\n",
    "            companion[:K, :] = Phi  # Top block: VAR coefficients\n",
    "\n",
    "            # Identity blocks for lagged terms\n",
    "            for i in range(1, p):\n",
    "                start_row, end_row = i * K, (i + 1) * K\n",
    "                start_col, end_col = (i - 1) * K, i * K\n",
    "                companion[start_row:end_row, start_col:end_col] = np.eye(K)\n",
    "\n",
    "        # Check stability condition\n",
    "        eigenvals = np.linalg.eigvals(companion)\n",
    "        max_modulus = np.max(np.abs(eigenvals))\n",
    "        is_stable = max_modulus < 1.0\n",
    "\n",
    "        estimation_type = \"Bayesian\" if self.factor_var.get('bayesian', False) else \"OLS\"\n",
    "        print(f\"\\n{estimation_type} VAR Stability Check:\")\n",
    "        print(f\"  Maximum eigenvalue modulus: {max_modulus:.4f}\")\n",
    "        print(f\"  Model is {'stable' if is_stable else 'unstable'} {'‚úì' if is_stable else '‚úó'}\")\n",
    "\n",
    "        self.companion_matrix = companion\n",
    "        self.eigenvalues = eigenvals\n",
    "        return is_stable\n",
    "\n",
    "    def forecast_var(self, horizon=8, confidence_level=0.95):\n",
    "        \"\"\"Generate VAR forecasts using companion form\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"VAR FORECASTING WITH COMPANION FORM\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        if self.factor_var is None:\n",
    "            raise ValueError(\"Must estimate VAR model first\")\n",
    "\n",
    "        # Extract VAR parameters\n",
    "        Phi = self.factor_var['coefficients']    # K x (K*p)\n",
    "        c = self.factor_var['constant']          # K x 1\n",
    "        Sigma = self.factor_var['sigma_u']       # K x K\n",
    "        p = self.factor_var['lags']\n",
    "        K = Phi.shape[0]\n",
    "\n",
    "        estimation_type = \"Bayesian\" if self.factor_var.get('bayesian', False) else \"OLS\"\n",
    "        print(f\"Forecasting {K} factors for {horizon} periods using {estimation_type} VAR({p})\")\n",
    "\n",
    "        # Analytical forecasting using companion form\n",
    "        forecasts_analytical = self._forecast_companion_form(horizon)\n",
    "\n",
    "        # Bootstrap forecasting for confidence intervals\n",
    "        forecasts_bootstrap = self._forecast_bootstrap(horizon, n_bootstrap=500, confidence_level=confidence_level)\n",
    "\n",
    "        # Combine results\n",
    "        forecast_dates = pd.date_range(\n",
    "            start=self.factors.index[-1] + pd.DateOffset(months=3),\n",
    "            periods=horizon,\n",
    "            freq='Q'\n",
    "        )\n",
    "\n",
    "        self.factor_forecasts = {\n",
    "            'mean': pd.DataFrame(\n",
    "                forecasts_analytical['mean'],\n",
    "                index=forecast_dates,\n",
    "                columns=self.factors.columns\n",
    "            ),\n",
    "            'analytical_std': pd.DataFrame(\n",
    "                forecasts_analytical['std'],\n",
    "                index=forecast_dates,\n",
    "                columns=self.factors.columns\n",
    "            ),\n",
    "            'bootstrap_lower': pd.DataFrame(\n",
    "                forecasts_bootstrap['lower'],\n",
    "                index=forecast_dates,\n",
    "                columns=self.factors.columns\n",
    "            ),\n",
    "            'bootstrap_upper': pd.DataFrame(\n",
    "                forecasts_bootstrap['upper'],\n",
    "                index=forecast_dates,\n",
    "                columns=self.factors.columns\n",
    "            )\n",
    "        }\n",
    "\n",
    "        print(f\"\\nForecast Summary (1-quarter ahead):\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, factor in enumerate(self.factors.columns):\n",
    "            mean_fcst = forecasts_analytical['mean'][0, i]\n",
    "            std_fcst = forecasts_analytical['std'][0, i]\n",
    "            print(f\"{factor}: {mean_fcst:7.3f} ¬± {std_fcst:.3f}\")\n",
    "\n",
    "        return self.factor_forecasts\n",
    "\n",
    "    def _forecast_companion_form(self, horizon):\n",
    "        \"\"\"Analytical VAR forecasting using companion matrix\"\"\"\n",
    "        Phi = self.factor_var['coefficients']\n",
    "        c = self.factor_var['constant']\n",
    "        Sigma = self.factor_var['sigma_u']\n",
    "        p = self.factor_var['lags']\n",
    "        K = Phi.shape[0]\n",
    "\n",
    "        # Initialize forecast arrays\n",
    "        forecasts = np.zeros((horizon, K))\n",
    "        forecast_variance = np.zeros((horizon, K))\n",
    "\n",
    "        if p == 1:\n",
    "            # VAR(1) case\n",
    "            for h in range(horizon):\n",
    "                if h == 0:\n",
    "                    forecasts[h, :] = c + Phi @ self.factors.values[-1, :]\n",
    "                    forecast_variance[h, :] = np.diag(Sigma)\n",
    "                else:\n",
    "                    forecasts[h, :] = c + Phi @ forecasts[h-1, :]\n",
    "                    Phi_h = np.linalg.matrix_power(Phi, h)\n",
    "                    forecast_variance[h, :] = np.diag(Phi_h @ Sigma @ Phi_h.T)\n",
    "        else:\n",
    "            # VAR(p) case - use companion form\n",
    "            companion = self.companion_matrix\n",
    "            K_comp = companion.shape[0]\n",
    "\n",
    "            # Get initial conditions\n",
    "            F_init = self.factors.values[-p:, :].flatten('F')\n",
    "            z_init = np.zeros(K_comp)\n",
    "            z_init[:K*p] = F_init\n",
    "\n",
    "            c_comp = np.zeros(K_comp)\n",
    "            c_comp[:K] = c\n",
    "\n",
    "            Sigma_comp = np.zeros((K_comp, K_comp))\n",
    "            Sigma_comp[:K, :K] = Sigma\n",
    "\n",
    "            z_forecast = z_init.copy()\n",
    "\n",
    "            for h in range(horizon):\n",
    "                z_forecast = c_comp + companion @ z_forecast\n",
    "                forecasts[h, :] = z_forecast[:K]\n",
    "\n",
    "                if h == 0:\n",
    "                    forecast_variance[h, :] = np.diag(Sigma)\n",
    "                else:\n",
    "                    cum_var = np.zeros((K, K))\n",
    "                    for j in range(h + 1):\n",
    "                        A_j = np.linalg.matrix_power(companion, j)\n",
    "                        cum_var += A_j[:K, :K] @ Sigma @ A_j[:K, :K].T\n",
    "                    forecast_variance[h, :] = np.diag(cum_var)\n",
    "\n",
    "        return {\n",
    "            'mean': forecasts,\n",
    "            'std': np.sqrt(forecast_variance)\n",
    "        }\n",
    "\n",
    "    def _forecast_bootstrap(self, horizon, n_bootstrap=500, confidence_level=0.95):\n",
    "        \"\"\"Bootstrap VAR forecasting for confidence intervals\"\"\"\n",
    "        Phi = self.factor_var['coefficients']\n",
    "        c = self.factor_var['constant']\n",
    "        residuals = self.factor_var['residuals']\n",
    "        p = self.factor_var['lags']\n",
    "        K = Phi.shape[0]\n",
    "\n",
    "        bootstrap_paths = np.zeros((n_bootstrap, horizon, K))\n",
    "\n",
    "        for b in range(n_bootstrap):\n",
    "            boot_indices = np.random.choice(len(residuals), size=horizon, replace=True)\n",
    "            boot_residuals = residuals[boot_indices, :]\n",
    "\n",
    "            if p == 1:\n",
    "                F_last = self.factors.values[-1, :].copy()\n",
    "                for h in range(horizon):\n",
    "                    F_forecast = c + Phi @ F_last + boot_residuals[h, :]\n",
    "                    bootstrap_paths[b, h, :] = F_forecast\n",
    "                    F_last = F_forecast\n",
    "            else:\n",
    "                F_history = self.factors.values[-p:, :].copy()\n",
    "                for h in range(horizon):\n",
    "                    F_lagged = F_history.flatten('F')\n",
    "                    F_forecast = c + Phi @ F_lagged + boot_residuals[h, :]\n",
    "                    bootstrap_paths[b, h, :] = F_forecast\n",
    "                    F_history = np.vstack([F_history[1:, :], F_forecast.reshape(1, -1)])\n",
    "\n",
    "        # Calculate statistics\n",
    "        alpha = 1 - confidence_level\n",
    "        lower_pct = 100 * (alpha / 2)\n",
    "        upper_pct = 100 * (1 - alpha / 2)\n",
    "\n",
    "        return {\n",
    "            'lower': np.percentile(bootstrap_paths, lower_pct, axis=0),\n",
    "            'upper': np.percentile(bootstrap_paths, upper_pct, axis=0)\n",
    "        }\n",
    "\n",
    "    def generate_variable_forecasts(self, horizon=8):\n",
    "        \"\"\"Generate forecasts for all observable variables using factor forecasts\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"VARIABLE FORECASTING VIA FACTOR MODEL\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        if not hasattr(self, 'factor_forecasts'):\n",
    "            self.forecast_var(horizon)\n",
    "\n",
    "        if self.loadings is None:\n",
    "            raise ValueError(\"Must estimate factor loadings first\")\n",
    "\n",
    "        Lambda = self.loadings.values  # N x K\n",
    "        F_forecasts = self.factor_forecasts['mean'].values  # horizon x K\n",
    "        X_forecasts_std = F_forecasts @ Lambda.T  # horizon x N\n",
    "\n",
    "        # Transform back to original scale\n",
    "        X_forecasts = self.scaler.inverse_transform(X_forecasts_std)\n",
    "\n",
    "        # Create forecast DataFrames\n",
    "        forecast_dates = self.factor_forecasts['mean'].index\n",
    "\n",
    "        variable_forecasts = pd.DataFrame(\n",
    "            X_forecasts,\n",
    "            index=forecast_dates,\n",
    "            columns=self.combined_data.columns\n",
    "        )\n",
    "\n",
    "        self.variable_forecasts = {\n",
    "            'mean': variable_forecasts\n",
    "        }\n",
    "\n",
    "        print(f\"Generated forecasts for {len(self.combined_data.columns)} variables\")\n",
    "        return self.variable_forecasts\n",
    "\n",
    "    def perform_cross_validation(self, k_folds=5, forecast_horizon=4):\n",
    "        \"\"\"Perform k-fold cross-validation and collect comprehensive fold-level metrics\"\"\"\n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(\"5-FOLD CROSS-VALIDATION WITH COMPREHENSIVE METRICS\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        T = len(self.combined_data)\n",
    "        fold_size = T // k_folds\n",
    "        min_train_size = max(20, self.n_factors * 4)  # Ensure sufficient training data\n",
    "        \n",
    "        # Store metrics for each fold and each variable\n",
    "        fold_metrics = {var: [] for var in self.combined_data.columns}\n",
    "        \n",
    "        print(f\"Total observations: {T}\")\n",
    "        print(f\"Fold size: {fold_size}\")\n",
    "        print(f\"Forecast horizon: {forecast_horizon}\")\n",
    "        \n",
    "        for fold in range(k_folds):\n",
    "            print(f\"\\nProcessing Fold {fold + 1}/{k_folds}...\")\n",
    "            \n",
    "            # Define train/test split for time series (expanding window)\n",
    "            test_start = min_train_size + fold * fold_size\n",
    "            test_end = min(test_start + forecast_horizon, T)\n",
    "            train_end = test_start\n",
    "            \n",
    "            if test_end > T or train_end < min_train_size:\n",
    "                print(f\"  Skipping fold {fold + 1} - insufficient data\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"  Train: {0} to {train_end-1} ({train_end} obs)\")\n",
    "            print(f\"  Test: {test_start} to {test_end-1} ({test_end - test_start} obs)\")\n",
    "            \n",
    "            try:\n",
    "                # Create training data\n",
    "                train_data = self.combined_data.iloc[:train_end].copy()\n",
    "                test_data = self.combined_data.iloc[test_start:test_end].copy()\n",
    "                \n",
    "                # Create temporary model for this fold\n",
    "                temp_organized_blocks = {}\n",
    "                for block_name, block_data in self.organized_blocks.items():\n",
    "                    temp_organized_blocks[block_name] = block_data.iloc[:train_end]\n",
    "                \n",
    "                # Create and train fold model - PASS DSGE PRIORS TO EACH FOLD\n",
    "                fold_model = EconometricDFM(temp_organized_blocks, train_data, dsge_priors=self.dsge_priors)\n",
    "                fold_model.extract_factors_pca()\n",
    "                fold_model.estimate_factor_loadings()\n",
    "                fold_model.estimate_factor_var()\n",
    "                \n",
    "                # Generate forecasts\n",
    "                fold_model.forecast_var(horizon=len(test_data))\n",
    "                fold_model.generate_variable_forecasts(horizon=len(test_data))\n",
    "                \n",
    "                # Store results for each variable\n",
    "                forecasts = fold_model.variable_forecasts['mean']\n",
    "                \n",
    "                for var in self.combined_data.columns:\n",
    "                    if var in forecasts.columns and var in test_data.columns:\n",
    "                        var_forecasts = forecasts[var].values[:len(test_data)]\n",
    "                        var_actuals = test_data[var].values\n",
    "                        \n",
    "                        # For Theil's U2, we need naive no-change forecast\n",
    "                        # Use the last training observation as naive forecast\n",
    "                        var_naive = np.full_like(var_actuals, train_data[var].iloc[-1])\n",
    "                        \n",
    "                        # Remove any NaN values\n",
    "                        valid_idx = ~(np.isnan(var_forecasts) | np.isnan(var_actuals))\n",
    "                        if valid_idx.sum() > 0:\n",
    "                            # Calculate metrics for this fold\n",
    "                            fold_metric = self._calculate_comprehensive_forecast_metrics(\n",
    "                                var_forecasts[valid_idx], \n",
    "                                var_actuals[valid_idx], \n",
    "                                var_naive[valid_idx],\n",
    "                                var\n",
    "                            )\n",
    "                            fold_metrics[var].append(fold_metric)\n",
    "                \n",
    "                print(f\"  Fold {fold + 1} completed successfully\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  Fold {fold + 1} failed: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Calculate statistics across folds for each variable\n",
    "        self.cv_fold_statistics = {}\n",
    "        for var in self.combined_data.columns:\n",
    "            if len(fold_metrics[var]) > 0:\n",
    "                self.cv_fold_statistics[var] = self._calculate_fold_statistics(fold_metrics[var])\n",
    "        \n",
    "        return self.cv_fold_statistics\n",
    "\n",
    "    def _calculate_comprehensive_forecast_metrics(self, forecasts, actuals, naive_forecasts, var_name):\n",
    "        \"\"\"Calculate all comprehensive forecast accuracy metrics for a single fold\"\"\"\n",
    "        # Basic error metrics\n",
    "        errors = forecasts - actuals\n",
    "        abs_errors = np.abs(errors)\n",
    "        \n",
    "        # Naive forecast errors for Theil's U2\n",
    "        naive_errors = naive_forecasts - actuals\n",
    "        \n",
    "        # Core metrics\n",
    "        rmse = np.sqrt(np.mean(errors**2))\n",
    "        mae = np.mean(abs_errors)\n",
    "        \n",
    "        # Percentage errors (handle division by zero)\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            # MAPE - Mean Absolute Percentage Error\n",
    "            epsilon = 1e-8\n",
    "            mape = np.mean(np.abs(errors / np.maximum(np.abs(actuals), epsilon))) * 100\n",
    "            \n",
    "            # SMAPE - Symmetric Mean Absolute Percentage Error  \n",
    "            denominator = (np.abs(forecasts) + np.abs(actuals)) / 2\n",
    "            smape = np.mean(np.abs(errors) / np.maximum(denominator, epsilon)) * 100\n",
    "            \n",
    "            # MdAPE - Median Absolute Percentage Error\n",
    "            ape = np.abs(errors / np.maximum(np.abs(actuals), epsilon)) * 100\n",
    "            ape_finite = ape[np.isfinite(ape)]\n",
    "            mdape = np.median(ape_finite) if len(ape_finite) > 0 else np.inf\n",
    "        \n",
    "        # Theil's U1 statistic (Inequality Coefficient)\n",
    "        if len(actuals) > 0:\n",
    "            mean_actual_sq = np.mean(actuals**2)\n",
    "            mean_forecast_sq = np.mean(forecasts**2)\n",
    "            \n",
    "            if mean_actual_sq > 0 and mean_forecast_sq > 0:\n",
    "                theil_u1 = rmse / np.sqrt(mean_actual_sq + mean_forecast_sq)\n",
    "            else:\n",
    "                theil_u1 = np.nan\n",
    "        else:\n",
    "            theil_u1 = np.nan\n",
    "        \n",
    "        # Theil's U2 statistic (Relative RMSE vs naive no-change forecast)\n",
    "        naive_rmse = np.sqrt(np.mean(naive_errors**2))\n",
    "        if naive_rmse > 0:\n",
    "            theil_u2 = rmse / naive_rmse\n",
    "        else:\n",
    "            theil_u2 = np.nan\n",
    "        \n",
    "        # MASE - Mean Absolute Scaled Error\n",
    "        if len(actuals) > 1:\n",
    "            # Scale by naive seasonal forecast (here just first differences)\n",
    "            naive_errors_seas = np.abs(np.diff(actuals))\n",
    "            if len(naive_errors_seas) > 0 and np.mean(naive_errors_seas) > 0:\n",
    "                mase = mae / np.mean(naive_errors_seas)\n",
    "            else:\n",
    "                mase = np.inf\n",
    "        else:\n",
    "            mase = np.inf\n",
    "        \n",
    "        # R-squared\n",
    "        ss_res = np.sum(errors**2)\n",
    "        ss_tot = np.sum((actuals - np.mean(actuals))**2)\n",
    "        r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'mape': mape,\n",
    "            'smape': smape,\n",
    "            'theil_u1': theil_u1,\n",
    "            'theil_u2': theil_u2,\n",
    "            'mdape': mdape,\n",
    "            'mase': mase,\n",
    "            'r2': r2\n",
    "        }\n",
    "\n",
    "    def _calculate_fold_statistics(self, fold_metrics_list):\n",
    "        \"\"\"Calculate mean across folds for each metric\"\"\"\n",
    "        metrics_dict = {}\n",
    "        \n",
    "        # Get all metric names\n",
    "        metric_names = fold_metrics_list[0].keys()\n",
    "        \n",
    "        for metric_name in metric_names:\n",
    "            values = [fold_metrics[metric_name] for fold_metrics in fold_metrics_list]\n",
    "            values = np.array(values)\n",
    "            \n",
    "            # Handle infinite values\n",
    "            finite_values = values[np.isfinite(values)]\n",
    "            \n",
    "            if len(finite_values) > 0:\n",
    "                metrics_dict[metric_name] = np.mean(finite_values)\n",
    "            else:\n",
    "                metrics_dict[metric_name] = np.nan\n",
    "        \n",
    "        return metrics_dict\n",
    "\n",
    "    def print_cv_summary(self):\n",
    "        \"\"\"Print cross-validation summary with comprehensive metrics\"\"\"\n",
    "        if not hasattr(self, 'cv_fold_statistics'):\n",
    "            print(\"No cross-validation results available. Run perform_cross_validation() first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*140)\n",
    "        print(\"DSGE-INFORMED DFM CROSS-VALIDATION SUMMARY\")\n",
    "        print(\"=\"*140)\n",
    "        \n",
    "        # Print header\n",
    "        print(f\"{'Variable':<15} {'CV RMSE':<10} {'CV MAE':<10} {'CV MAPE':<10} {'CV SMAPE':<10} {'CV Theil_U1':<12} {'CV Theil_U2':<12} {'CV MdAPE':<10} {'CV MASE':<10} {'CV R¬≤':<8}\")\n",
    "        print(\"-\" * 140)\n",
    "        \n",
    "        # Print results for each variable\n",
    "        for var in self.combined_data.columns:\n",
    "            if var not in self.cv_fold_statistics:\n",
    "                continue\n",
    "                \n",
    "            var_stats = self.cv_fold_statistics[var]\n",
    "            \n",
    "            # Format values, handling NaN and inf\n",
    "            rmse_str = f\"{var_stats['rmse']:.4f}\" if np.isfinite(var_stats['rmse']) else \"NaN\"\n",
    "            mae_str = f\"{var_stats['mae']:.4f}\" if np.isfinite(var_stats['mae']) else \"NaN\"\n",
    "            mape_str = f\"{var_stats['mape']:.2f}\" if np.isfinite(var_stats['mape']) else \"NaN\"\n",
    "            smape_str = f\"{var_stats['smape']:.2f}\" if np.isfinite(var_stats['smape']) else \"NaN\"\n",
    "            theil_u1_str = f\"{var_stats['theil_u1']:.4f}\" if np.isfinite(var_stats['theil_u1']) else \"NaN\"\n",
    "            theil_u2_str = f\"{var_stats['theil_u2']:.4f}\" if np.isfinite(var_stats['theil_u2']) else \"NaN\"\n",
    "            mdape_str = f\"{var_stats['mdape']:.2f}\" if np.isfinite(var_stats['mdape']) else \"NaN\"\n",
    "            mase_str = f\"{var_stats['mase']:.4f}\" if np.isfinite(var_stats['mase']) else \"NaN\"\n",
    "            r2_str = f\"{var_stats['r2']:.3f}\" if np.isfinite(var_stats['r2']) else \"NaN\"\n",
    "            \n",
    "            print(f\"{var:<15} {rmse_str:<10} {mae_str:<10} {mape_str:<10} {smape_str:<10} \"\n",
    "                  f\"{theil_u1_str:<12} {theil_u2_str:<12} {mdape_str:<10} {mase_str:<10} {r2_str:<8}\")\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"DSGE-INFORMED MODEL SUMMARY STATISTICS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Calculate averages across variables\n",
    "        valid_rmse = [stats['rmse'] for stats in self.cv_fold_statistics.values() \n",
    "                     if np.isfinite(stats['rmse'])]\n",
    "        valid_mae = [stats['mae'] for stats in self.cv_fold_statistics.values() \n",
    "                    if np.isfinite(stats['mae'])]\n",
    "        valid_r2 = [stats['r2'] for stats in self.cv_fold_statistics.values() \n",
    "                   if np.isfinite(stats['r2'])]\n",
    "        valid_theil_u1 = [stats['theil_u1'] for stats in self.cv_fold_statistics.values() \n",
    "                          if np.isfinite(stats['theil_u1'])]\n",
    "        valid_theil_u2 = [stats['theil_u2'] for stats in self.cv_fold_statistics.values() \n",
    "                          if np.isfinite(stats['theil_u2'])]\n",
    "        valid_mase = [stats['mase'] for stats in self.cv_fold_statistics.values() \n",
    "                     if np.isfinite(stats['mase'])]\n",
    "        \n",
    "        if valid_rmse:\n",
    "            print(f\"Average CV RMSE: {np.mean(valid_rmse):.4f}\")\n",
    "            print(f\"Median CV RMSE: {np.median(valid_rmse):.4f}\")\n",
    "        if valid_mae:\n",
    "            print(f\"Average CV MAE: {np.mean(valid_mae):.4f}\")\n",
    "        if valid_r2:\n",
    "            print(f\"Average CV R¬≤: {np.mean(valid_r2):.3f}\")\n",
    "        if valid_theil_u1:\n",
    "            print(f\"Average CV Theil's U1: {np.mean(valid_theil_u1):.4f}\")\n",
    "        if valid_theil_u2:\n",
    "            print(f\"Average CV Theil's U2: {np.mean(valid_theil_u2):.4f}\")\n",
    "        if valid_mase:\n",
    "            print(f\"Average CV MASE: {np.mean(valid_mase):.4f}\")\n",
    "            print(f\"Median CV MASE: {np.median(valid_mase):.4f}\")\n",
    "            \n",
    "        print(f\"Variables with valid metrics: {len(self.cv_fold_statistics)}/{len(self.combined_data.columns)}\")\n",
    "        \n",
    "        # Show DSGE influence\n",
    "        if self.dsge_priors is not None:\n",
    "            print(f\"DSGE priors used: {len(self.dsge_priors)} structural parameters\")\n",
    "            print(\"Model uses Bayesian VAR with DSGE-informed coefficient restrictions\")\n",
    "\n",
    "    def run_complete_estimation(self, forecast_horizon=8, run_cv=True):\n",
    "        \"\"\"Run complete DSGE-informed DFM estimation pipeline\"\"\"\n",
    "        print(\"DSGE-INFORMED DYNAMIC FACTOR MODEL - COMPLETE ESTIMATION\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        try:\n",
    "            # Core estimation steps\n",
    "            self.extract_factors_pca()\n",
    "            self.estimate_factor_loadings()\n",
    "            self.estimate_factor_var()\n",
    "\n",
    "            # Forecasting\n",
    "            factor_forecasts = self.forecast_var(forecast_horizon)\n",
    "            variable_forecasts = self.generate_variable_forecasts(forecast_horizon)\n",
    "\n",
    "            # Cross-validation\n",
    "            if run_cv:\n",
    "                cv_results = self.perform_cross_validation(k_folds=5, forecast_horizon=4)\n",
    "                self.print_cv_summary()\n",
    "\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"DSGE-INFORMED DFM ESTIMATION COMPLETED SUCCESSFULLY\")\n",
    "            print(\"=\"*80)\n",
    "\n",
    "            results = {\n",
    "                'factors': self.factors,\n",
    "                'loadings': self.loadings,\n",
    "                'factor_var': self.factor_var,\n",
    "                'factor_forecasts': factor_forecasts,\n",
    "                'variable_forecasts': variable_forecasts\n",
    "            }\n",
    "            \n",
    "            if run_cv:\n",
    "                results['cv_results'] = cv_results\n",
    "\n",
    "            return results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in DSGE-informed DFM estimation: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "\n",
    "\n",
    "def run_econometric_dfm(dsge_posterior_estimates, start_date=\"2000-01-01\", forecast_horizon=8):\n",
    "    \"\"\"\n",
    "    NEW FUNCTION: Run DSGE-informed DFM with structural priors\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dsge_posterior_estimates : dict\n",
    "        Dictionary of DSGE posterior parameter estimates from Document 1\n",
    "        Should contain keys like 'sigma', 'theta', 'phi_pi', 'phi_y', etc.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Prepare data\n",
    "        print(\"PREPARING ECONOMETRIC DATA FOR DSGE-INFORMED DFM\")\n",
    "        print(\"=\" * 60)\n",
    "        organized_blocks, combined_data = prepare_econometric_data(start_date)\n",
    "\n",
    "        # Check data quality\n",
    "        if len(combined_data.columns) < 6:\n",
    "            print(f\"Warning: Only {len(combined_data.columns)} variables available\")\n",
    "\n",
    "        # Initialize DSGE-informed DFM\n",
    "        print(f\"\\nINITIALIZING DSGE-INFORMED DFM\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"DSGE priors available: {list(dsge_posterior_estimates.keys()) if dsge_posterior_estimates else 'None'}\")\n",
    "        \n",
    "        model = EconometricDFM(organized_blocks, combined_data, dsge_priors=dsge_posterior_estimates)\n",
    "\n",
    "        # Run complete estimation\n",
    "        results = model.run_complete_estimation(forecast_horizon)\n",
    "        return model, results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in DSGE-informed DFM: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def run_core_economic_analysis(dsge_posterior_estimates=None, start_date=\"2000-01-01\", forecast_horizon=8):\n",
    "    \"\"\"\n",
    "    NEW MAIN FUNCTION: Run DSGE-informed econometric analysis\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dsge_posterior_estimates : dict, optional\n",
    "        DSGE posterior parameter estimates. If None, runs standard DFM.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"DSGE-INFORMED VAR-DFM ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    if dsge_posterior_estimates is not None:\n",
    "        print(\"Using DSGE-estimated priors for VAR coefficient restrictions\")\n",
    "        model, results = run_econometric_dfm(dsge_posterior_estimates, start_date, forecast_horizon)\n",
    "    else:\n",
    "        print(\"No DSGE priors provided - running standard DFM\")\n",
    "        # Fallback to standard model\n",
    "        organized_blocks, combined_data = prepare_econometric_data(start_date)\n",
    "        model = EconometricDFM(organized_blocks, combined_data, dsge_priors=None)\n",
    "        results = model.run_complete_estimation(forecast_horizon)\n",
    "\n",
    "    if model is not None:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"DSGE-INFORMED ANALYSIS COMPLETED SUCCESSFULLY\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        estimation_type = \"DSGE-Informed Bayesian\" if model.dsge_priors else \"Standard OLS\"\n",
    "        print(f\"Model Summary:\")\n",
    "        print(f\"  ‚Ä¢ {model.N_vars} macroeconomic variables\")\n",
    "        print(f\"  ‚Ä¢ {model.T_obs} quarterly observations\")\n",
    "        print(f\"  ‚Ä¢ {model.n_factors} economic factors extracted\")\n",
    "        print(f\"  ‚Ä¢ VAR({model.factor_var['lags']}) dynamics estimated ({estimation_type})\")\n",
    "        print(f\"  ‚Ä¢ {forecast_horizon} quarter forecasts generated\")\n",
    "\n",
    "        if model.dsge_priors:\n",
    "            print(f\"  ‚Ä¢ DSGE structural priors: {len(model.dsge_priors)} parameters\")\n",
    "\n",
    "        return {\n",
    "            'model': model,\n",
    "            'results': results\n",
    "        }\n",
    "    else:\n",
    "        print(\"Model estimation failed\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXECUTION WITH DSGE PRIORS\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run DSGE-informed analysis\n",
    "    # Replace with:\n",
    "    analysis_results = run_core_economic_analysis(\n",
    "    dsge_posterior_estimates=dsge_posteriors,  # Use actual estimates from Document 1\n",
    "    start_date=\"2000-01-01\",\n",
    "    forecast_horizon=8\n",
    ")\n",
    "\n",
    "    if analysis_results:\n",
    "        model = analysis_results['model']\n",
    "        results = analysis_results['results']\n",
    "        dsge_posterior_estimates=dsge_posteriors\n",
    "        \n",
    "        print(f\"\\nüéØ INTEGRATION SUMMARY:\")\n",
    "        print(f\"   DSGE parameters used: {len(dsge_posteriors)}\")\n",
    "        print(f\"   VAR estimation method: {'Bayesian (DSGE-informed)' if model.dsge_priors else 'OLS'}\")\n",
    "        print(f\"   Model stability: {hasattr(model, 'eigenvalues')}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"DSGE-DFM INTEGRATION COMPLETED SUCCESSFULLY\")\n",
    "        print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced DFM Analysis Components\n",
      "==================================================\n",
      "This module provides advanced analysis for econometric DFM models.\n",
      "\n",
      "Main functions:\n",
      "‚Ä¢ AdvancedDFMAnalyzer: Core advanced analysis class\n",
      "‚Ä¢ run_complete_analysis_with_diagnostics: Full diagnostic pipeline\n",
      "‚Ä¢ enhanced_bootstrap_forecasts: Robust bootstrap forecasting\n",
      "‚Ä¢ stress_test_forecasts: Scenario analysis\n",
      "‚Ä¢ model_selection_criteria: Model comparison\n",
      "‚Ä¢ run_complete_advanced_dfm_analysis: Complete advanced pipeline\n",
      "\n",
      "To use with core model:\n",
      "advanced_results = run_complete_advanced_dfm_analysis(core_analysis_results)\n",
      "DSGE-INFORMED VAR-DFM ANALYSIS\n",
      "================================================================================\n",
      "No DSGE priors provided - running standard DFM\n",
      "Fetching economic data from FRED...\n",
      "\n",
      "Fetching Demand_Block:\n",
      "Failed to fetch GDPC1: <urlopen error [Errno 8] nodename nor servname provided, or not known>\n",
      "  GDPC1 ‚úó\n",
      "Failed to fetch PAYEMS: <urlopen error [Errno 8] nodename nor servname provided, or not known>\n",
      "  PAYEMS ‚úó\n",
      "Failed to fetch INDPRO: <urlopen error [Errno 8] nodename nor servname provided, or not known>\n",
      "  INDPRO ‚úó\n",
      "Failed to fetch ICSA: <urlopen error [Errno 8] nodename nor servname provided, or not known>\n",
      "  ICSA ‚úó\n",
      "\n",
      "Fetching Supply_Block:\n",
      "Failed to fetch CPIAUCSL: <urlopen error [Errno 8] nodename nor servname provided, or not known>\n",
      "  CPIAUCSL ‚úó\n",
      "Failed to fetch PCEPI: <urlopen error [Errno 8] nodename nor servname provided, or not known>\n",
      "  PCEPI ‚úó\n",
      "Failed to fetch AHETPI: <urlopen error [Errno 8] nodename nor servname provided, or not known>\n",
      "  AHETPI ‚úó\n",
      "Failed to fetch DCOILWTICO: <urlopen error [Errno 8] nodename nor servname provided, or not known>\n",
      "  DCOILWTICO ‚úó\n",
      "\n",
      "Fetching Monetary_Block:\n",
      "Failed to fetch FEDFUNDS: <urlopen error [Errno 8] nodename nor servname provided, or not known>\n",
      "  FEDFUNDS ‚úó\n",
      "Failed to fetch DGS10: <urlopen error [Errno 8] nodename nor servname provided, or not known>\n",
      "  DGS10 ‚úó\n",
      "Failed to fetch M2SL: <urlopen error [Errno 8] nodename nor servname provided, or not known>\n",
      "  M2SL ‚úó\n",
      "Failed to fetch AAA: <urlopen error [Errno 8] nodename nor servname provided, or not known>\n",
      "  AAA ‚úó\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only 0 series fetched. Need at least 8.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1041\u001b[0m\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madvanced_results = run_complete_advanced_dfm_analysis(core_analysis_results)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m# EXECUTION\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m# After running your core estimation:\u001b[39;00m\n\u001b[0;32m-> 1041\u001b[0m core_results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_core_economic_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;66;03m# Run advanced analysis:\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m advanced_results \u001b[38;5;241m=\u001b[39m run_complete_advanced_dfm_analysis(core_results)\n",
      "Cell \u001b[0;32mIn[4], line 1190\u001b[0m, in \u001b[0;36mrun_core_economic_analysis\u001b[0;34m(dsge_posterior_estimates, start_date, forecast_horizon)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo DSGE priors provided - running standard DFM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# Fallback to standard model\u001b[39;00m\n\u001b[0;32m-> 1190\u001b[0m organized_blocks, combined_data \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_econometric_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m model \u001b[38;5;241m=\u001b[39m EconometricDFM(organized_blocks, combined_data, dsge_priors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1192\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mrun_complete_estimation(forecast_horizon)\n",
      "Cell \u001b[0;32mIn[4], line 64\u001b[0m, in \u001b[0;36mprepare_econometric_data\u001b[0;34m(start_date)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseries_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ‚úó\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(all_series) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m8\u001b[39m:  \u001b[38;5;66;03m# Need most variables for robust estimation\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_series)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m series fetched. Need at least 8.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSuccessfully fetched \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_series)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Find common time range\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Only 0 series fetched. Need at least 8."
     ]
    }
   ],
   "source": [
    "# Advanced Analysis and Visualization Components for Econometric DFM\n",
    "# This extends the core model estimation with comprehensive diagnostics and analysis\n",
    "\n",
    "class AdvancedDFMAnalyzer:\n",
    "    \"\"\"\n",
    "    Advanced analysis components for the Econometric DFM\n",
    "\n",
    "    This class extends the core EconometricDFM with:\n",
    "    - Comprehensive VAR diagnostics\n",
    "    - Impulse response functions\n",
    "    - Historical decomposition\n",
    "    - Forecast quality assessment\n",
    "    - Advanced visualization\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dfm_model):\n",
    "        \"\"\"Initialize with a fitted EconometricDFM model\"\"\"\n",
    "        self.model = dfm_model\n",
    "        self.impulse_responses = None\n",
    "        self.historical_decomp = None\n",
    "\n",
    "    def enhanced_var_diagnostics(self):\n",
    "        \"\"\"Run comprehensive VAR model diagnostics\"\"\"\n",
    "        print(f\"\\nVAR Model Diagnostics (Enhanced):\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        var_result = self.model.factor_var\n",
    "        u = var_result['residuals']\n",
    "        T_eff, K = u.shape\n",
    "\n",
    "        # Portmanteau test for serial correlation\n",
    "        max_lag_test = min(8, T_eff // 4)\n",
    "        lm_stat = self._portmanteau_test(u, max_lag_test)\n",
    "        lm_pval = 1 - chi2.cdf(lm_stat, df=K**2 * max_lag_test)\n",
    "\n",
    "        print(f\"  Portmanteau test (lag {max_lag_test}): {lm_stat:.2f} (p-val: {lm_pval:.3f})\")\n",
    "        print(f\"  Serial correlation: {'Not detected' if lm_pval > 0.05 else 'Detected'} \"\n",
    "              f\"{'‚úì' if lm_pval > 0.05 else '‚úó'}\")\n",
    "\n",
    "        # Normality test (Jarque-Bera for each equation)\n",
    "        jb_stats = []\n",
    "        for k in range(K):\n",
    "            resid_k = u[:, k]\n",
    "            # Simplified JB test\n",
    "            skew = np.mean(((resid_k - np.mean(resid_k)) / np.std(resid_k))**3)\n",
    "            kurt = np.mean(((resid_k - np.mean(resid_k)) / np.std(resid_k))**4) - 3\n",
    "            jb_k = T_eff / 6 * (skew**2 + kurt**2 / 4)\n",
    "            jb_stats.append(jb_k)\n",
    "\n",
    "        avg_jb = np.mean(jb_stats)\n",
    "        print(f\"  Average Jarque-Bera: {avg_jb:.2f}\")\n",
    "\n",
    "        # Factor persistence (AR(1) diagonal elements)\n",
    "        if var_result['lags'] >= 1:\n",
    "            AR1_diag = np.diag(var_result['coefficients'][:, :K])\n",
    "            print(f\"  Factor persistence:\")\n",
    "            for i, factor_name in enumerate(self.model.factors.columns):\n",
    "                pers = AR1_diag[i] if i < len(AR1_diag) else 0\n",
    "                print(f\"    {factor_name}: {pers:.3f}\")\n",
    "\n",
    "        # Residual correlations\n",
    "        residual_corr = np.corrcoef(u.T)\n",
    "        off_diag_corr = np.abs(residual_corr[np.triu_indices_from(residual_corr, k=1)])\n",
    "        avg_cross_corr = np.mean(off_diag_corr)\n",
    "        print(f\"  Average cross-correlation of residuals: {avg_cross_corr:.3f}\")\n",
    "\n",
    "    def _portmanteau_test(self, residuals, max_lag):\n",
    "        \"\"\"Portmanteau test for serial correlation (Ljung-Box type)\"\"\"\n",
    "        T, K = residuals.shape\n",
    "\n",
    "        # Calculate sample autocorrelations\n",
    "        autocorrs = []\n",
    "        for lag in range(1, max_lag + 1):\n",
    "            if T > lag:\n",
    "                resid_lagged = residuals[:-lag, :]\n",
    "                resid_current = residuals[lag:, :]\n",
    "\n",
    "                # Cross-correlation matrix at lag h\n",
    "                C_h = np.cov(resid_current.T, resid_lagged.T)[:K, K:]\n",
    "                C_0 = np.cov(residuals.T)\n",
    "\n",
    "                # Normalized autocorrelation\n",
    "                rho_h = np.linalg.solve(C_0, C_h) @ np.linalg.solve(C_0, C_h.T)\n",
    "                autocorrs.append(np.trace(rho_h))\n",
    "\n",
    "        # Ljung-Box statistic (simplified)\n",
    "        lm_stat = T * (T + 2) * sum(autocorr / (T - lag - 1)\n",
    "                                   for lag, autocorr in enumerate(autocorrs, 1))\n",
    "\n",
    "        return lm_stat\n",
    "\n",
    "    def enhanced_forecast_quality(self):\n",
    "        \"\"\"Enhanced forecast quality and continuity assessment\"\"\"\n",
    "        print(\"\\nEnhanced Forecast Quality Assessment:\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # Check forecast continuity (no large jumps)\n",
    "        continuity_issues = 0\n",
    "\n",
    "        for var in self.model.combined_data.columns:\n",
    "            last_actual = self.model.combined_data[var].iloc[-1]\n",
    "            first_forecast = self.model.variable_forecasts['mean'][var].iloc[0]\n",
    "\n",
    "            # Historical volatility for jump assessment\n",
    "            var_changes = self.model.combined_data[var].diff().dropna()\n",
    "            typical_change = var_changes.std()\n",
    "\n",
    "            jump_size = abs(first_forecast - last_actual)\n",
    "            jump_ratio = jump_size / typical_change if typical_change > 0 else 0\n",
    "\n",
    "            is_continuous = jump_ratio < 3.0  # Allow up to 3 standard deviations\n",
    "\n",
    "            if not is_continuous:\n",
    "                continuity_issues += 1\n",
    "\n",
    "            print(f\"{var:<12}: Jump={jump_size:7.2f} ({jump_ratio:.1f}œÉ) \"\n",
    "                  f\"{'‚úì' if is_continuous else '‚úó'}\")\n",
    "\n",
    "        print(f\"\\nContinuity assessment: {self.model.N_vars - continuity_issues}/{self.model.N_vars} variables pass\")\n",
    "\n",
    "        # Factor forecast consistency check\n",
    "        print(f\"\\nFactor Forecast Consistency:\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        for factor in self.model.factors.columns:\n",
    "            factor_std = self.model.factors[factor].std()\n",
    "            forecast_range = (self.model.factor_forecasts['mean'][factor].max() -\n",
    "                            self.model.factor_forecasts['mean'][factor].min())\n",
    "            consistency_ratio = forecast_range / (4 * factor_std)  # 4 std as reasonable range\n",
    "\n",
    "            print(f\"{factor}: Range ratio = {consistency_ratio:.2f} \"\n",
    "                  f\"{'‚úì' if consistency_ratio < 1.5 else '‚ö†' if consistency_ratio < 2.5 else '‚úó'}\")\n",
    "\n",
    "    def compute_impulse_responses(self, horizon=20, orthogonalize=True):\n",
    "        \"\"\"\n",
    "        Compute impulse response functions with proper identification\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"IMPULSE RESPONSE FUNCTION ANALYSIS\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        if self.model.factor_var is None:\n",
    "            raise ValueError(\"Must estimate VAR model first\")\n",
    "\n",
    "        Phi = self.model.factor_var['coefficients']\n",
    "        Sigma = self.model.factor_var['sigma_u']\n",
    "        p = self.model.factor_var['lags']\n",
    "        K = Phi.shape[0]\n",
    "\n",
    "        # Shock identification\n",
    "        if orthogonalize:\n",
    "            try:\n",
    "                # Cholesky decomposition for recursive identification\n",
    "                P = np.linalg.cholesky(Sigma)  # Lower triangular\n",
    "                shock_names = [f'{name} (Orthogonal)' for name in self.model.factors.columns]\n",
    "                print(\"Using Cholesky decomposition for orthogonal shocks\")\n",
    "                print(\"Ordering: Demand ‚Üí Supply ‚Üí Monetary\")\n",
    "            except np.linalg.LinAlgError:\n",
    "                print(\"Warning: Cholesky decomposition failed, using identity matrix\")\n",
    "                P = np.eye(K)\n",
    "                shock_names = [f'{name} (Raw)' for name in self.model.factors.columns]\n",
    "        else:\n",
    "            P = np.eye(K)\n",
    "            shock_names = [f'{name} (Raw)' for name in self.model.factors.columns]\n",
    "\n",
    "        # Compute IRFs\n",
    "        irfs = np.zeros((horizon, K, K))  # horizon x responses x shocks\n",
    "\n",
    "        for shock_idx in range(K):\n",
    "            # Unit shock vector\n",
    "            shock_vector = P[:, shock_idx]\n",
    "\n",
    "            # Compute response over horizon\n",
    "            for h in range(horizon):\n",
    "                if h == 0:\n",
    "                    irfs[h, :, shock_idx] = shock_vector\n",
    "                else:\n",
    "                    if p == 1:\n",
    "                        irfs[h, :, shock_idx] = Phi @ irfs[h-1, :, shock_idx]\n",
    "                    else:\n",
    "                        # Use companion matrix for VAR(p)\n",
    "                        if h == 1:\n",
    "                            # First period response\n",
    "                            extended_shock = np.zeros(self.model.companion_matrix.shape[0])\n",
    "                            extended_shock[:K] = shock_vector\n",
    "                            response = self.model.companion_matrix @ extended_shock\n",
    "                            irfs[h, :, shock_idx] = response[:K]\n",
    "                        else:\n",
    "                            # Subsequent periods\n",
    "                            prev_extended = np.zeros(self.model.companion_matrix.shape[0])\n",
    "                            prev_extended[:K] = irfs[h-1, :, shock_idx]\n",
    "                            response = self.model.companion_matrix @ prev_extended\n",
    "                            irfs[h, :, shock_idx] = response[:K]\n",
    "\n",
    "        self.impulse_responses = {\n",
    "            'irfs': irfs,\n",
    "            'shock_names': shock_names,\n",
    "            'response_names': list(self.model.factors.columns),\n",
    "            'horizon': horizon,\n",
    "            'identification_matrix': P\n",
    "        }\n",
    "\n",
    "        # Print summary statistics\n",
    "        print(f\"Computed {K}x{K} impulse responses over {horizon} periods\")\n",
    "\n",
    "        # Peak responses\n",
    "        print(f\"\\nPeak Response Analysis:\")\n",
    "        for i, response_name in enumerate(self.model.factors.columns):\n",
    "            for j, shock_name in enumerate(shock_names):\n",
    "                irf_series = irfs[:, i, j]\n",
    "                peak_period = np.argmax(np.abs(irf_series))\n",
    "                peak_value = irf_series[peak_period]\n",
    "                print(f\"  {response_name} ‚Üí {shock_name}: Peak = {peak_value:.3f} at period {peak_period}\")\n",
    "\n",
    "        return self.impulse_responses\n",
    "\n",
    "    def plot_impulse_responses(self):\n",
    "        \"\"\"Plot impulse response functions\"\"\"\n",
    "        if self.impulse_responses is None:\n",
    "            self.compute_impulse_responses()\n",
    "\n",
    "        irfs = self.impulse_responses['irfs']\n",
    "        shock_names = self.impulse_responses['shock_names']\n",
    "        response_names = self.impulse_responses['response_names']\n",
    "        horizon = self.impulse_responses['horizon']\n",
    "\n",
    "        fig, axes = plt.subplots(len(response_names), len(shock_names),\n",
    "                                figsize=(5*len(shock_names), 4*len(response_names)))\n",
    "\n",
    "        if len(response_names) == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        if len(shock_names) == 1:\n",
    "            axes = axes.reshape(-1, 1)\n",
    "\n",
    "        for i, response_name in enumerate(response_names):\n",
    "            for j, shock_name in enumerate(shock_names):\n",
    "                ax = axes[i, j] if len(response_names) > 1 else axes[j]\n",
    "\n",
    "                irf_series = irfs[:, i, j]\n",
    "                periods = range(horizon)\n",
    "\n",
    "                ax.plot(periods, irf_series, linewidth=2, color=f'C{j}')\n",
    "                ax.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "                ax.set_title(f'{response_name} ‚Üí {shock_name}', fontsize=10)\n",
    "                ax.grid(True, alpha=0.3)\n",
    "                ax.set_xlabel('Quarters')\n",
    "\n",
    "        plt.suptitle('Impulse Response Functions', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def historical_decomposition(self, periods_back=40):\n",
    "        \"\"\"Compute historical decomposition of factors\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"HISTORICAL DECOMPOSITION\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        if self.model.factor_var is None:\n",
    "            raise ValueError(\"Must estimate VAR model first\")\n",
    "\n",
    "        residuals = self.model.factor_var['residuals']\n",
    "        Phi = self.model.factor_var['coefficients']\n",
    "        c = self.model.factor_var['constant']\n",
    "        p = self.model.factor_var['lags']\n",
    "        K = Phi.shape[0]\n",
    "\n",
    "        T_residuals = len(residuals)\n",
    "        periods = min(periods_back, T_residuals)\n",
    "\n",
    "        # Use Cholesky identification for decomposition\n",
    "        try:\n",
    "            P = np.linalg.cholesky(self.model.factor_var['sigma_u'])\n",
    "            orthogonal_residuals = np.linalg.solve(P, residuals.T).T\n",
    "        except:\n",
    "            P = np.eye(K)\n",
    "            orthogonal_residuals = residuals\n",
    "\n",
    "        # Initialize decomposition arrays\n",
    "        historical_decomp = np.zeros((periods, K, K))  # periods x factors x shocks\n",
    "\n",
    "        # Compute decomposition recursively\n",
    "        for t in range(periods):\n",
    "            time_idx = T_residuals - periods + t\n",
    "\n",
    "            for shock_idx in range(K):\n",
    "                if t == 0:\n",
    "                    # Initial impact\n",
    "                    historical_decomp[t, :, shock_idx] = orthogonal_residuals[time_idx, shock_idx] * P[:, shock_idx]\n",
    "                else:\n",
    "                    # Propagated impact from previous period\n",
    "                    if p == 1:\n",
    "                        historical_decomp[t, :, shock_idx] = (\n",
    "                            Phi @ historical_decomp[t-1, :, shock_idx] +\n",
    "                            orthogonal_residuals[time_idx, shock_idx] * P[:, shock_idx]\n",
    "                        )\n",
    "                    else:\n",
    "                        # For VAR(p), use companion form (simplified)\n",
    "                        historical_decomp[t, :, shock_idx] = (\n",
    "                            Phi[:, :K] @ historical_decomp[t-1, :, shock_idx] +\n",
    "                            orthogonal_residuals[time_idx, shock_idx] * P[:, shock_idx]\n",
    "                        )\n",
    "\n",
    "        # Store results\n",
    "        decomp_dates = self.model.factors.index[-periods:]\n",
    "\n",
    "        self.historical_decomp = {\n",
    "            'contributions': historical_decomp,\n",
    "            'dates': decomp_dates,\n",
    "            'shock_names': ['Demand', 'Supply', 'Monetary'][:K],\n",
    "            'factor_names': list(self.model.factors.columns)\n",
    "        }\n",
    "\n",
    "        print(f\"Computed historical decomposition for {periods} periods\")\n",
    "        return self.historical_decomp\n",
    "\n",
    "    def plot_historical_decomposition(self):\n",
    "        \"\"\"Plot historical decomposition\"\"\"\n",
    "        if self.historical_decomp is None:\n",
    "            self.historical_decomposition()\n",
    "\n",
    "        decomp = self.historical_decomp['contributions']\n",
    "        dates = self.historical_decomp['dates']\n",
    "        shock_names = self.historical_decomp['shock_names']\n",
    "        factor_names = self.historical_decomp['factor_names']\n",
    "\n",
    "        fig, axes = plt.subplots(len(factor_names), 1, figsize=(15, 4*len(factor_names)))\n",
    "\n",
    "        if len(factor_names) == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        colors = ['blue', 'red', 'green']\n",
    "\n",
    "        for factor_idx, factor_name in enumerate(factor_names):\n",
    "            ax = axes[factor_idx]\n",
    "\n",
    "            # Plot contributions from each shock\n",
    "            bottom_pos = np.zeros(len(dates))\n",
    "            bottom_neg = np.zeros(len(dates))\n",
    "\n",
    "            for shock_idx, shock_name in enumerate(shock_names):\n",
    "                contributions = decomp[:, factor_idx, shock_idx]\n",
    "\n",
    "                # Separate positive and negative contributions\n",
    "                pos_contrib = np.maximum(contributions, 0)\n",
    "                neg_contrib = np.minimum(contributions, 0)\n",
    "\n",
    "                # Stack positive contributions upward\n",
    "                ax.fill_between(dates, bottom_pos, bottom_pos + pos_contrib,\n",
    "                               label=f'{shock_name} (+)', alpha=0.7, color=colors[shock_idx % len(colors)])\n",
    "                bottom_pos += pos_contrib\n",
    "\n",
    "                # Stack negative contributions downward\n",
    "                ax.fill_between(dates, bottom_neg, bottom_neg + neg_contrib,\n",
    "                               alpha=0.7, color=colors[shock_idx % len(colors)])\n",
    "                bottom_neg += neg_contrib\n",
    "\n",
    "            # Add actual factor values for comparison\n",
    "            factor_actual = self.model.factors[factor_name].iloc[-len(dates):].values\n",
    "            ax.plot(dates, factor_actual, color='black', linewidth=2, label='Actual')\n",
    "\n",
    "            ax.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "            ax.set_title(f'{factor_name} - Historical Decomposition')\n",
    "            ax.legend(loc='upper left')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "        plt.suptitle('Historical Shock Decomposition', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_comprehensive_results(self):\n",
    "        \"\"\"Comprehensive visualization of all DFM results\"\"\"\n",
    "        fig = plt.figure(figsize=(20, 16))\n",
    "        gs = fig.add_gridspec(4, 3, hspace=0.4, wspace=0.3)\n",
    "\n",
    "        # Row 1: Factor time series with forecasts\n",
    "        for i, factor in enumerate(self.model.factors.columns):\n",
    "            ax = fig.add_subplot(gs[0, i])\n",
    "\n",
    "            # Historical factors\n",
    "            ax.plot(self.model.factors.index, self.model.factors[factor],\n",
    "                   linewidth=2, color=f'C{i}', label='Historical')\n",
    "\n",
    "            # Add forecasts if available\n",
    "            if hasattr(self.model, 'factor_forecasts'):\n",
    "                forecast_mean = self.model.factor_forecasts['mean'][factor]\n",
    "\n",
    "                ax.plot(forecast_mean.index, forecast_mean,\n",
    "                       color=f'C{i}', linewidth=2, linestyle='--', label='Forecast')\n",
    "\n",
    "                # Bootstrap confidence intervals\n",
    "                if 'bootstrap_lower' in self.model.factor_forecasts:\n",
    "                    lower = self.model.factor_forecasts['bootstrap_lower'][factor]\n",
    "                    upper = self.model.factor_forecasts['bootstrap_upper'][factor]\n",
    "                    ax.fill_between(forecast_mean.index, lower, upper,\n",
    "                                   color=f'C{i}', alpha=0.2, label='95% CI')\n",
    "\n",
    "                # Mark forecast start\n",
    "                ax.axvline(x=self.model.factors.index[-1], color='red', linestyle=':', alpha=0.7)\n",
    "\n",
    "            ax.set_title(f'{factor}', fontsize=12, fontweight='bold')\n",
    "            ax.legend(fontsize=8)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "        # Row 2: Factor loadings heatmap\n",
    "        ax_loadings = fig.add_subplot(gs[1, :])\n",
    "\n",
    "        # Create enhanced heatmap\n",
    "        loadings_matrix = self.model.loadings.values.T\n",
    "        im = ax_loadings.imshow(loadings_matrix, aspect='auto', cmap='RdBu_r',\n",
    "                               vmin=-np.max(np.abs(loadings_matrix)),\n",
    "                               vmax=np.max(np.abs(loadings_matrix)))\n",
    "\n",
    "        ax_loadings.set_title('Factor Loading Matrix', fontsize=14, fontweight='bold')\n",
    "        ax_loadings.set_xticks(range(len(self.model.loadings.index)))\n",
    "        ax_loadings.set_xticklabels(self.model.loadings.index, rotation=45, ha='right')\n",
    "        ax_loadings.set_yticks(range(len(self.model.loadings.columns)))\n",
    "        ax_loadings.set_yticklabels(self.model.loadings.columns)\n",
    "\n",
    "        # Add value annotations\n",
    "        for i in range(loadings_matrix.shape[0]):\n",
    "            for j in range(loadings_matrix.shape[1]):\n",
    "                text_color = 'white' if abs(loadings_matrix[i, j]) > 0.5 else 'black'\n",
    "                ax_loadings.text(j, i, f'{loadings_matrix[i, j]:.2f}',\n",
    "                               ha=\"center\", va=\"center\", color=text_color, fontsize=8)\n",
    "\n",
    "        plt.colorbar(im, ax=ax_loadings, orientation='horizontal', pad=0.1, label='Loading Magnitude')\n",
    "\n",
    "        # Row 3: VAR diagnostics\n",
    "        ax_stability = fig.add_subplot(gs[2, 0])\n",
    "        if hasattr(self.model, 'eigenvalues'):\n",
    "            # Plot eigenvalues in complex plane\n",
    "            real_parts = np.real(self.model.eigenvalues)\n",
    "            imag_parts = np.imag(self.model.eigenvalues)\n",
    "\n",
    "            ax_stability.scatter(real_parts, imag_parts, s=50, alpha=0.7)\n",
    "\n",
    "            # Unit circle\n",
    "            theta = np.linspace(0, 2*np.pi, 100)\n",
    "            ax_stability.plot(np.cos(theta), np.sin(theta), 'r--', alpha=0.5, label='Unit Circle')\n",
    "\n",
    "            ax_stability.set_xlabel('Real Part')\n",
    "            ax_stability.set_ylabel('Imaginary Part')\n",
    "            ax_stability.set_title('VAR Eigenvalues')\n",
    "            ax_stability.legend()\n",
    "            ax_stability.grid(True, alpha=0.3)\n",
    "            ax_stability.axis('equal')\n",
    "\n",
    "        # Row 3: Model fit (R-squared)\n",
    "        ax_fit = fig.add_subplot(gs[2, 1])\n",
    "        if hasattr(self.model, 'variable_forecasts'):\n",
    "            # Calculate R-squared from factor model\n",
    "            r_squared = []\n",
    "            for var in self.model.combined_data.columns:\n",
    "                X_actual = self.model.data_standardized[var].values\n",
    "                F_values = self.model.factors.values\n",
    "                loadings_var = self.model.loadings.loc[var].values\n",
    "\n",
    "                X_fitted = F_values @ loadings_var\n",
    "                ss_res = np.sum((X_actual - X_fitted)**2)\n",
    "                ss_tot = np.sum((X_actual - np.mean(X_actual))**2)\n",
    "                r_sq = 1 - ss_res / ss_tot if ss_tot > 0 else 0\n",
    "                r_squared.append(r_sq)\n",
    "\n",
    "            bars = ax_fit.bar(range(len(r_squared)), r_squared, color='steelblue', alpha=0.7)\n",
    "            ax_fit.set_title('Model Fit (R¬≤)')\n",
    "            ax_fit.set_xticks(range(len(r_squared)))\n",
    "            ax_fit.set_xticklabels(self.model.combined_data.columns, rotation=45, ha='right')\n",
    "            ax_fit.set_ylabel('R¬≤')\n",
    "            ax_fit.set_ylim(0, 1)\n",
    "            ax_fit.grid(True, alpha=0.3)\n",
    "\n",
    "            # Add value labels on bars\n",
    "            for bar, r2 in zip(bars, r_squared):\n",
    "                ax_fit.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                           f'{r2:.2f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "        # Row 3: Forecast continuity assessment\n",
    "        ax_continuity = fig.add_subplot(gs[2, 2])\n",
    "        if hasattr(self.model, 'variable_forecasts'):\n",
    "            # Check forecast jumps\n",
    "            jump_ratios = []\n",
    "            for var in self.model.combined_data.columns:\n",
    "                last_actual = self.model.combined_data[var].iloc[-1]\n",
    "                first_forecast = self.model.variable_forecasts['mean'][var].iloc[0]\n",
    "                var_changes = self.model.combined_data[var].diff().dropna()\n",
    "                typical_change = var_changes.std()\n",
    "                jump_size = abs(first_forecast - last_actual)\n",
    "                jump_ratio = jump_size / typical_change if typical_change > 0 else 0\n",
    "                jump_ratios.append(jump_ratio)\n",
    "\n",
    "            bars = ax_continuity.bar(range(len(jump_ratios)), jump_ratios,\n",
    "                                   color='green' if all(jr < 3 for jr in jump_ratios) else 'orange', alpha=0.7)\n",
    "            ax_continuity.set_title('Forecast Continuity\\n(Jump size / Historical œÉ)')\n",
    "            ax_continuity.set_xticks(range(len(jump_ratios)))\n",
    "            ax_continuity.set_xticklabels(self.model.combined_data.columns, rotation=45, ha='right')\n",
    "            ax_continuity.set_ylabel('Jump Ratio')\n",
    "            ax_continuity.axhline(y=3, color='red', linestyle='--', alpha=0.7, label='Warning threshold')\n",
    "            ax_continuity.legend()\n",
    "            ax_continuity.grid(True, alpha=0.3)\n",
    "\n",
    "        # Row 4: Variable forecasts (selected key variables)\n",
    "        key_variables = ['GDPC1', 'CPIAUCSL', 'FEDFUNDS'] if all(v in self.model.combined_data.columns for v in ['GDPC1', 'CPIAUCSL', 'FEDFUNDS']) else self.model.combined_data.columns[:3]\n",
    "\n",
    "        for i, var in enumerate(key_variables):\n",
    "            if i >= 3:\n",
    "                break\n",
    "\n",
    "            ax = fig.add_subplot(gs[3, i])\n",
    "\n",
    "            # Historical data\n",
    "            hist_data = self.model.combined_data[var]\n",
    "            ax.plot(hist_data.index, hist_data, color='black', linewidth=1.5, label='Historical')\n",
    "\n",
    "            # Forecasts with uncertainty\n",
    "            if hasattr(self.model, 'variable_forecasts'):\n",
    "                forecast_mean = self.model.variable_forecasts['mean'][var]\n",
    "\n",
    "                ax.plot(forecast_mean.index, forecast_mean,\n",
    "                       color='blue', linewidth=2, linestyle='--', label='Forecast')\n",
    "\n",
    "                # Mark forecast start\n",
    "                ax.axvline(x=hist_data.index[-1], color='red', linestyle=':', alpha=0.7)\n",
    "\n",
    "            ax.set_title(f'{var} - Forecast', fontweight='bold')\n",
    "            ax.legend(fontsize=8)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "        plt.suptitle('Econometric Dynamic Factor Model - Complete Analysis',\n",
    "                     fontsize=16, fontweight='bold', y=0.98)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def run_complete_analysis_with_diagnostics(core_model):\n",
    "    \"\"\"\n",
    "    Run complete advanced analysis on a fitted core model\n",
    "\n",
    "    Parameters:\n",
    "    - core_model: Fitted EconometricDFM instance from core estimation\n",
    "\n",
    "    Returns:\n",
    "    - Advanced analyzer with all diagnostics computed\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RUNNING ADVANCED ANALYSIS AND DIAGNOSTICS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Initialize advanced analyzer\n",
    "    analyzer = AdvancedDFMAnalyzer(core_model)\n",
    "\n",
    "    # Run comprehensive diagnostics\n",
    "    print(\"\\n1. Enhanced VAR Diagnostics\")\n",
    "    analyzer.enhanced_var_diagnostics()\n",
    "\n",
    "    print(\"\\n2. Enhanced Forecast Quality Assessment\")\n",
    "    analyzer.enhanced_forecast_quality()\n",
    "\n",
    "    # Advanced structural analysis\n",
    "    print(\"\\n3. Impulse Response Functions\")\n",
    "    analyzer.compute_impulse_responses(horizon=20, orthogonalize=True)\n",
    "\n",
    "    print(\"\\n4. Historical Decomposition\")\n",
    "    analyzer.historical_decomposition(periods_back=min(40, core_model.T_obs//2))\n",
    "\n",
    "    # Comprehensive visualization\n",
    "    print(\"\\n5. Generating Comprehensive Plots\")\n",
    "    analyzer.plot_impulse_responses()\n",
    "    analyzer.plot_historical_decomposition()\n",
    "    analyzer.plot_comprehensive_results()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ADVANCED ANALYSIS COMPLETED\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    return analyzer\n",
    "\n",
    "\n",
    "# Example usage function\n",
    "def complete_dfm_pipeline_with_advanced_analysis(start_date=\"2000-01-01\", forecast_horizon=8):\n",
    "    \"\"\"\n",
    "    Complete DFM pipeline combining core estimation with advanced analysis\n",
    "\n",
    "    This function:\n",
    "    1. Runs the core model estimation\n",
    "    2. Applies all advanced diagnostics and analysis\n",
    "    3. Generates comprehensive visualizations\n",
    "\n",
    "    Returns both the core model and advanced analyzer\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"COMPLETE ECONOMETRIC DFM PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Step 1: Run core estimation (assumes you have the core functions available)\n",
    "    # This would use your core estimation code\n",
    "    print(\"Step 1: Running Core Model Estimation...\")\n",
    "\n",
    "    # Step 2: Advanced analysis\n",
    "    print(\"Step 2: Running Advanced Analysis...\")\n",
    "    # analyzer = run_complete_analysis_with_diagnostics(core_model)\n",
    "\n",
    "    print(\"Complete pipeline finished!\")\n",
    "\n",
    "    return None  # Would return (core_model, analyzer)\n",
    "\n",
    "\n",
    "# Additional utility functions for enhanced analysis\n",
    "\n",
    "def compare_forecast_scenarios(model, scenarios={'baseline': {}, 'stressed': {'shock_scale': 2.0}}):\n",
    "    \"\"\"Compare forecasts under different scenarios\"\"\"\n",
    "    print(\"\\nForecast Scenario Comparison\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    scenario_results = {}\n",
    "\n",
    "    for scenario_name, scenario_params in scenarios.items():\n",
    "        print(f\"\\nRunning {scenario_name} scenario...\")\n",
    "\n",
    "        # This would modify the model parameters according to scenario\n",
    "        # and re-run forecasts\n",
    "        scenario_results[scenario_name] = {\n",
    "            'forecasts': model.factor_forecasts['mean'].copy()\n",
    "        }\n",
    "\n",
    "    return scenario_results\n",
    "\n",
    "\n",
    "def generate_forecast_report(model, analyzer):\n",
    "    \"\"\"Generate a comprehensive forecast report\"\"\"\n",
    "\n",
    "    report = {\n",
    "        'model_summary': {\n",
    "            'n_variables': model.N_vars,\n",
    "            'n_observations': model.T_obs,\n",
    "            'n_factors': model.n_factors,\n",
    "            'var_lags': model.factor_var['lags'],\n",
    "            'stability': hasattr(model, 'eigenvalues') and np.max(np.abs(model.eigenvalues)) < 1.0\n",
    "        },\n",
    "        'factor_persistence': {},\n",
    "        'forecast_summary': {},\n",
    "        'diagnostics': {}\n",
    "    }\n",
    "\n",
    "    # Add factor persistence\n",
    "    if model.factor_var['lags'] >= 1:\n",
    "        AR1_diag = np.diag(model.factor_var['coefficients'][:, :model.n_factors])\n",
    "        for i, factor_name in enumerate(model.factors.columns):\n",
    "            if i < len(AR1_diag):\n",
    "                report['factor_persistence'][factor_name] = AR1_diag[i]\n",
    "\n",
    "    # Forecast summary statistics\n",
    "    for factor in model.factors.columns:\n",
    "        if hasattr(model, 'factor_forecasts'):\n",
    "            factor_forecast = model.factor_forecasts['mean'][factor]\n",
    "            report['forecast_summary'][factor] = {\n",
    "                'mean_forecast': factor_forecast.mean(),\n",
    "                'forecast_volatility': factor_forecast.std(),\n",
    "                'trend': 'increasing' if factor_forecast.iloc[-1] > factor_forecast.iloc[0] else 'decreasing'\n",
    "            }\n",
    "\n",
    "    return report\n",
    "\n",
    "\n",
    "def enhanced_bootstrap_forecasts(model, horizon=8, n_bootstrap=2000, confidence_levels=[0.68, 0.90, 0.95]):\n",
    "    \"\"\"\n",
    "    Enhanced bootstrap forecasting with multiple confidence levels and scenario analysis\n",
    "    \"\"\"\n",
    "    print(f\"\\nEnhanced Bootstrap Forecasting\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    Phi = model.factor_var['coefficients']\n",
    "    c = model.factor_var['constant']\n",
    "    residuals = model.factor_var['residuals']\n",
    "    p = model.factor_var['lags']\n",
    "    K = Phi.shape[0]\n",
    "\n",
    "    # Multiple bootstrap samples for robust inference\n",
    "    bootstrap_paths = np.zeros((n_bootstrap, horizon, K))\n",
    "\n",
    "    print(f\"Running {n_bootstrap} bootstrap replications...\")\n",
    "\n",
    "    for b in range(n_bootstrap):\n",
    "        if b % 500 == 0:\n",
    "            print(f\"  Bootstrap replication {b}/{n_bootstrap}\")\n",
    "\n",
    "        # Resample residuals with replacement\n",
    "        boot_indices = np.random.choice(len(residuals), size=horizon, replace=True)\n",
    "        boot_residuals = residuals[boot_indices, :]\n",
    "\n",
    "        if p == 1:\n",
    "            F_last = model.factors.values[-1, :].copy()\n",
    "            for h in range(horizon):\n",
    "                F_forecast = c + Phi @ F_last + boot_residuals[h, :]\n",
    "                bootstrap_paths[b, h, :] = F_forecast\n",
    "                F_last = F_forecast\n",
    "        else:\n",
    "            F_history = model.factors.values[-p:, :].copy()\n",
    "            for h in range(horizon):\n",
    "                F_lagged = F_history.flatten('F')\n",
    "                F_forecast = c + Phi @ F_lagged + boot_residuals[h, :]\n",
    "                bootstrap_paths[b, h, :] = F_forecast\n",
    "                F_history = np.vstack([F_history[1:, :], F_forecast.reshape(1, -1)])\n",
    "\n",
    "    # Calculate multiple confidence levels\n",
    "    bootstrap_results = {}\n",
    "\n",
    "    for conf_level in confidence_levels:\n",
    "        alpha = 1 - conf_level\n",
    "        lower_pct = 100 * (alpha / 2)\n",
    "        upper_pct = 100 * (1 - alpha / 2)\n",
    "\n",
    "        bootstrap_results[f'{int(conf_level*100)}%'] = {\n",
    "            'lower': np.percentile(bootstrap_paths, lower_pct, axis=0),\n",
    "            'upper': np.percentile(bootstrap_paths, upper_pct, axis=0)\n",
    "        }\n",
    "\n",
    "    # Bootstrap statistics\n",
    "    bootstrap_results['statistics'] = {\n",
    "        'mean': np.mean(bootstrap_paths, axis=0),\n",
    "        'std': np.std(bootstrap_paths, axis=0),\n",
    "        'skewness': np.mean(((bootstrap_paths - np.mean(bootstrap_paths, axis=0)[np.newaxis, :, :]) /\n",
    "                           np.std(bootstrap_paths, axis=0)[np.newaxis, :, :])**3, axis=0),\n",
    "        'kurtosis': np.mean(((bootstrap_paths - np.mean(bootstrap_paths, axis=0)[np.newaxis, :, :]) /\n",
    "                           np.std(bootstrap_paths, axis=0)[np.newaxis, :, :])**4, axis=0) - 3\n",
    "    }\n",
    "\n",
    "    print(f\"Bootstrap forecasting completed with {len(confidence_levels)} confidence levels\")\n",
    "    return bootstrap_results\n",
    "\n",
    "\n",
    "def forecast_combination_analysis(models_list, weights=None):\n",
    "    \"\"\"\n",
    "    Combine forecasts from multiple DFM models with different specifications\n",
    "\n",
    "    Parameters:\n",
    "    - models_list: List of fitted DFM models\n",
    "    - weights: Optional weights for combination (default: equal weights)\n",
    "    \"\"\"\n",
    "    print(\"\\nForecast Combination Analysis\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    n_models = len(models_list)\n",
    "\n",
    "    if weights is None:\n",
    "        weights = np.ones(n_models) / n_models\n",
    "    else:\n",
    "        weights = np.array(weights)\n",
    "        weights = weights / np.sum(weights)  # Normalize\n",
    "\n",
    "    print(f\"Combining {n_models} models with weights: {weights}\")\n",
    "\n",
    "    # Combine factor forecasts\n",
    "    combined_forecasts = {}\n",
    "\n",
    "    # Get common factors across models\n",
    "    common_factors = set(models_list[0].factors.columns)\n",
    "    for model in models_list[1:]:\n",
    "        common_factors = common_factors.intersection(set(model.factors.columns))\n",
    "\n",
    "    print(f\"Common factors across models: {list(common_factors)}\")\n",
    "\n",
    "    for factor in common_factors:\n",
    "        factor_forecasts = []\n",
    "\n",
    "        for model in models_list:\n",
    "            if hasattr(model, 'factor_forecasts'):\n",
    "                factor_forecasts.append(model.factor_forecasts['mean'][factor].values)\n",
    "\n",
    "        if factor_forecasts:\n",
    "            # Weight and combine\n",
    "            combined_forecast = np.average(np.array(factor_forecasts), axis=0, weights=weights)\n",
    "            combined_forecasts[factor] = combined_forecast\n",
    "\n",
    "    return combined_forecasts\n",
    "\n",
    "\n",
    "def stress_test_forecasts(model, stress_scenarios):\n",
    "    \"\"\"\n",
    "    Stress test forecasts under adverse scenarios\n",
    "\n",
    "    Parameters:\n",
    "    - model: Fitted DFM model\n",
    "    - stress_scenarios: Dict of stress scenarios with parameter modifications\n",
    "    \"\"\"\n",
    "    print(\"\\nForecast Stress Testing\")\n",
    "    print(\"=\"*30)\n",
    "\n",
    "    stress_results = {}\n",
    "\n",
    "    for scenario_name, scenario_params in stress_scenarios.items():\n",
    "        print(f\"\\nStress scenario: {scenario_name}\")\n",
    "\n",
    "        # Modify model parameters according to stress scenario\n",
    "        stressed_model = deepcopy(model)  # Would need to import copy\n",
    "\n",
    "        # Apply stress to residual covariance (increased uncertainty)\n",
    "        if 'volatility_multiplier' in scenario_params:\n",
    "            vol_mult = scenario_params['volatility_multiplier']\n",
    "            stressed_model.factor_var['sigma_u'] *= vol_mult**2\n",
    "            print(f\"  Applied volatility multiplier: {vol_mult}\")\n",
    "\n",
    "        # Apply persistent shock to factors\n",
    "        if 'persistent_shock' in scenario_params:\n",
    "            shock_dict = scenario_params['persistent_shock']\n",
    "            print(f\"  Applied persistent shocks: {shock_dict}\")\n",
    "\n",
    "        # Re-run forecasts with stressed parameters\n",
    "        # This would require re-implementing the forecast method with modified parameters\n",
    "        stress_results[scenario_name] = {\n",
    "            'modified_parameters': scenario_params,\n",
    "            'status': 'computed'  # Placeholder\n",
    "        }\n",
    "\n",
    "    return stress_results\n",
    "\n",
    "\n",
    "def model_selection_criteria(models_dict):\n",
    "    \"\"\"\n",
    "    Compare multiple DFM specifications using various criteria\n",
    "\n",
    "    Parameters:\n",
    "    - models_dict: Dictionary of model_name -> fitted_model pairs\n",
    "    \"\"\"\n",
    "    print(\"\\nModel Selection and Comparison\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    criteria_results = {}\n",
    "\n",
    "    for model_name, model in models_dict.items():\n",
    "        if model.factor_var is None:\n",
    "            continue\n",
    "\n",
    "        var_result = model.factor_var\n",
    "        T_eff = var_result['T_eff']\n",
    "        K = len(model.factors.columns)\n",
    "        p = var_result['lags']\n",
    "\n",
    "        # Log-likelihood\n",
    "        log_likelihood = var_result['log_likelihood']\n",
    "\n",
    "        # Number of parameters (VAR coefficients + factor loadings)\n",
    "        n_var_params = K * (1 + K * p)  # Constants + VAR coefficients\n",
    "        n_loading_params = model.N_vars * K  # Factor loadings\n",
    "        total_params = n_var_params + n_loading_params\n",
    "\n",
    "        # Information criteria\n",
    "        aic = -2 * log_likelihood + 2 * total_params\n",
    "        bic = -2 * log_likelihood + total_params * np.log(T_eff)\n",
    "        hqic = -2 * log_likelihood + 2 * total_params * np.log(np.log(T_eff))\n",
    "\n",
    "        # Forecast accuracy metrics (if validation sample available)\n",
    "        # This would require out-of-sample evaluation\n",
    "\n",
    "        criteria_results[model_name] = {\n",
    "            'log_likelihood': log_likelihood,\n",
    "            'AIC': aic,\n",
    "            'BIC': bic,\n",
    "            'HQIC': hqic,\n",
    "            'n_parameters': total_params,\n",
    "            'n_factors': K,\n",
    "            'var_lags': p,\n",
    "            'sample_size': T_eff\n",
    "        }\n",
    "\n",
    "        print(f\"{model_name}:\")\n",
    "        print(f\"  Log-likelihood: {log_likelihood:.2f}\")\n",
    "        print(f\"  AIC: {aic:.2f}\")\n",
    "        print(f\"  BIC: {bic:.2f}\")\n",
    "        print(f\"  Parameters: {total_params}\")\n",
    "\n",
    "    # Select best model by BIC (most conservative)\n",
    "    best_model_name = min(criteria_results.keys(),\n",
    "                         key=lambda x: criteria_results[x]['BIC'])\n",
    "    print(f\"\\nBest model by BIC: {best_model_name}\")\n",
    "\n",
    "    return criteria_results, best_model_name\n",
    "\n",
    "\n",
    "def real_time_forecast_evaluation(model, real_time_data, evaluation_periods=8):\n",
    "    \"\"\"\n",
    "    Evaluate forecast accuracy using real-time data\n",
    "\n",
    "    Parameters:\n",
    "    - model: Fitted DFM model\n",
    "    - real_time_data: New data for evaluation\n",
    "    - evaluation_periods: Number of periods to evaluate\n",
    "    \"\"\"\n",
    "    print(f\"\\nReal-time Forecast Evaluation\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    if not hasattr(model, 'factor_forecasts'):\n",
    "        print(\"No forecasts available for evaluation\")\n",
    "        return None\n",
    "\n",
    "    evaluation_results = {}\n",
    "\n",
    "    # Compare forecasts with actual realizations\n",
    "    for var in model.combined_data.columns:\n",
    "        if var in real_time_data.columns:\n",
    "            forecast_values = model.variable_forecasts['mean'][var].iloc[:evaluation_periods]\n",
    "            actual_values = real_time_data[var].iloc[:evaluation_periods]\n",
    "\n",
    "            # Calculate forecast errors\n",
    "            errors = actual_values - forecast_values\n",
    "\n",
    "            # Accuracy metrics\n",
    "            mae = np.mean(np.abs(errors))\n",
    "            rmse = np.sqrt(np.mean(errors**2))\n",
    "            mape = np.mean(np.abs(errors / actual_values)) * 100\n",
    "\n",
    "            evaluation_results[var] = {\n",
    "                'MAE': mae,\n",
    "                'RMSE': rmse,\n",
    "                'MAPE': mape,\n",
    "                'bias': np.mean(errors),\n",
    "                'forecast_values': forecast_values,\n",
    "                'actual_values': actual_values,\n",
    "                'errors': errors\n",
    "            }\n",
    "\n",
    "            print(f\"{var}: RMSE={rmse:.3f}, MAE={mae:.3f}, MAPE={mape:.1f}%\")\n",
    "\n",
    "    return evaluation_results\n",
    "\n",
    "\n",
    "# Main integration function\n",
    "def run_complete_advanced_dfm_analysis(core_analysis_results,\n",
    "                                     include_stress_tests=True,\n",
    "                                     include_bootstrap_enhanced=True,\n",
    "                                     stress_scenarios=None):\n",
    "    \"\"\"\n",
    "    Complete advanced analysis pipeline integrating all components\n",
    "\n",
    "    Parameters:\n",
    "    - core_analysis_results: Results from core model estimation\n",
    "    - include_stress_tests: Whether to run stress tests\n",
    "    - include_bootstrap_enhanced: Whether to run enhanced bootstrap\n",
    "    - stress_scenarios: Custom stress test scenarios\n",
    "    \"\"\"\n",
    "\n",
    "    if core_analysis_results is None:\n",
    "        print(\"No core analysis results provided\")\n",
    "        return None\n",
    "\n",
    "    model = core_analysis_results['model']\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(\"COMPLETE ADVANCED DFM ANALYSIS PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Initialize advanced analyzer\n",
    "    analyzer = AdvancedDFMAnalyzer(model)\n",
    "\n",
    "    # Component 1: Enhanced diagnostics\n",
    "    print(\"\\n1. ENHANCED VAR DIAGNOSTICS\")\n",
    "    analyzer.enhanced_var_diagnostics()\n",
    "    analyzer.enhanced_forecast_quality()\n",
    "\n",
    "    # Component 2: Structural analysis\n",
    "    print(\"\\n2. STRUCTURAL ANALYSIS\")\n",
    "    analyzer.compute_impulse_responses(horizon=20)\n",
    "    analyzer.historical_decomposition()\n",
    "\n",
    "    # Component 3: Enhanced bootstrap (optional)\n",
    "    enhanced_bootstrap_results = None\n",
    "    if include_bootstrap_enhanced:\n",
    "        print(\"\\n3. ENHANCED BOOTSTRAP FORECASTING\")\n",
    "        enhanced_bootstrap_results = enhanced_bootstrap_forecasts(model, horizon=8, n_bootstrap=1000)\n",
    "\n",
    "    # Component 4: Stress testing (optional)\n",
    "    stress_test_results = None\n",
    "    if include_stress_tests:\n",
    "        print(\"\\n4. STRESS TESTING\")\n",
    "        if stress_scenarios is None:\n",
    "            stress_scenarios = {\n",
    "                'high_volatility': {'volatility_multiplier': 2.0},\n",
    "                'recession_scenario': {'volatility_multiplier': 1.5, 'persistent_shock': {'Demand_Factor': -1.0}},\n",
    "                'inflation_shock': {'persistent_shock': {'Supply_Factor': 1.0}}\n",
    "            }\n",
    "        stress_test_results = stress_test_forecasts(model, stress_scenarios)\n",
    "\n",
    "    # Component 5: Generate comprehensive report\n",
    "    print(\"\\n5. GENERATING FORECAST REPORT\")\n",
    "    forecast_report = generate_forecast_report(model, analyzer)\n",
    "\n",
    "    # Component 6: Comprehensive visualizations\n",
    "    print(\"\\n6. COMPREHENSIVE VISUALIZATIONS\")\n",
    "    analyzer.plot_impulse_responses()\n",
    "    analyzer.plot_historical_decomposition()\n",
    "    analyzer.plot_comprehensive_results()\n",
    "\n",
    "    # Compile final results\n",
    "    advanced_results = {\n",
    "        'analyzer': analyzer,\n",
    "        'forecast_report': forecast_report,\n",
    "        'enhanced_bootstrap': enhanced_bootstrap_results,\n",
    "        'stress_tests': stress_test_results,\n",
    "        'impulse_responses': analyzer.impulse_responses,\n",
    "        'historical_decomposition': analyzer.historical_decomp\n",
    "    }\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ADVANCED ANALYSIS PIPELINE COMPLETED\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Results stored in advanced_results dictionary\")\n",
    "    print(f\"Key components:\")\n",
    "    print(f\"  ‚Ä¢ Enhanced VAR diagnostics and forecast quality assessment\")\n",
    "    print(f\"  ‚Ä¢ Impulse response functions and historical decomposition\")\n",
    "    if include_bootstrap_enhanced:\n",
    "        print(f\"  ‚Ä¢ Enhanced bootstrap forecasting with multiple confidence levels\")\n",
    "    if include_stress_tests:\n",
    "        print(f\"  ‚Ä¢ Stress test scenarios\")\n",
    "    print(f\"  ‚Ä¢ Comprehensive visualizations and reporting\")\n",
    "\n",
    "    return advanced_results\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Advanced DFM Analysis Components\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"This module provides advanced analysis for econometric DFM models.\")\n",
    "    print(\"\\nMain functions:\")\n",
    "    print(\"‚Ä¢ AdvancedDFMAnalyzer: Core advanced analysis class\")\n",
    "    print(\"‚Ä¢ run_complete_analysis_with_diagnostics: Full diagnostic pipeline\")\n",
    "    print(\"‚Ä¢ enhanced_bootstrap_forecasts: Robust bootstrap forecasting\")\n",
    "    print(\"‚Ä¢ stress_test_forecasts: Scenario analysis\")\n",
    "    print(\"‚Ä¢ model_selection_criteria: Model comparison\")\n",
    "    print(\"‚Ä¢ run_complete_advanced_dfm_analysis: Complete advanced pipeline\")\n",
    "    print(\"\\nTo use with core model:\")\n",
    "    print(\"advanced_results = run_complete_advanced_dfm_analysis(core_analysis_results)\")\n",
    "\n",
    "# ============================================================================\n",
    "# EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "# After running your core estimation:\n",
    "core_results = run_core_economic_analysis()\n",
    "\n",
    "# Run advanced analysis:\n",
    "advanced_results = run_complete_advanced_dfm_analysis(core_results)\n",
    "\n",
    "# Or step by step:\n",
    "analyzer = AdvancedDFMAnalyzer(core_results['model'])\n",
    "analyzer.compute_impulse_responses()\n",
    "analyzer.historical_decomposition()\n",
    "analyzer.plot_comprehensive_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSGE-INFORMED THETA ENHANCEMENT EXAMPLE\n",
      "==================================================\n",
      "\n",
      "FIXED INTEGRATION APPROACH:\n",
      "==================================================\n",
      "\n",
      "1. Complete Pipeline (uses Document 1's DSGE results):\n",
      "   # This automatically runs DSGE estimation then theta enhancement\n",
      "   results = integrate_dsge_theta_with_document1_results(\n",
      "       dsge_posterior_estimates=dsge_estimates)\n",
      "   \n",
      "2. Manual Two-Step Process:\n",
      "   # Step 1: Run Document 1's DSGE-informed DFM\n",
      "   base_analysis = run_core_economic_analysis(dsge_posterior_estimates)\n",
      "   base_dfm = base_analysis['model']\n",
      "   \n",
      "   # Step 2: Enhance with theta (automatically extracts DSGE priors)\n",
      "   enhanced_dfm, results = enhance_dsge_dfm_with_theta(base_dfm)\n",
      "   \n",
      "3. Method Comparison with DSGE Consistency:\n",
      "   enhanced_dfm, results = compare_dsge_theta_methods(base_dfm)\n",
      "   \n",
      "KEY FIXES IN THIS VERSION:\n",
      "‚Ä¢ _extract_dsge_posterior_estimates() properly extracts DSGE priors\n",
      "‚Ä¢ _construct_priors_from_dsge_estimates() handles missing prior_info\n",
      "‚Ä¢ Integration function imports and uses Document 1 functions\n",
      "‚Ä¢ DSGE parameter extraction from posterior_table format\n",
      "‚Ä¢ Automatic fallback to econometric constraints if no DSGE priors\n",
      "   \n",
      "DSGE-Informed Methods Available:\n",
      "‚Ä¢ DSGE_HP_Trend_Cycle: DSGE persistence guides trend-cycle weights\n",
      "‚Ä¢ DSGE_Regime_Switching: Structural break regimes from DSGE parameters\n",
      "‚Ä¢ DSGE_Time_Varying: Parameter evolution consistent with DSGE stability\n"
     ]
    }
   ],
   "source": [
    "# DSGE-Informed Enhanced DFM with Theta Optimization\n",
    "# FIXED: Properly integrates DSGE posterior estimates from Document 1\n",
    "\n",
    "class DSGEInformedEnhancedDFMTheta:\n",
    "    \"\"\"\n",
    "    Enhanced DFM with theta optimization that preserves DSGE-informed VAR structure\n",
    "    FIXED: Now properly extracts DSGE posterior estimates from Document 1's estimation results\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_dfm_model):\n",
    "        # Import structural components from DSGE-informed base model\n",
    "        self.factors = base_dfm_model.factors.copy()\n",
    "        self.loadings = base_dfm_model.loadings.copy()  # PRESERVE original loadings\n",
    "        self.data_standardized = base_dfm_model.data_standardized.copy()\n",
    "        self.scaler = base_dfm_model.scaler\n",
    "        self.combined_data = base_dfm_model.combined_data.copy()\n",
    "        \n",
    "        # CRITICAL: Preserve DSGE-informed VAR structure\n",
    "        self.base_factor_var = base_dfm_model.factor_var  # Original DSGE-informed VAR\n",
    "        \n",
    "        # FIXED: Extract DSGE priors from base model's estimation results\n",
    "        self.dsge_priors = self._extract_dsge_posterior_estimates(base_dfm_model)\n",
    "        self.idiosyncratic_var = base_dfm_model.idiosyncratic_var.copy()\n",
    "\n",
    "        # Model dimensions\n",
    "        self.T_obs, self.n_factors = self.factors.shape\n",
    "        self.N_vars = len(self.data_standardized.columns)\n",
    "\n",
    "        # Initialize theta components\n",
    "        self.optimal_theta = None\n",
    "        self.theta_strategy = None\n",
    "        self.method_results = {}\n",
    "        \n",
    "        # Results storage for each method\n",
    "        self.method_forecasts = {}\n",
    "        self.method_var_models = {}  # Store theta-adapted VAR models\n",
    "        self.method_r2 = {}\n",
    "        self.method_metrics = {}\n",
    "        \n",
    "        # Cross-validation setup\n",
    "        self.tscv = TimeSeriesSplit(n_splits=3, test_size=4)\n",
    "\n",
    "        print(f\"DSGE-Informed Enhanced DFM-Theta initialized:\")\n",
    "        print(f\"  Factors: {self.n_factors}, Variables: {self.N_vars}\")\n",
    "        print(f\"  DSGE priors: {'Available' if self.dsge_priors else 'None'}\")\n",
    "        print(f\"  Base VAR estimation: {'Bayesian' if self.base_factor_var.get('bayesian', False) else 'OLS'}\")\n",
    "\n",
    "    # Add these methods to the DSGEInformedEnhancedDFMTheta class\n",
    "\n",
    "    def detailed_variable_cv_analysis(self, method_name, theta_params, theta_func):\n",
    "        \"\"\"\n",
    "        Detailed cross-validation analysis at the variable level\n",
    "        \"\"\"\n",
    "        variable_cv_results = {}\n",
    "        \n",
    "        for train_idx, test_idx in self.tscv.split(self.factors):\n",
    "            if len(test_idx) < 2:\n",
    "                continue\n",
    "                \n",
    "            # Split data maintaining temporal structure\n",
    "            factors_train = self.factors.iloc[train_idx]\n",
    "            factors_test = self.factors.iloc[test_idx]\n",
    "            data_train = self.data_standardized.iloc[train_idx]\n",
    "            data_test = self.data_standardized.iloc[test_idx]\n",
    "            \n",
    "            try:\n",
    "                # Apply theta transformation to training factors\n",
    "                F_theta_train = theta_func(factors_train, theta_params)\n",
    "                F_theta_test = theta_func(factors_test, theta_params)\n",
    "                \n",
    "                # Estimate theta-aware VAR on training data\n",
    "                theta_var_cv = self._estimate_theta_aware_var(F_theta_train, theta_params, method_name)\n",
    "                \n",
    "                # Generate forecasts\n",
    "                test_forecasts = self._forecast_theta_var(F_theta_test, theta_var_cv, len(test_idx))\n",
    "                F_theta_forecast = test_forecasts['mean'].values\n",
    "                \n",
    "                # Use original loadings for variable forecasts\n",
    "                X_pred = F_theta_forecast @ self.loadings.values.T\n",
    "                \n",
    "                # Calculate metrics for each variable\n",
    "                for i, var_name in enumerate(self.data_standardized.columns):\n",
    "                    if var_name not in variable_cv_results:\n",
    "                        variable_cv_results[var_name] = {\n",
    "                            'RMSE': [], 'MAE': [], 'MAPE': [], 'SMAPE': [], \n",
    "                            'Theil_U1': [], 'Theil_U2': [], 'MdAPE': [], 'MASE': [], 'R2': []\n",
    "                        }\n",
    "                    \n",
    "                    y_true_var = data_test.values[:, i]\n",
    "                    y_pred_var = X_pred[:, i]\n",
    "                    \n",
    "                    # Calculate all metrics\n",
    "                    metrics = self._calculate_comprehensive_metrics(y_true_var, y_pred_var, data_train.values[:, i])\n",
    "                    \n",
    "                    for metric_name, value in metrics.items():\n",
    "                        variable_cv_results[var_name][metric_name].append(value)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"CV fold failed for {method_name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Average across folds (rest remains the same)\n",
    "        averaged_results = {}\n",
    "        for var_name, metrics in variable_cv_results.items():\n",
    "            averaged_results[var_name] = {}\n",
    "            for metric_name, values in metrics.items():\n",
    "                if values:\n",
    "                    averaged_results[var_name][metric_name] = np.mean(values)\n",
    "                else:\n",
    "                    averaged_results[var_name][metric_name] = np.nan\n",
    "        \n",
    "        return averaged_results\n",
    "    \n",
    "    def _calculate_comprehensive_metrics(self, y_true, y_pred, y_train):\n",
    "        \"\"\"Calculate comprehensive forecast accuracy metrics\"\"\"\n",
    "        epsilon = 1e-8\n",
    "        \n",
    "        # Basic metrics\n",
    "        rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "        mae = np.mean(np.abs(y_true - y_pred))\n",
    "        \n",
    "        # MAPE\n",
    "        mape = np.mean(np.abs((y_true - y_pred) / np.maximum(np.abs(y_true), epsilon))) * 100\n",
    "        \n",
    "        # SMAPE\n",
    "        smape = np.mean(2 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred) + epsilon)) * 100\n",
    "        \n",
    "        # Theil's U1\n",
    "        numerator = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "        denominator = np.sqrt(np.mean(y_true**2)) + np.sqrt(np.mean(y_pred**2))\n",
    "        theil_u1 = numerator / (denominator + epsilon)\n",
    "        \n",
    "        # Theil's U2\n",
    "        naive_forecast = np.full_like(y_true, y_true[0] if len(y_true) > 0 else 0)\n",
    "        theil_u2 = rmse / (np.sqrt(np.mean((y_true - naive_forecast)**2)) + epsilon)\n",
    "        \n",
    "        # MdAPE (Median Absolute Percentage Error)\n",
    "        mdape = np.median(np.abs((y_true - y_pred) / np.maximum(np.abs(y_true), epsilon))) * 100\n",
    "        \n",
    "        # MASE (Mean Absolute Scaled Error)\n",
    "        if len(y_train) > 1:\n",
    "            seasonal_naive_mae = np.mean(np.abs(np.diff(y_train)))\n",
    "            mase = mae / (seasonal_naive_mae + epsilon)\n",
    "        else:\n",
    "            mase = np.nan\n",
    "        \n",
    "        # R-squared\n",
    "        ss_res = np.sum((y_true - y_pred)**2)\n",
    "        ss_tot = np.sum((y_true - np.mean(y_true))**2)\n",
    "        r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'SMAPE': smape,\n",
    "            'Theil_U1': theil_u1, 'Theil_U2': theil_u2, 'MdAPE': mdape, \n",
    "            'MASE': mase, 'R2': r2\n",
    "        }\n",
    "\n",
    "    def print_variable_cv_results(self):\n",
    "        \"\"\"\n",
    "        Print detailed variable-level cross-validation results\n",
    "        \"\"\"\n",
    "        if not self.method_results:\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n{'='*150}\")\n",
    "        print(\"DETAILED VARIABLE-LEVEL CROSS-VALIDATION RESULTS\")\n",
    "        print(\"=\"*150)\n",
    "        \n",
    "        for method_name, results in self.method_results.items():\n",
    "            if 'variable_cv_metrics' not in results:\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\nMethod: {method_name}\")\n",
    "            print(\"-\" * 140)\n",
    "            print(f\"{'Variable':<15} {'CV RMSE':<8} {'CV MAE':<8} {'CV MAPE':<9} {'CV SMAPE':<10} \"\n",
    "                f\"{'CV Theil_U1':<12} {'CV Theil_U2':<12} {'CV MdAPE':<10} {'CV MASE':<9} {'CV R¬≤':<8}\")  # ADDED MASE\n",
    "            print(\"-\" * 140)\n",
    "            \n",
    "            var_cv_metrics = results['variable_cv_metrics']\n",
    "            for var_name, metrics in var_cv_metrics.items():\n",
    "                print(f\"{var_name:<15} {metrics.get('RMSE', np.nan):<8.4f} {metrics.get('MAE', np.nan):<8.4f} \"\n",
    "                    f\"{metrics.get('MAPE', np.nan):<9.2f} {metrics.get('SMAPE', np.nan):<10.2f} \"\n",
    "                    f\"{metrics.get('Theil_U1', np.nan):<12.4f} {metrics.get('Theil_U2', np.nan):<12.4f} \"\n",
    "                    f\"{metrics.get('MdAPE', np.nan):<10.2f} {metrics.get('MASE', np.nan):<9.4f} \"  # ADDED MASE\n",
    "                    f\"{metrics.get('R2', np.nan):<8.3f}\")\n",
    "\n",
    "    def get_model_averages(self):\n",
    "        \"\"\"\n",
    "        Get average Theil U1, U2, and MASE for all models\n",
    "        Returns a DataFrame with model names and their average metrics\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'method_results') or not self.method_results:\n",
    "            print(\"No results available\")\n",
    "            return None\n",
    "        \n",
    "        import pandas as pd\n",
    "        results_data = []\n",
    "        \n",
    "        for method_name, results in self.method_results.items():\n",
    "            if 'variable_cv_metrics' not in results:\n",
    "                continue\n",
    "                \n",
    "            var_cv_metrics = results['variable_cv_metrics']\n",
    "            \n",
    "            # Calculate averages\n",
    "            all_rmse = [metrics.get('RMSE', np.nan) for metrics in var_cv_metrics.values()]\n",
    "            all_mae = [metrics.get('MAE', np.nan) for metrics in var_cv_metrics.values()]\n",
    "            all_mape = [metrics.get('MAPE', np.nan) for metrics in var_cv_metrics.values()]\n",
    "            all_theil_u1 = [metrics.get('Theil_U1', np.nan) for metrics in var_cv_metrics.values()]\n",
    "            all_theil_u2 = [metrics.get('Theil_U2', np.nan) for metrics in var_cv_metrics.values()]\n",
    "            all_mase = [metrics.get('MASE', np.nan) for metrics in var_cv_metrics.values()]\n",
    "            \n",
    "            results_data.append({\n",
    "                'Method': method_name,\n",
    "                'Avg_RMSE': np.nanmean(all_rmse),\n",
    "                'Avg_MAE': np.nanmean(all_mae),\n",
    "                'Avg_MAPE': np.nanmean(all_mape),\n",
    "                'Avg_Theil_U1': np.nanmean(all_theil_u1),\n",
    "                'Avg_Theil_U2': np.nanmean(all_theil_u2),\n",
    "                'Avg_MASE': np.nanmean(all_mase),\n",
    "                'Avg_R2': np.mean(list(results['variable_r2'].values())),\n",
    "                'CV_RMSE': results['cv_metrics'].get('RMSE', np.nan),\n",
    "                'DSGE_Informed': results.get('dsge_informed', False)\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(results_data).set_index('Method')\n",
    "        return df.sort_values('Avg_RMSE')  # Sort by best RMSE\n",
    "\n",
    "    def print_comprehensive_model_summary(self):\n",
    "        \"\"\"\n",
    "        Print comprehensive summary including all average metrics\n",
    "        \"\"\"\n",
    "        averages_df = self.get_model_averages()\n",
    "        if averages_df is None:\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n{'='*120}\")\n",
    "        print(\"COMPREHENSIVE MODEL COMPARISON - ALL AVERAGE METRICS\")\n",
    "        print(\"=\"*120)\n",
    "        \n",
    "        # Round for better display\n",
    "        display_df = averages_df.round(4)\n",
    "        \n",
    "        print(display_df.to_string())\n",
    "        \n",
    "        print(f\"\\n{'='*120}\")\n",
    "        print(\"RANKING BY KEY METRICS:\")\n",
    "        print(\"=\"*120)\n",
    "        \n",
    "        print(\"\\nBest by RMSE:\")\n",
    "        best_rmse = averages_df.nsmallest(3, 'Avg_RMSE')[['Avg_RMSE', 'Avg_Theil_U1', 'Avg_Theil_U2', 'Avg_MASE']]\n",
    "        print(best_rmse)\n",
    "        \n",
    "        print(\"\\nBest by Theil U1:\")\n",
    "        best_u1 = averages_df.nsmallest(3, 'Avg_Theil_U1')[['Avg_RMSE', 'Avg_Theil_U1', 'Avg_Theil_U2', 'Avg_MASE']]\n",
    "        print(best_u1)\n",
    "        \n",
    "        print(\"\\nBest by Theil U2:\")\n",
    "        best_u2 = averages_df.nsmallest(3, 'Avg_Theil_U2')[['Avg_RMSE', 'Avg_Theil_U1', 'Avg_Theil_U2', 'Avg_MASE']]\n",
    "        print(best_u2)\n",
    "        \n",
    "        print(\"\\nBest by MASE:\")\n",
    "        best_mase = averages_df.nsmallest(3, 'Avg_MASE')[['Avg_RMSE', 'Avg_Theil_U1', 'Avg_Theil_U2', 'Avg_MASE']]\n",
    "        print(best_mase)\n",
    "\n",
    "    def select_best_method(self, all_results, selection_criteria=None):\n",
    "        \"\"\"\n",
    "        Select best method based on comprehensive forecasting and fit metrics\n",
    "        \"\"\"\n",
    "        if not all_results:\n",
    "            print(\"No results available for selection\")\n",
    "            return None, None\n",
    "            \n",
    "        if selection_criteria is None:\n",
    "            # Simplified weighting scheme - only 4 core metrics\n",
    "            selection_criteria = {\n",
    "                'cv_rmse_weight': 0.30,      # Increased weight\n",
    "                'mase_weight': 0.25,         # Substantial weight for MASE\n",
    "                'theil_u1_weight': 0.20,     # Increased weight\n",
    "                'theil_u2_weight': 0.20,     # Increased weight\n",
    "                'dsge_bonus': 0.05           # Keep DSGE bonus\n",
    "            }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"COMPREHENSIVE METHOD SELECTION\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        method_scores = {}\n",
    "        detailed_scores = {}\n",
    "        \n",
    "        for method_name, results in all_results.items():\n",
    "            if 'variable_cv_metrics' not in results:\n",
    "                print(f\"Skipping {method_name} - incomplete metrics\")\n",
    "                continue\n",
    "                \n",
    "            # Calculate component scores\n",
    "            cv_metrics = results['cv_metrics']\n",
    "            var_cv_metrics = results['variable_cv_metrics']\n",
    "            \n",
    "            # Aggregate variable-level metrics\n",
    "            all_rmse = [metrics.get('RMSE', np.nan) for metrics in var_cv_metrics.values()]\n",
    "            all_mae = [metrics.get('MAE', np.nan) for metrics in var_cv_metrics.values()]\n",
    "            all_mape = [metrics.get('MAPE', np.nan) for metrics in var_cv_metrics.values()]\n",
    "            all_theil_u1 = [metrics.get('Theil_U1', np.nan) for metrics in var_cv_metrics.values()]\n",
    "            all_theil_u2 = [metrics.get('Theil_U2', np.nan) for metrics in var_cv_metrics.values()]\n",
    "            all_mase = [metrics.get('MASE', np.nan) for metrics in var_cv_metrics.values()]  # ADDED\n",
    "            \n",
    "            avg_var_rmse = np.nanmean(all_rmse)\n",
    "            avg_var_mae = np.nanmean(all_mae)\n",
    "            avg_var_mape = np.nanmean(all_mape)\n",
    "            avg_theil_u1 = np.nanmean(all_theil_u1)\n",
    "            avg_theil_u2 = np.nanmean(all_theil_u2)\n",
    "            avg_mase = np.nanmean(all_mase)  # ADDED\n",
    "            \n",
    "            # Overall fit\n",
    "            avg_r2 = np.mean(list(results['variable_r2'].values()))\n",
    "            \n",
    "            # Normalize metrics (lower is better for most, except R¬≤)\n",
    "            # Use min-max normalization across methods for fair comparison\n",
    "            detailed_scores[method_name] = {\n",
    "                'avg_var_rmse': avg_var_rmse,\n",
    "                'avg_var_mae': avg_var_mae,\n",
    "                'avg_var_mape': avg_var_mape,\n",
    "                'avg_r2': avg_r2,\n",
    "                'avg_theil_u1': avg_theil_u1,\n",
    "                'avg_theil_u2': avg_theil_u2,\n",
    "                'avg_mase': avg_mase,  # ADDED\n",
    "                'dsge_informed': results.get('dsge_informed', False)\n",
    "            }\n",
    "        \n",
    "        # Normalize scores across methods\n",
    "        metric_ranges = {}\n",
    "        for metric in ['avg_var_rmse', 'avg_var_mae', 'avg_var_mape', 'avg_r2', 'avg_theil_u1', 'avg_theil_u2', 'avg_mase']:  # ADDED avg_mase\n",
    "            values = [scores[metric] for scores in detailed_scores.values() if not np.isnan(scores[metric])]\n",
    "            if values:\n",
    "                metric_ranges[metric] = {'min': min(values), 'max': max(values)}\n",
    "            else:\n",
    "                metric_ranges[metric] = {'min': 0, 'max': 1}\n",
    "        \n",
    "        # Calculate composite scores\n",
    "        for method_name, scores in detailed_scores.items():\n",
    "            composite_score = 0.0\n",
    "            \n",
    "            # RMSE component (lower is better)\n",
    "            if not np.isnan(scores['avg_var_rmse']) and metric_ranges['avg_var_rmse']['max'] > metric_ranges['avg_var_rmse']['min']:\n",
    "                rmse_normalized = 1 - (scores['avg_var_rmse'] - metric_ranges['avg_var_rmse']['min']) / (metric_ranges['avg_var_rmse']['max'] - metric_ranges['avg_var_rmse']['min'])\n",
    "                composite_score += selection_criteria['cv_rmse_weight'] * rmse_normalized\n",
    "            \n",
    "            # MAE component (lower is better)\n",
    "            if not np.isnan(scores['avg_var_mae']) and metric_ranges['avg_var_mae']['max'] > metric_ranges['avg_var_mae']['min']:\n",
    "                mae_normalized = 1 - (scores['avg_var_mae'] - metric_ranges['avg_var_mae']['min']) / (metric_ranges['avg_var_mae']['max'] - metric_ranges['avg_var_mae']['min'])\n",
    "                composite_score += selection_criteria['cv_mae_weight'] * mae_normalized\n",
    "            \n",
    "            # MAPE component (lower is better)\n",
    "            if not np.isnan(scores['avg_var_mape']) and metric_ranges['avg_var_mape']['max'] > metric_ranges['avg_var_mape']['min']:\n",
    "                mape_normalized = 1 - (scores['avg_var_mape'] - metric_ranges['avg_var_mape']['min']) / (metric_ranges['avg_var_mape']['max'] - metric_ranges['avg_var_mape']['min'])\n",
    "                composite_score += selection_criteria['cv_mape_weight'] * mape_normalized\n",
    "            \n",
    "            # R¬≤ component (higher is better)\n",
    "            if not np.isnan(scores['avg_r2']) and metric_ranges['avg_r2']['max'] > metric_ranges['avg_r2']['min']:\n",
    "                r2_normalized = (scores['avg_r2'] - metric_ranges['avg_r2']['min']) / (metric_ranges['avg_r2']['max'] - metric_ranges['avg_r2']['min'])\n",
    "                composite_score += selection_criteria['avg_r2_weight'] * r2_normalized\n",
    "            \n",
    "            # Theil U1 component (lower is better)\n",
    "            if not np.isnan(scores['avg_theil_u1']) and metric_ranges['avg_theil_u1']['max'] > metric_ranges['avg_theil_u1']['min']:\n",
    "                theil_u1_normalized = 1 - (scores['avg_theil_u1'] - metric_ranges['avg_theil_u1']['min']) / (metric_ranges['avg_theil_u1']['max'] - metric_ranges['avg_theil_u1']['min'])\n",
    "                composite_score += selection_criteria['theil_u1_weight'] * theil_u1_normalized\n",
    "            \n",
    "            # Theil U2 component (lower is better)\n",
    "            if not np.isnan(scores['avg_theil_u2']) and metric_ranges['avg_theil_u2']['max'] > metric_ranges['avg_theil_u2']['min']:\n",
    "                theil_u2_normalized = 1 - (scores['avg_theil_u2'] - metric_ranges['avg_theil_u2']['min']) / (metric_ranges['avg_theil_u2']['max'] - metric_ranges['avg_theil_u2']['min'])\n",
    "                composite_score += selection_criteria['theil_u2_weight'] * theil_u2_normalized\n",
    "            \n",
    "            # DSGE bonus\n",
    "            if scores['dsge_informed']:\n",
    "                composite_score += selection_criteria['dsge_bonus']\n",
    "            \n",
    "            method_scores[method_name] = composite_score\n",
    "        \n",
    "        # Print selection results\n",
    "        print(f\"{'Method':<25} {'Composite Score':<15} {'Avg RMSE':<10} {'Avg R¬≤':<8} {'Avg Theil_U1':<12} {'Avg Theil_U2':<12} {'Avg MASE':<10} {'DSGE':<6}\")\n",
    "        print(\"-\" * 105)  # EXTENDED\n",
    "        \n",
    "        for method_name in sorted(method_scores.keys(), key=lambda x: method_scores[x], reverse=True):\n",
    "            score = method_scores[method_name]\n",
    "            rmse = detailed_scores[method_name]['avg_var_rmse']\n",
    "            r2 = detailed_scores[method_name]['avg_r2']\n",
    "            theil_u1 = detailed_scores[method_name]['avg_theil_u1']  # ADDED\n",
    "            theil_u2 = detailed_scores[method_name]['avg_theil_u2']  # ADDED\n",
    "            mase = detailed_scores[method_name]['avg_mase']  # ADDED\n",
    "            dsge = \"Yes\" if detailed_scores[method_name]['dsge_informed'] else \"No\"\n",
    "            \n",
    "            print(f\"{method_name:<25} {score:<15.4f} {rmse:<10.4f} {r2:<8.3f} {theil_u1:<12.4f} {theil_u2:<12.4f} {mase:<10.4f} {dsge:<6}\")\n",
    "        \n",
    "        # Select best method\n",
    "        best_method = max(method_scores.keys(), key=lambda x: method_scores[x])\n",
    "        best_score = method_scores[best_method]\n",
    "        \n",
    "        print(f\"\\nSelected Best Method: {best_method} (Score: {best_score:.4f})\")\n",
    "        \n",
    "        return best_method, method_scores\n",
    "            \n",
    "    def _extract_dsge_posterior_estimates(self, base_dfm_model):\n",
    "        \"\"\"\n",
    "        FIXED: Extract DSGE posterior estimates from the base model's DSGE estimation\n",
    "        This integrates with Document 1's dsge.posterior_table results\n",
    "        \"\"\"\n",
    "        # Try to get DSGE priors from the base model\n",
    "        if hasattr(base_dfm_model, 'dsge_priors') and base_dfm_model.dsge_priors is not None:\n",
    "            return base_dfm_model.dsge_priors\n",
    "            \n",
    "        # FIXED: If base model was created with DSGE posterior estimates, extract them\n",
    "        # This assumes Document 1's DSGE estimation results are available\n",
    "        if hasattr(base_dfm_model, 'factor_var') and base_dfm_model.factor_var.get('bayesian', False):\n",
    "            prior_info = base_dfm_model.factor_var.get('prior_info')\n",
    "            if prior_info and 'dsge_params' in prior_info:\n",
    "                # Convert DSGE structural parameters to format expected by theta methods\n",
    "                dsge_params = prior_info['dsge_params']\n",
    "                return {\n",
    "                    'sigma': {'mean': dsge_params.get('sigma', 1.25), 'std': 0.15},\n",
    "                    'theta': {'mean': dsge_params.get('theta', 0.75), 'std': 0.08},\n",
    "                    'phi_pi': {'mean': dsge_params.get('phi_pi', 1.65), 'std': 0.25},\n",
    "                    'phi_y': {'mean': dsge_params.get('phi_y', 0.35), 'std': 0.12},\n",
    "                    'rho_a': {'mean': dsge_params.get('rho_a', 0.82), 'std': 0.10},\n",
    "                    'rho_v': {'mean': dsge_params.get('rho_v', 0.45), 'std': 0.18},\n",
    "                }\n",
    "        \n",
    "        # FIXED: Try to reconstruct from any DSGE calibration in the base model\n",
    "        if hasattr(base_dfm_model, 'organized_blocks'):\n",
    "            # This indicates the model might have been created with DSGE context\n",
    "            print(\"  Attempting to extract DSGE parameters from model context...\")\n",
    "            # Look for any stored DSGE results or use reasonable defaults based on literature\n",
    "            return {\n",
    "                'sigma': {'mean': 1.30, 'std': 0.20},    # Risk aversion\n",
    "                'theta': {'mean': 0.75, 'std': 0.10},    # Price stickiness  \n",
    "                'phi_pi': {'mean': 1.50, 'std': 0.35},   # Taylor rule - inflation\n",
    "                'phi_y': {'mean': 0.25, 'std': 0.10},    # Taylor rule - output\n",
    "                'rho_a': {'mean': 0.80, 'std': 0.15},    # Technology persistence\n",
    "                'rho_v': {'mean': 0.50, 'std': 0.20},    # Monetary persistence\n",
    "            }\n",
    "            \n",
    "        print(\"  No DSGE priors found - theta optimization will use econometric constraints only\")\n",
    "        return None\n",
    "\n",
    "    # ============================================================================\n",
    "    # DSGE-INFORMED THETA TRANSFORMATION METHODS (unchanged from original)\n",
    "    # ============================================================================\n",
    "\n",
    "    def _adapt_dsge_priors_to_theta(self, transformed_factors, theta_params, method_name):\n",
    "        \"\"\"\n",
    "        Adapt DSGE priors to transformed factor space while preserving economic structure\n",
    "        \"\"\"\n",
    "        if self.dsge_priors is None:\n",
    "            return None\n",
    "            \n",
    "        # REMOVED: Repetitive print statement that was causing repeated output\n",
    "        # Only print the method name once at the beginning\n",
    "        if not hasattr(self, '_adaptation_logged'):\n",
    "            print(f\"  Adapting DSGE priors for {method_name} transformation...\")\n",
    "            self._adaptation_logged = True\n",
    "        \n",
    "        # Get original prior structure\n",
    "        base_priors = self.base_factor_var.get('prior_info')\n",
    "        if base_priors is None:\n",
    "            # FIXED: Create prior structure from DSGE estimates if not available\n",
    "            return self._construct_priors_from_dsge_estimates(transformed_factors, theta_params)\n",
    "            \n",
    "        # Calculate transformation scaling factors for each factor\n",
    "        original_factors = self.factors.values\n",
    "        theta_factors = transformed_factors.values if hasattr(transformed_factors, 'values') else transformed_factors\n",
    "        \n",
    "        scaling_factors = []\n",
    "        for i in range(self.n_factors):\n",
    "            orig_std = np.std(original_factors[:, i])\n",
    "            theta_std = np.std(theta_factors[:, i])\n",
    "            if orig_std > 0:\n",
    "                scaling_factors.append(theta_std / orig_std)\n",
    "            else:\n",
    "                scaling_factors.append(1.0)\n",
    "        \n",
    "        # Adapt prior means and variances\n",
    "        adapted_prior_mean = base_priors['mean'].copy()\n",
    "        adapted_prior_var = base_priors['variance'].copy()\n",
    "        \n",
    "        # Adjust VAR coefficient priors based on transformation scaling\n",
    "        K = self.n_factors\n",
    "        lags = self.base_factor_var['lags']\n",
    "        \n",
    "        # Skip constants, adjust VAR coefficients\n",
    "        coeff_start = K\n",
    "        for lag in range(1, lags + 1):\n",
    "            for i in range(K):  # Each factor equation\n",
    "                for j in range(K):  # Each factor lag\n",
    "                    coeff_idx = coeff_start + (lag-1)*K*K + i*K + j\n",
    "                    if coeff_idx < len(adapted_prior_mean):\n",
    "                        # Scale coefficient priors by transformation ratios\n",
    "                        scale_ratio = scaling_factors[i] / scaling_factors[j]\n",
    "                        adapted_prior_mean[coeff_idx] *= scale_ratio\n",
    "                        # Increase uncertainty for transformed relationships\n",
    "                        adapted_prior_var[coeff_idx] *= (1.0 + 0.1 * abs(1 - scale_ratio))\n",
    "        \n",
    "        # REMOVED: The repetitive print statement that was at the end\n",
    "        \n",
    "        return {\n",
    "            'mean': adapted_prior_mean,\n",
    "            'variance': adapted_prior_var,\n",
    "            'dsge_params': base_priors.get('dsge_params', {}),\n",
    "            'scaling_factors': scaling_factors\n",
    "        }\n",
    "\n",
    "    def _construct_priors_from_dsge_estimates(self, transformed_factors, theta_params):\n",
    "        \"\"\"\n",
    "        FIXED: Construct VAR priors directly from DSGE posterior estimates when prior_info unavailable\n",
    "        \"\"\"\n",
    "        if self.dsge_priors is None:\n",
    "            return None\n",
    "            \n",
    "        print(f\"  Constructing priors from DSGE posterior estimates...\")\n",
    "        \n",
    "        K = self.n_factors\n",
    "        lags = self.base_factor_var['lags']\n",
    "        n_coeffs = K * K * lags + K  # VAR coeffs + constants\n",
    "        \n",
    "        # Extract key DSGE parameters (using posterior means)\n",
    "        dsge_params = {}\n",
    "        for param_name in ['sigma', 'theta', 'phi_pi', 'phi_y', 'rho_a', 'rho_v']:\n",
    "            if param_name in self.dsge_priors:\n",
    "                # Get posterior mean as point estimate\n",
    "                dsge_params[param_name] = self.dsge_priors[param_name]['mean']\n",
    "        \n",
    "        # Construct theory-consistent priors\n",
    "        prior_mean = np.zeros(n_coeffs)\n",
    "        prior_var = np.ones(n_coeffs)\n",
    "        \n",
    "        # Constants (intercepts) - weakly informative\n",
    "        prior_var[:K] = 1.0\n",
    "        \n",
    "        # VAR coefficient priors based on DSGE structure\n",
    "        coeff_start = K\n",
    "        \n",
    "        for lag in range(1, lags + 1):\n",
    "            for i in range(K):  # Each factor equation\n",
    "                for j in range(K):  # Each factor lag\n",
    "                    coeff_idx = coeff_start + (lag-1)*K*K + i*K + j\n",
    "                    \n",
    "                    if coeff_idx >= n_coeffs:\n",
    "                        continue\n",
    "                        \n",
    "                    if i == j:  # Own lags\n",
    "                        if lag == 1:\n",
    "                            # First own lag - use DSGE persistence parameters\n",
    "                            if i == 0:  # Demand factor - related to output persistence\n",
    "                                prior_mean[coeff_idx] = dsge_params.get('rho_a', 0.5) * 0.7\n",
    "                                prior_var[coeff_idx] = 0.1\n",
    "                            elif i == 1:  # Supply factor - related to price stickiness\n",
    "                                stickiness = dsge_params.get('theta', 0.7)\n",
    "                                prior_mean[coeff_idx] = min(0.9, stickiness * 1.2)\n",
    "                                prior_var[coeff_idx] = 0.1\n",
    "                            else:  # Monetary factor - use monetary persistence\n",
    "                                prior_mean[coeff_idx] = dsge_params.get('rho_v', 0.3)\n",
    "                                prior_var[coeff_idx] = 0.15\n",
    "                        else:\n",
    "                            # Higher order own lags - decay\n",
    "                            first_lag_idx = coeff_start + (i*K + j)\n",
    "                            if first_lag_idx < len(prior_mean):\n",
    "                                prior_mean[coeff_idx] = prior_mean[first_lag_idx] * 0.5\n",
    "                            prior_var[coeff_idx] = 0.2\n",
    "                    else:  # Cross-lags\n",
    "                        if lag == 1:\n",
    "                            # Theory-based cross-effects\n",
    "                            if (i == 0 and j == 2):  # Monetary -> Demand (IS curve)\n",
    "                                prior_mean[coeff_idx] = -1.0 / dsge_params.get('sigma', 1.0) * 0.1\n",
    "                                prior_var[coeff_idx] = 0.05\n",
    "                            elif (i == 1 and j == 0):  # Demand -> Supply (Phillips curve)  \n",
    "                                prior_mean[coeff_idx] = dsge_params.get('phi_y', 0.5) * 0.2\n",
    "                                prior_var[coeff_idx] = 0.05\n",
    "                            elif (i == 2 and j == 1):  # Supply -> Monetary (Taylor rule)\n",
    "                                prior_mean[coeff_idx] = dsge_params.get('phi_pi', 1.5) * 0.1\n",
    "                                prior_var[coeff_idx] = 0.05\n",
    "                            else:\n",
    "                                prior_mean[coeff_idx] = 0.0\n",
    "                                prior_var[coeff_idx] = 0.1\n",
    "                        else:\n",
    "                            # Higher order cross-lags - shrink to zero\n",
    "                            prior_mean[coeff_idx] = 0.0\n",
    "                            prior_var[coeff_idx] = 0.1 / lag\n",
    "        \n",
    "        return {\n",
    "            'mean': prior_mean,\n",
    "            'variance': prior_var,\n",
    "            'dsge_params': dsge_params\n",
    "        }\n",
    "\n",
    "    def _estimate_theta_aware_var(self, transformed_factors, theta_params, method_name):\n",
    "        \"\"\"\n",
    "        Estimate VAR on transformed factors using adapted DSGE priors\n",
    "        \"\"\"\n",
    "        F_theta = transformed_factors.values if hasattr(transformed_factors, 'values') else transformed_factors\n",
    "        \n",
    "        # Get adapted DSGE priors\n",
    "        adapted_priors = self._adapt_dsge_priors_to_theta(transformed_factors, theta_params, method_name)\n",
    "        \n",
    "        if adapted_priors is not None and self.dsge_priors is not None:\n",
    "            # Bayesian estimation with adapted priors\n",
    "            return self._estimate_bayesian_var_theta(F_theta, adapted_priors)\n",
    "        else:\n",
    "            # OLS fallback\n",
    "            return self._estimate_var_ols(F_theta, self.base_factor_var['lags'])\n",
    "\n",
    "    def _estimate_bayesian_var_theta(self, F_theta, adapted_priors):\n",
    "        \"\"\"\n",
    "        Bayesian VAR estimation for theta-transformed factors with adapted DSGE priors\n",
    "        \"\"\"\n",
    "        T, K = F_theta.shape\n",
    "        lags = self.base_factor_var['lags']\n",
    "        \n",
    "        # Construct regression matrices\n",
    "        Y = F_theta[lags:, :]\n",
    "        T_eff = Y.shape[0]\n",
    "        \n",
    "        # Design matrix\n",
    "        X = np.ones((T_eff, 1))  # Constant\n",
    "        for lag in range(1, lags + 1):\n",
    "            X = np.hstack([X, F_theta[lags-lag:-lag, :]])\n",
    "        \n",
    "        n_regressors = X.shape[1]\n",
    "        \n",
    "        # Prior parameters (adapted)\n",
    "        beta_prior = adapted_priors['mean'][:n_regressors*K].reshape(-1, 1)\n",
    "        V_prior = np.diag(adapted_priors['variance'][:n_regressors*K])\n",
    "        \n",
    "        # Bayesian updating\n",
    "        V_prior_inv = np.linalg.inv(V_prior)\n",
    "        XtX = X.T @ X\n",
    "        \n",
    "        # Posterior covariance and mean\n",
    "        V_posterior_inv = V_prior_inv + np.kron(np.eye(K), XtX)\n",
    "        V_posterior = np.linalg.inv(V_posterior_inv)\n",
    "        \n",
    "        XtY = X.T @ Y\n",
    "        beta_posterior_vec = V_posterior @ (V_prior_inv @ beta_prior + XtY.flatten('F').reshape(-1, 1))\n",
    "        beta_posterior = beta_posterior_vec.reshape((n_regressors, K), order='F')\n",
    "        \n",
    "        # Residuals and covariance\n",
    "        Y_fitted = X @ beta_posterior\n",
    "        residuals = Y - Y_fitted\n",
    "        sigma_u = (residuals.T @ residuals) / T_eff\n",
    "        \n",
    "        # Coefficient matrices\n",
    "        const = beta_posterior[0, :]\n",
    "        var_coeffs = beta_posterior[1:, :].T\n",
    "        \n",
    "        # Model statistics\n",
    "        log_likelihood = self._compute_log_likelihood(residuals, sigma_u)\n",
    "        \n",
    "        return {\n",
    "            'coefficients': var_coeffs,\n",
    "            'constant': const,\n",
    "            'sigma_u': sigma_u,\n",
    "            'residuals': residuals,\n",
    "            'log_likelihood': log_likelihood,\n",
    "            'lags': lags,\n",
    "            'T_eff': T_eff,\n",
    "            'bayesian': True,\n",
    "            'adapted_priors': adapted_priors,\n",
    "            'theta_informed': True\n",
    "        }\n",
    "\n",
    "    def _estimate_var_ols(self, F_theta, lags):\n",
    "        \"\"\"OLS VAR estimation fallback\"\"\"\n",
    "        T, K = F_theta.shape\n",
    "        \n",
    "        # Construct regression matrices\n",
    "        Y = F_theta[lags:, :]\n",
    "        T_eff = Y.shape[0]\n",
    "        \n",
    "        X = np.ones((T_eff, 1))\n",
    "        for lag in range(1, lags + 1):\n",
    "            X = np.hstack([X, F_theta[lags-lag:-lag, :]])\n",
    "        \n",
    "        # OLS estimation\n",
    "        XtX_inv = np.linalg.inv(X.T @ X)\n",
    "        beta = XtX_inv @ X.T @ Y\n",
    "        \n",
    "        u = Y - X @ beta\n",
    "        sigma_u = (u.T @ u) / T_eff\n",
    "        \n",
    "        const = beta[0, :]\n",
    "        var_coeffs = beta[1:, :].T\n",
    "        \n",
    "        log_likelihood = self._compute_log_likelihood(u, sigma_u)\n",
    "        \n",
    "        return {\n",
    "            'coefficients': var_coeffs,\n",
    "            'constant': const,\n",
    "            'sigma_u': sigma_u,\n",
    "            'residuals': u,\n",
    "            'log_likelihood': log_likelihood,\n",
    "            'lags': lags,\n",
    "            'T_eff': T_eff,\n",
    "            'bayesian': False,\n",
    "            'theta_informed': True\n",
    "        }\n",
    "\n",
    "    def _compute_log_likelihood(self, residuals, sigma_u):\n",
    "        \"\"\"Compute VAR log-likelihood\"\"\"\n",
    "        T, K = residuals.shape\n",
    "        log_likelihood = -0.5 * T * K * np.log(2 * np.pi)\n",
    "        log_likelihood -= 0.5 * T * np.log(np.linalg.det(sigma_u))\n",
    "        log_likelihood -= 0.5 * np.trace(residuals.T @ residuals @ np.linalg.inv(sigma_u))\n",
    "        return log_likelihood\n",
    "\n",
    "    # ============================================================================\n",
    "    # THETA TRANSFORMATION METHODS (unchanged from original)\n",
    "    # ============================================================================\n",
    "\n",
    "    def dsge_constrained_hp_method(self):\n",
    "        \"\"\"\n",
    "        HP filter with DSGE-consistent constraints on trend-cycle decomposition\n",
    "        \"\"\"\n",
    "        print(\"Running DSGE-Constrained HP Trend-Cycle Method...\")\n",
    "        \n",
    "        def theta_transform(factors, theta_params):\n",
    "            F_theta_df = factors.copy()\n",
    "            for i, factor_name in enumerate(factors.columns):\n",
    "                trend, cycle = self._hp_filter(factors[factor_name])\n",
    "                theta1, theta2 = theta_params[i], theta_params[i + self.n_factors]\n",
    "                F_theta_df[factor_name] = theta1 * trend + theta2 * cycle\n",
    "            return F_theta_df\n",
    "        \n",
    "        def objective(theta_vector):\n",
    "            theta1s = theta_vector[:self.n_factors]  # Trend weights\n",
    "            theta2s = theta_vector[self.n_factors:]  # Cycle weights\n",
    "            \n",
    "            # DSGE-consistent constraints\n",
    "            if self.dsge_priors is not None:\n",
    "                # Use DSGE persistence parameters to guide trend-cycle weights\n",
    "                dsge_params = {k: v['mean'] for k, v in self.dsge_priors.items()}\n",
    "                \n",
    "                # High persistence factors should weight trends more heavily\n",
    "                persistence_penalty = 0.0\n",
    "                for i in range(self.n_factors):\n",
    "                    if i == 0:  # Demand factor\n",
    "                        target_persistence = dsge_params.get('rho_a', 0.5)\n",
    "                        trend_target = 0.3 + 0.4 * target_persistence\n",
    "                        cycle_target = 1.2 - 0.3 * target_persistence\n",
    "                    elif i == 1:  # Supply factor  \n",
    "                        price_stickiness = dsge_params.get('theta', 0.7)\n",
    "                        trend_target = 0.2 + 0.5 * price_stickiness\n",
    "                        cycle_target = 1.3 - 0.4 * price_stickiness\n",
    "                    else:  # Monetary factor\n",
    "                        monetary_persistence = dsge_params.get('rho_v', 0.3)\n",
    "                        trend_target = 0.4 + 0.3 * monetary_persistence\n",
    "                        cycle_target = 1.1 - 0.2 * monetary_persistence\n",
    "                    \n",
    "                    persistence_penalty += 0.3 * ((theta1s[i] - trend_target)**2 + \n",
    "                                                 (theta2s[i] - cycle_target)**2)\n",
    "            else:\n",
    "                # Standard economic constraints if no DSGE priors\n",
    "                persistence_penalty = 0.2 * (np.sum((theta1s - 0.4)**2) + \n",
    "                                            np.sum((theta2s - 1.1)**2))\n",
    "            \n",
    "            # Complementary weighting\n",
    "            target_sum = 1.5\n",
    "            complementary_penalty = 0.4 * np.sum((theta1s + theta2s - target_sum)**2)\n",
    "            \n",
    "            # Estimate VAR on transformed factors\n",
    "            F_theta = theta_transform(self.factors, theta_vector)\n",
    "            theta_var = self._estimate_theta_aware_var(F_theta, theta_vector, 'HP_Trend_Cycle')\n",
    "            \n",
    "            # Use original loadings (don't re-estimate)\n",
    "            Y_reconstructed = F_theta.values @ self.loadings.values.T\n",
    "            reconstruction_error = np.mean((self.data_standardized.values - Y_reconstructed)**2)\n",
    "            \n",
    "            return reconstruction_error + persistence_penalty + complementary_penalty\n",
    "        \n",
    "        # DSGE-informed bounds\n",
    "        if self.dsge_priors is not None:\n",
    "            dsge_params = {k: v['mean'] for k, v in self.dsge_priors.items()}\n",
    "            bounds = []\n",
    "            \n",
    "            for i in range(self.n_factors):\n",
    "                if i == 0:  # Demand - based on technology persistence\n",
    "                    persistence = dsge_params.get('rho_a', 0.5)\n",
    "                    bounds.append((0.2, 0.3 + 0.5 * persistence))\n",
    "                elif i == 1:  # Supply - based on price stickiness\n",
    "                    stickiness = dsge_params.get('theta', 0.7)\n",
    "                    bounds.append((0.1, 0.4 + 0.4 * stickiness))\n",
    "                else:  # Monetary\n",
    "                    bounds.append((0.2, 0.6))\n",
    "            \n",
    "            for i in range(self.n_factors):\n",
    "                bounds.append((0.8, 1.8))  # Cycle weights\n",
    "                \n",
    "            initial_guess = []\n",
    "            for i in range(self.n_factors):\n",
    "                initial_guess.append((bounds[i][0] + bounds[i][1]) / 2)\n",
    "            initial_guess.extend([1.2] * self.n_factors)\n",
    "        else:\n",
    "            # Standard bounds\n",
    "            bounds = [(0.2, 0.7) for _ in range(self.n_factors)] + [(0.8, 2.0) for _ in range(self.n_factors)]\n",
    "            initial_guess = [0.4] * self.n_factors + [1.1] * self.n_factors\n",
    "        \n",
    "        result = minimize(objective, initial_guess, bounds=bounds, method='L-BFGS-B')\n",
    "        return result.x if result.success else initial_guess, theta_transform\n",
    "\n",
    "    def dsge_regime_switching_method(self):\n",
    "        \"\"\"\n",
    "        Regime-switching transformation informed by DSGE structural breaks\n",
    "        \"\"\"\n",
    "        print(\"Running DSGE-Informed Regime Switching Method...\")\n",
    "        \n",
    "        def theta_transform(factors, theta_params):\n",
    "            F_theta_df = factors.copy()\n",
    "            for i, factor_name in enumerate(factors.columns):\n",
    "                factor_vals = factors[factor_name].values\n",
    "                theta1, theta2, threshold = (theta_params[i], \n",
    "                                           theta_params[i + self.n_factors],\n",
    "                                           theta_params[i + 2*self.n_factors])\n",
    "                \n",
    "                # Piecewise linear with DSGE-consistent regime interpretation\n",
    "                F_theta_df[factor_name] = np.where(factor_vals <= threshold,\n",
    "                                                 theta1 * factor_vals,\n",
    "                                                 theta1 * threshold + theta2 * (factor_vals - threshold))\n",
    "            return F_theta_df\n",
    "        \n",
    "        def objective(theta_vector):\n",
    "            theta1s = theta_vector[:self.n_factors]\n",
    "            theta2s = theta_vector[self.n_factors:2*self.n_factors]\n",
    "            thresholds = theta_vector[2*self.n_factors:]\n",
    "            \n",
    "            # DSGE-informed regime constraints\n",
    "            if self.dsge_priors is not None:\n",
    "                dsge_params = {k: v['mean'] for k, v in self.dsge_priors.items()}\n",
    "                \n",
    "                # Different regimes should reflect DSGE parameter uncertainty\n",
    "                regime_penalty = 0.0\n",
    "                for i in range(self.n_factors):\n",
    "                    if i == 0:  # Demand factor - high vs low growth regimes\n",
    "                        sigma_param = dsge_params.get('sigma', 1.0)\n",
    "                        regime1_target = 0.8 - 0.2 * (sigma_param - 1.0)  # Risk aversion effect\n",
    "                        regime2_target = 1.2 + 0.3 * (sigma_param - 1.0)\n",
    "                    elif i == 1:  # Supply factor - flexible vs sticky regimes\n",
    "                        theta_param = dsge_params.get('theta', 0.7)\n",
    "                        regime1_target = 0.6 + 0.4 * theta_param  # Sticky regime\n",
    "                        regime2_target = 1.4 - 0.3 * theta_param  # Flexible regime\n",
    "                    else:  # Monetary factor - accommodative vs restrictive\n",
    "                        phi_pi = dsge_params.get('phi_pi', 1.5)\n",
    "                        regime1_target = 0.7 + 0.1 * (phi_pi - 1.5)  # Accommodative\n",
    "                        regime2_target = 1.3 + 0.2 * (phi_pi - 1.5)  # Restrictive\n",
    "                    \n",
    "                    regime_penalty += 0.4 * ((theta1s[i] - regime1_target)**2 + \n",
    "                                           (theta2s[i] - regime2_target)**2)\n",
    "            else:\n",
    "                regime_penalty = 0.3 * (np.sum((theta1s - 0.7)**2) + np.sum((theta2s - 1.3)**2))\n",
    "            \n",
    "            # Minimum regime separation\n",
    "            separation_penalty = 0.6 * np.sum(np.maximum(0, 0.3 - np.abs(theta1s - theta2s))**2)\n",
    "            \n",
    "            F_theta = theta_transform(self.factors, theta_vector)\n",
    "            theta_var = self._estimate_theta_aware_var(F_theta, theta_vector, 'Regime_Switching')\n",
    "            \n",
    "            Y_reconstructed = F_theta.values @ self.loadings.values.T\n",
    "            reconstruction_error = np.mean((self.data_standardized.values - Y_reconstructed)**2)\n",
    "            \n",
    "            return reconstruction_error + regime_penalty + separation_penalty\n",
    "        \n",
    "        # Set bounds using factor medians and DSGE guidance\n",
    "        factor_medians = [self.factors.iloc[:, i].median() for i in range(self.n_factors)]\n",
    "        \n",
    "        if self.dsge_priors is not None:\n",
    "            dsge_params = {k: v['mean'] for k, v in self.dsge_priors.items()}\n",
    "            bounds = []\n",
    "            \n",
    "            # Regime 1 bounds (informed by DSGE)\n",
    "            for i in range(self.n_factors):\n",
    "                if i == 0:  # Demand\n",
    "                    bounds.append((0.5, 1.0))\n",
    "                elif i == 1:  # Supply\n",
    "                    theta_param = dsge_params.get('theta', 0.7)\n",
    "                    bounds.append((0.4 + 0.2 * theta_param, 1.0 + 0.2 * theta_param))\n",
    "                else:  # Monetary\n",
    "                    bounds.append((0.6, 1.1))\n",
    "            \n",
    "            # Regime 2 bounds\n",
    "            for i in range(self.n_factors):\n",
    "                bounds.append((1.0, 1.8))\n",
    "            \n",
    "            # Threshold bounds\n",
    "            for med in factor_medians:\n",
    "                bounds.append((med - 0.6, med + 0.6))\n",
    "        else:\n",
    "            bounds = ([(0.4, 1.0) for _ in range(self.n_factors)] +\n",
    "                     [(1.0, 1.8) for _ in range(self.n_factors)] +\n",
    "                     [(med - 0.8, med + 0.8) for med in factor_medians])\n",
    "        \n",
    "        initial_guess = ([0.7] * self.n_factors + [1.3] * self.n_factors + factor_medians)\n",
    "        \n",
    "        result = minimize(objective, initial_guess, bounds=bounds, method='L-BFGS-B')\n",
    "        return result.x if result.success else initial_guess, theta_transform\n",
    "\n",
    "    def dsge_time_varying_method(self):\n",
    "        \"\"\"\n",
    "        Time-varying theta with evolution guided by DSGE parameter stability\n",
    "        \"\"\"\n",
    "        print(\"Running DSGE-Informed Time-Varying Method...\")\n",
    "        \n",
    "        def theta_transform(factors, theta_params):\n",
    "            F_theta_df = factors.copy()\n",
    "            T = len(factors)\n",
    "            \n",
    "            for i, factor_name in enumerate(factors.columns):\n",
    "                theta_init = theta_params[i]\n",
    "                theta_final = theta_params[i + self.n_factors]\n",
    "                midpoint = theta_params[i + 2*self.n_factors]\n",
    "                speed = theta_params[i + 3*self.n_factors]\n",
    "                \n",
    "                t_vals = np.arange(T)\n",
    "                theta_t = theta_init + (theta_final - theta_init) / (1 + np.exp(-speed * (t_vals - midpoint)))\n",
    "                \n",
    "                trend = self._extract_trend_linear(factors[factor_name])\n",
    "                deviation = factors[factor_name] - trend\n",
    "                F_theta_df[factor_name] = trend + theta_t * deviation\n",
    "                \n",
    "            return F_theta_df\n",
    "        \n",
    "        def objective(theta_vector):\n",
    "            theta_inits = theta_vector[:self.n_factors]\n",
    "            theta_finals = theta_vector[self.n_factors:2*self.n_factors]\n",
    "            midpoints = theta_vector[2*self.n_factors:3*self.n_factors]\n",
    "            speeds = theta_vector[3*self.n_factors:]\n",
    "            \n",
    "            # DSGE-consistent time variation\n",
    "            if self.dsge_priors is not None:\n",
    "                dsge_params = {k: v['mean'] for k, v in self.dsge_priors.items()}\n",
    "                \n",
    "                evolution_penalty = 0.0\n",
    "                for i in range(self.n_factors):\n",
    "                    if i == 0:  # Demand factor evolution\n",
    "                        tech_persistence = dsge_params.get('rho_a', 0.5)\n",
    "                        init_target = 0.7 + 0.2 * tech_persistence\n",
    "                        final_target = 1.1 + 0.1 * (1 - tech_persistence)\n",
    "                    elif i == 1:  # Supply factor evolution\n",
    "                        price_flexibility = 1 - dsge_params.get('theta', 0.7)\n",
    "                        init_target = 0.8 - 0.2 * price_flexibility\n",
    "                        final_target = 1.2 + 0.3 * price_flexibility\n",
    "                    else:  # Monetary factor evolution\n",
    "                        policy_response = dsge_params.get('phi_pi', 1.5) - 1.0\n",
    "                        init_target = 0.6 + 0.2 * policy_response\n",
    "                        final_target = 1.0 + 0.2 * policy_response\n",
    "                    \n",
    "                    evolution_penalty += 0.3 * ((theta_inits[i] - init_target)**2 + \n",
    "                                               (theta_finals[i] - final_target)**2)\n",
    "            else:\n",
    "                evolution_penalty = 0.2 * (np.sum((theta_inits - 0.8)**2) + np.sum((theta_finals - 1.2)**2))\n",
    "            \n",
    "            # Minimum meaningful evolution\n",
    "            min_evolution = 0.25\n",
    "            evolution_constraint = 0.5 * np.sum(np.maximum(0, min_evolution - np.abs(theta_finals - theta_inits))**2)\n",
    "            \n",
    "            # Speed constraints - not too abrupt for economic factors\n",
    "            speed_penalty = 0.2 * (np.sum(np.maximum(0, 0.03 - speeds)**2) + \n",
    "                                  np.sum(np.maximum(0, speeds - 0.10)**2))\n",
    "            \n",
    "            F_theta = theta_transform(self.factors, theta_vector)\n",
    "            theta_var = self._estimate_theta_aware_var(F_theta, theta_vector, 'Time_Varying')\n",
    "            \n",
    "            Y_reconstructed = F_theta.values @ self.loadings.values.T\n",
    "            reconstruction_error = np.mean((self.data_standardized.values - Y_reconstructed)**2)\n",
    "            \n",
    "            return reconstruction_error + evolution_penalty + evolution_constraint + speed_penalty\n",
    "        \n",
    "        T_mid = self.T_obs // 2\n",
    "        \n",
    "        if self.dsge_priors is not None:\n",
    "            # DSGE-informed bounds and initialization\n",
    "            dsge_params = {k: v['mean'] for k, v in self.dsge_priors.items()}\n",
    "            \n",
    "            init_bounds = []\n",
    "            final_bounds = []\n",
    "            \n",
    "            for i in range(self.n_factors):\n",
    "                if i == 0:  # Demand\n",
    "                    persistence = dsge_params.get('rho_a', 0.5)\n",
    "                    init_bounds.append((0.5 + 0.2 * persistence, 1.0 + 0.1 * persistence))\n",
    "                    final_bounds.append((0.9, 1.3 + 0.2 * (1 - persistence)))\n",
    "                elif i == 1:  # Supply\n",
    "                    flexibility = 1 - dsge_params.get('theta', 0.7)\n",
    "                    init_bounds.append((0.6, 1.0 - 0.1 * flexibility))\n",
    "                    final_bounds.append((1.0 + 0.2 * flexibility, 1.5 + 0.1 * flexibility))\n",
    "                else:  # Monetary\n",
    "                    init_bounds.append((0.5, 0.9))\n",
    "                    final_bounds.append((0.9, 1.3))\n",
    "            \n",
    "            bounds = (init_bounds + final_bounds + \n",
    "                     [(T_mid*0.7, T_mid*1.3) for _ in range(self.n_factors)] +\n",
    "                     [(0.04, 0.08) for _ in range(self.n_factors)])\n",
    "            \n",
    "            initial_guess = []\n",
    "            for i in range(self.n_factors):\n",
    "                initial_guess.append((init_bounds[i][0] + init_bounds[i][1]) / 2)\n",
    "            for i in range(self.n_factors):\n",
    "                initial_guess.append((final_bounds[i][0] + final_bounds[i][1]) / 2)\n",
    "            initial_guess.extend([T_mid] * self.n_factors)\n",
    "            initial_guess.extend([0.06] * self.n_factors)\n",
    "        else:\n",
    "            bounds = ([(0.5, 1.1) for _ in range(self.n_factors)] +\n",
    "                     [(0.9, 1.5) for _ in range(self.n_factors)] +\n",
    "                     [(T_mid*0.6, T_mid*1.4) for _ in range(self.n_factors)] +\n",
    "                     [(0.03, 0.12) for _ in range(self.n_factors)])\n",
    "            \n",
    "            initial_guess = ([0.8] * self.n_factors + [1.2] * self.n_factors +\n",
    "                           [T_mid] * self.n_factors + [0.06] * self.n_factors)\n",
    "        \n",
    "        result = minimize(objective, initial_guess, bounds=bounds, method='L-BFGS-B')\n",
    "        return result.x if result.success else initial_guess, theta_transform\n",
    "\n",
    "    # ============================================================================\n",
    "    # HELPER METHODS\n",
    "    # ============================================================================\n",
    "\n",
    "    def _hp_filter(self, series, lamb=1600):\n",
    "        \"\"\"Hodrick-Prescott filter\"\"\"\n",
    "        n = len(series)\n",
    "        I = np.eye(n)\n",
    "        D2 = np.diff(np.eye(n), 2, axis=0)\n",
    "        trend = np.linalg.solve(I + lamb * D2.T @ D2, series.values)\n",
    "        cycle = series.values - trend\n",
    "        return pd.Series(trend, index=series.index), pd.Series(cycle, index=series.index)\n",
    "\n",
    "    def _extract_trend_linear(self, series):\n",
    "        \"\"\"Extract linear trend\"\"\"\n",
    "        n = len(series)\n",
    "        x = np.arange(n)\n",
    "        X = np.column_stack([np.ones(n), x])\n",
    "        coeffs = np.linalg.lstsq(X, series.values, rcond=None)[0]\n",
    "        return pd.Series(coeffs[0] + coeffs[1] * x, index=series.index)\n",
    "\n",
    "    # ============================================================================\n",
    "    # FORECASTING AND EVALUATION (unchanged from original)\n",
    "    # ============================================================================\n",
    "\n",
    "    def evaluate_theta_method(self, method_name, theta_params, theta_func, horizon=8):\n",
    "        \"\"\"\n",
    "        Evaluate theta method using DSGE-consistent approach:\n",
    "        MODIFIED: Now includes detailed variable-level CV analysis\n",
    "        \"\"\"\n",
    "        print(f\"Evaluating {method_name} with DSGE consistency...\")\n",
    "        \n",
    "        # Apply theta transformation\n",
    "        F_theta = theta_func(self.factors, theta_params)\n",
    "        \n",
    "        # Estimate theta-aware VAR with adapted DSGE priors\n",
    "        theta_var_model = self._estimate_theta_aware_var(F_theta, theta_params, method_name)\n",
    "        \n",
    "        # Calculate fit using ORIGINAL loadings (preserve economic structure)\n",
    "        Lambda_original = self.loadings.values  # N x K (PRESERVE)\n",
    "        Y_fitted = F_theta.values @ Lambda_original.T\n",
    "        residuals = self.data_standardized.values - Y_fitted\n",
    "        \n",
    "        # Variable R-squared with original loadings\n",
    "        variable_r2 = {}\n",
    "        for i, var_name in enumerate(self.data_standardized.columns):\n",
    "            ss_res = np.sum(residuals[:, i]**2)\n",
    "            ss_tot = np.sum((self.data_standardized.values[:, i] - \n",
    "                        np.mean(self.data_standardized.values[:, i]))**2)\n",
    "            r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "            variable_r2[var_name] = max(0, r2)\n",
    "        \n",
    "        # Generate forecasts using theta-aware VAR\n",
    "        theta_factor_forecasts = self._forecast_theta_var(F_theta, theta_var_model, horizon)\n",
    "        \n",
    "        # Variable forecasts using ORIGINAL loadings\n",
    "        F_theta_forecast = theta_factor_forecasts['mean'].values\n",
    "        X_forecast_std = F_theta_forecast @ Lambda_original.T\n",
    "        \n",
    "        # Transform back to original scale\n",
    "        X_forecast_original = self.scaler.inverse_transform(X_forecast_std)\n",
    "        \n",
    "        # Create forecast DataFrame\n",
    "        forecast_dates = pd.date_range(\n",
    "            start=self.factors.index[-1] + pd.DateOffset(months=3),\n",
    "            periods=horizon, freq='Q'\n",
    "        )\n",
    "        \n",
    "        variable_forecasts = pd.DataFrame(\n",
    "            X_forecast_original,\n",
    "            index=forecast_dates,\n",
    "            columns=self.combined_data.columns\n",
    "        )\n",
    "        \n",
    "        # Cross-validation metrics (DSGE-aware)\n",
    "        cv_metrics = self._cross_validate_dsge_theta_method(method_name, theta_func, theta_params)\n",
    "        \n",
    "        # ADDED: Detailed variable-level CV analysis like Document 2\n",
    "        variable_cv_metrics = self.detailed_variable_cv_analysis(method_name, theta_params, theta_func)\n",
    "        \n",
    "        return {\n",
    "            'theta_var_model': theta_var_model,\n",
    "            'variable_r2': variable_r2,\n",
    "            'forecasts': variable_forecasts,\n",
    "            'factor_forecasts': theta_factor_forecasts,\n",
    "            'cv_metrics': cv_metrics,\n",
    "            'variable_cv_metrics': variable_cv_metrics,  # ADDED THIS LINE\n",
    "            'theta_params': theta_params,\n",
    "            'theta_func': theta_func,\n",
    "            'preserved_loadings': True,\n",
    "            'dsge_informed': self.dsge_priors is not None\n",
    "        }\n",
    "\n",
    "    def _forecast_theta_var(self, F_theta, theta_var_model, horizon):\n",
    "        \"\"\"Generate forecasts using theta-aware VAR model\"\"\"\n",
    "        Phi = theta_var_model['coefficients']\n",
    "        c = theta_var_model['constant']\n",
    "        p = theta_var_model['lags']\n",
    "        K = Phi.shape[0]\n",
    "\n",
    "        forecasts = np.zeros((horizon, K))\n",
    "\n",
    "        if p == 1:\n",
    "            F_last = F_theta.values[-1, :]\n",
    "            for h in range(horizon):\n",
    "                if h == 0:\n",
    "                    forecasts[h, :] = c + Phi @ F_last\n",
    "                else:\n",
    "                    forecasts[h, :] = c + Phi @ forecasts[h-1, :]\n",
    "        else:\n",
    "            F_history = F_theta.values[-p:, :].copy()\n",
    "            for h in range(horizon):\n",
    "                F_lagged = F_history.flatten('F')\n",
    "                F_forecast = c + Phi @ F_lagged\n",
    "                forecasts[h, :] = F_forecast\n",
    "                F_history = np.vstack([F_history[1:, :], F_forecast.reshape(1, -1)])\n",
    "\n",
    "        forecast_dates = pd.date_range(\n",
    "            start=self.factors.index[-1] + pd.DateOffset(months=3),\n",
    "            periods=horizon, freq='Q'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'mean': pd.DataFrame(forecasts, index=forecast_dates, columns=self.factors.columns)\n",
    "        }\n",
    "\n",
    "    def _cross_validate_dsge_theta_method(self, method_name, theta_func, theta_params):\n",
    "        \"\"\"Cross-validate theta method preserving DSGE structure throughout\"\"\"\n",
    "        cv_metrics = []\n",
    "        \n",
    "        for train_idx, test_idx in self.tscv.split(self.factors):\n",
    "            if len(test_idx) < 2:\n",
    "                continue\n",
    "                \n",
    "            # Split data maintaining temporal structure\n",
    "            factors_train = self.factors.iloc[train_idx]\n",
    "            factors_test = self.factors.iloc[test_idx]\n",
    "            data_train = self.data_standardized.iloc[train_idx]\n",
    "            data_test = self.data_standardized.iloc[test_idx]\n",
    "            \n",
    "            try:\n",
    "                # Apply theta transformation to training factors\n",
    "                F_theta_train = theta_func(factors_train, theta_params)\n",
    "                F_theta_test = theta_func(factors_test, theta_params)\n",
    "                \n",
    "                # Estimate theta-aware VAR on training data with DSGE priors\n",
    "                theta_var_cv = self._estimate_theta_aware_var(F_theta_train, theta_params, method_name)\n",
    "                \n",
    "                # Generate forecasts using theta VAR\n",
    "                test_forecasts = self._forecast_theta_var(F_theta_test, theta_var_cv, len(test_idx))\n",
    "                F_theta_forecast = test_forecasts['mean'].values\n",
    "                \n",
    "                # Use ORIGINAL loadings for variable forecasts (preserve structure)\n",
    "                X_pred = F_theta_forecast @ self.loadings.values.T\n",
    "                \n",
    "                # Calculate metrics\n",
    "                metrics = self._calculate_forecast_metrics(data_test.values, X_pred)\n",
    "                cv_metrics.append(metrics)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"CV fold failed for {method_name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if cv_metrics:\n",
    "            # Average across folds\n",
    "            avg_metrics = {}\n",
    "            for metric in cv_metrics[0].keys():\n",
    "                values = [fold[metric] for fold in cv_metrics if not np.isnan(fold[metric])]\n",
    "                avg_metrics[metric] = np.mean(values) if values else np.nan\n",
    "            return avg_metrics\n",
    "        \n",
    "        return {'RMSE': np.nan, 'MAE': np.nan, 'MAPE': np.nan, 'R2': np.nan}\n",
    "\n",
    "    def _calculate_forecast_metrics(self, y_true, y_pred):\n",
    "        \"\"\"Calculate forecast accuracy metrics\"\"\"\n",
    "        y_true_flat = y_true.flatten()\n",
    "        y_pred_flat = y_pred.flatten()\n",
    "        \n",
    "        mask = ~(np.isnan(y_true_flat) | np.isnan(y_pred_flat))\n",
    "        y_true_clean = y_true_flat[mask]\n",
    "        y_pred_clean = y_pred_flat[mask]\n",
    "        \n",
    "        if len(y_true_clean) == 0:\n",
    "            return {'RMSE': np.nan, 'MAE': np.nan, 'MAPE': np.nan, 'R2': np.nan}\n",
    "        \n",
    "        # Basic metrics\n",
    "        rmse = np.sqrt(np.mean((y_true_clean - y_pred_clean)**2))\n",
    "        mae = np.mean(np.abs(y_true_clean - y_pred_clean))\n",
    "        \n",
    "        # MAPE\n",
    "        epsilon = 1e-8\n",
    "        mape = np.mean(np.abs((y_true_clean - y_pred_clean) / \n",
    "                            np.maximum(np.abs(y_true_clean), epsilon))) * 100\n",
    "        \n",
    "        # R-squared\n",
    "        ss_res = np.sum((y_true_clean - y_pred_clean)**2)\n",
    "        ss_tot = np.sum((y_true_clean - np.mean(y_true_clean))**2)\n",
    "        r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "        \n",
    "        return {'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2}\n",
    "\n",
    "    # ============================================================================\n",
    "    # MAIN EXECUTION METHODS (unchanged from original)\n",
    "    # ============================================================================\n",
    "\n",
    "    def run_dsge_theta_comparison(self, horizon=8):\n",
    "        \"\"\"Run all DSGE-informed theta methods and compare results\"\"\"\n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(\"DSGE-INFORMED THETA METHOD COMPARISON\")\n",
    "        print(\"=\"*100)\n",
    "        print(f\"Using {'Bayesian' if self.dsge_priors else 'OLS'} VAR with DSGE structure preservation\")\n",
    "\n",
    "        methods = {\n",
    "            'DSGE_HP_Trend_Cycle': self.dsge_constrained_hp_method,\n",
    "            'DSGE_Regime_Switching': self.dsge_regime_switching_method,\n",
    "            'DSGE_Time_Varying': self.dsge_time_varying_method,\n",
    "        }\n",
    "\n",
    "        all_results = {}\n",
    "\n",
    "        for method_name, method_func in methods.items():\n",
    "            print(f\"\\n--- {method_name} Method ---\")\n",
    "            try:\n",
    "                # Get optimal parameters and transformation function\n",
    "                theta_params, theta_func = method_func()\n",
    "                \n",
    "                # Evaluate method with DSGE consistency\n",
    "                results = self.evaluate_theta_method(method_name, theta_params, theta_func, horizon)\n",
    "                all_results[method_name] = results\n",
    "                \n",
    "                # Print summary\n",
    "                avg_r2 = np.mean(list(results['variable_r2'].values()))\n",
    "                cv_rmse = results['cv_metrics']['RMSE']\n",
    "                dsge_informed = \"Yes\" if results['dsge_informed'] else \"No\"\n",
    "                print(f\"Average R¬≤: {avg_r2:.3f}\")\n",
    "                print(f\"CV RMSE: {cv_rmse:.4f}\")\n",
    "                print(f\"DSGE-Informed: {dsge_informed}\")\n",
    "                print(f\"Original Loadings Preserved: {results['preserved_loadings']}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Method {method_name} failed: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        print(f\"Debug: run_dsge_theta_comparison returning: {list(all_results.keys())}\")\n",
    "        return all_results# REMOVED: No longer select best method here - return all results\n",
    "\n",
    "    def print_dsge_theta_results(self):\n",
    "        \"\"\"\n",
    "        Print comprehensive results preserving DSGE structure information\n",
    "        MODIFIED: Now includes call to variable-level CV results\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'method_results') or not self.method_results:\n",
    "            print(\"No results available\")\n",
    "            print(f\"Debug: method_results = {getattr(self, 'method_results', 'NOT SET')}\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*140)\n",
    "        print(\"DSGE-INFORMED THETA METHOD COMPARISON RESULTS\")\n",
    "        print(\"=\"*140)\n",
    "        \n",
    "        # Summary table\n",
    "        print(f\"\\n{'Method':<25} {'Avg R¬≤':<8} {'CV RMSE':<10} {'CV MAE':<10} {'CV MAPE':<10} {'DSGE':<6} {'Loadings':<9}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for method_name, results in self.method_results.items():\n",
    "            avg_r2 = np.mean(list(results['variable_r2'].values()))\n",
    "            cv_metrics = results['cv_metrics']\n",
    "            dsge_flag = \"Yes\" if results.get('dsge_informed', False) else \"No\"\n",
    "            loadings_flag = \"Original\" if results.get('preserved_loadings', False) else \"Re-est\"\n",
    "            \n",
    "            print(f\"{method_name:<25} {avg_r2:<8.3f} {cv_metrics['RMSE']:<10.4f} \"\n",
    "                f\"{cv_metrics['MAE']:<10.4f} {cv_metrics['MAPE']:<10.2f} \"\n",
    "                f\"{dsge_flag:<6} {loadings_flag:<9}\")\n",
    "        \n",
    "        # DSGE-specific information\n",
    "        if self.dsge_priors is not None:\n",
    "            print(f\"\\n\\n{'='*80}\")\n",
    "            print(\"DSGE PRIOR INTEGRATION SUMMARY\")\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            dsge_params = {k: v['mean'] for k, v in self.dsge_priors.items()}\n",
    "            if dsge_params:\n",
    "                print(\"DSGE Parameters Used:\")\n",
    "                for param, value in dsge_params.items():\n",
    "                    print(f\"  {param}: {value:.3f}\")\n",
    "            \n",
    "            print(f\"\\nStructural Consistency:\")\n",
    "            print(f\"  ‚Ä¢ Original factor loadings preserved: YES\")\n",
    "            print(f\"  ‚Ä¢ VAR priors adapted to theta transformations: YES\") \n",
    "            print(f\"  ‚Ä¢ Economic interpretation maintained: YES\")\n",
    "            print(f\"  ‚Ä¢ DSGE constraints applied to theta parameters: YES\")\n",
    "        \n",
    "        # Best method detailed results\n",
    "        if self.theta_strategy:\n",
    "            best_results = self.method_results[self.theta_strategy]\n",
    "            print(f\"\\n\\nDETAILED RESULTS FOR BEST METHOD: {self.theta_strategy}\")\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            print(\"\\nVariable Fit (using original DSGE-informed loadings):\")\n",
    "            print(\"-\"*60)\n",
    "            print(f\"{'Variable':<15} {'R¬≤':<8} {'Factor_1':<12} {'Factor_2':<12} {'Factor_3':<12}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            original_loadings = self.loadings  # These are the DSGE-informed loadings\n",
    "            for var_name in original_loadings.index:\n",
    "                r2 = best_results['variable_r2'].get(var_name, 0.0)\n",
    "                print(f\"{var_name:<15} {r2:<8.3f}\", end=\"\")\n",
    "                for j, factor in enumerate(original_loadings.columns):\n",
    "                    if j < 3:\n",
    "                        loading_val = original_loadings.loc[var_name, factor]\n",
    "                        print(f\" {loading_val:<12.3f}\", end=\"\")\n",
    "                print()\n",
    "            \n",
    "            avg_r2_best = np.mean(list(best_results['variable_r2'].values()))\n",
    "            print(f\"\\nAverage R¬≤ (Best Method): {avg_r2_best:.3f}\")\n",
    "            \n",
    "            # VAR model comparison\n",
    "            theta_var = best_results['theta_var_model']\n",
    "            base_var = self.base_factor_var\n",
    "            \n",
    "            print(f\"\\nVAR Model Comparison:\")\n",
    "            print(f\"  Base VAR Log-Likelihood: {base_var['log_likelihood']:.2f}\")\n",
    "            print(f\"  Theta VAR Log-Likelihood: {theta_var['log_likelihood']:.2f}\")\n",
    "            print(f\"  Improvement: {theta_var['log_likelihood'] - base_var['log_likelihood']:.2f}\")\n",
    "        \n",
    "        # ADDED: Call to print detailed variable-level CV results\n",
    "        self.print_variable_cv_results()\n",
    "\n",
    "    def run_complete_dsge_theta_analysis(self, strategy='auto', forecast_horizon=8):\n",
    "        \"\"\"Run complete DSGE-informed theta analysis\"\"\"\n",
    "        print(\"DSGE-INFORMED ENHANCED DFM-THETA ANALYSIS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        if self.dsge_priors is not None:\n",
    "            print(\"‚úì Using DSGE structural priors for VAR coefficient adaptation\")\n",
    "            print(\"‚úì Preserving original factor loadings throughout\")\n",
    "            print(\"‚úì Maintaining economic interpretation of factors\")\n",
    "        else:\n",
    "            print(\"! No DSGE priors available - using econometric constraints only\")\n",
    "\n",
    "        # Step 1: Run method comparison\n",
    "        if strategy == 'auto':\n",
    "            all_results = self.run_dsge_theta_comparison(forecast_horizon)\n",
    "            if not all_results:\n",
    "                print(\"No successful methods found, analysis cannot continue\")\n",
    "                return None\n",
    "                \n",
    "            # Store results first\n",
    "            self.method_results = all_results\n",
    "            print(f\"Debug: After assignment, method_results has: {list(self.method_results.keys())}\")\n",
    "\n",
    "            # NEW: Select best method after all analysis is complete\n",
    "            best_method, method_scores = self.select_best_method(all_results)\n",
    "            print(f\"Debug: After select_best_method, method_results has: {list(self.method_results.keys())}\")\n",
    "\n",
    "            # Set the selected method attributes\n",
    "            self.theta_strategy = best_method\n",
    "            if best_method in all_results:\n",
    "                self.optimal_theta = all_results[best_method]['theta_params']\n",
    "                \n",
    "        else:\n",
    "            # Run specific method (unchanged)\n",
    "            strategy_map = {\n",
    "                'dsge_hp_trend_cycle': self.dsge_constrained_hp_method,\n",
    "                'dsge_regime_switching': self.dsge_regime_switching_method,\n",
    "                'dsge_time_varying': self.dsge_time_varying_method,\n",
    "            }\n",
    "            \n",
    "            if strategy in strategy_map:\n",
    "                method_func = strategy_map[strategy]\n",
    "                theta_params, theta_func = method_func()\n",
    "                results = self.evaluate_theta_method(strategy.title(), theta_params, theta_func, forecast_horizon)\n",
    "                self.method_results = {strategy: results}\n",
    "                self.theta_strategy = strategy\n",
    "                self.optimal_theta = theta_params\n",
    "            else:\n",
    "                print(f\"Unknown strategy: {strategy}\")\n",
    "                return None\n",
    "\n",
    "        # Step 2: Print comprehensive results\n",
    "        self.print_dsge_theta_results()\n",
    "\n",
    "        # Step 3: Generate enhanced forecasts\n",
    "        if self.theta_strategy and self.theta_strategy in self.method_results:\n",
    "            best_results = self.method_results[self.theta_strategy]\n",
    "            \n",
    "            print(f\"\\n\\nDSGE-INFORMED FORECAST SUMMARY ({forecast_horizon} periods ahead):\")\n",
    "            print(\"=\"*90)\n",
    "            \n",
    "            forecasts_df = best_results['forecasts']\n",
    "            \n",
    "            print(f\"\\n{'Variable':<20} {'Latest Forecast':<15} {'CV RMSE':<10} {'Original R¬≤':<12}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            for var in forecasts_df.columns:\n",
    "                latest_forecast = forecasts_df[var].iloc[-1]\n",
    "                cv_rmse = best_results['cv_metrics'].get('RMSE', np.nan)\n",
    "                fit_r2 = best_results['variable_r2'].get(var, 0.0)\n",
    "                \n",
    "                print(f\"{var:<20} {latest_forecast:>14.2f} {cv_rmse:>9.4f} {fit_r2:>11.3f}\")\n",
    "\n",
    "        print(\"\\nDSGE-INFORMED ENHANCED DFM-THETA ANALYSIS COMPLETE\")\n",
    "        print(\"Key advantages:\")\n",
    "        print(\"‚Ä¢ Theta transformations respect DSGE economic structure\")\n",
    "        print(\"‚Ä¢ VAR priors properly adapted to transformed factor space\") \n",
    "        print(\"‚Ä¢ Original loadings preserved (no loss of economic interpretation)\")\n",
    "        print(\"‚Ä¢ Cross-validation accounts for DSGE temporal structure\")\n",
    "\n",
    "        return {\n",
    "            'strategy_used': self.theta_strategy,\n",
    "            'optimal_theta': self.optimal_theta,\n",
    "            'method_results': self.method_results,\n",
    "            'best_method_results': self.method_results.get(self.theta_strategy, {}),\n",
    "            'forecasts': self.method_results.get(self.theta_strategy, {}).get('forecasts', None),\n",
    "            'preserved_structure': True,\n",
    "            'dsge_informed': self.dsge_priors is not None\n",
    "        }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CONVENIENCE FUNCTIONS FOR DSGE-INFORMED THETA ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def enhance_dsge_dfm_with_theta(existing_dsge_dfm_model, strategy='auto', forecast_horizon=8):\n",
    "    \"\"\"\n",
    "    FIXED: Enhance existing DSGE-informed DFM with theta optimization while preserving structure\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    existing_dsge_dfm_model : EconometricDFM (from document 1)\n",
    "        Fitted DSGE-informed DFM model with Bayesian VAR and DSGE posterior estimates\n",
    "    strategy : str\n",
    "        'auto' - compare all DSGE-informed methods and pick best\n",
    "        Or specific: 'dsge_hp_trend_cycle', 'dsge_regime_switching', 'dsge_time_varying'\n",
    "    forecast_horizon : int\n",
    "        Number of quarters to forecast\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    enhanced_dfm : DSGEInformedEnhancedDFMTheta\n",
    "        DSGE-consistent theta-enhanced model with proper DSGE integration\n",
    "    results : dict\n",
    "        Dictionary with all results preserving DSGE structure\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ENHANCING DSGE-INFORMED DFM WITH THETA OPTIMIZATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Verify input model has DSGE components\n",
    "    if not hasattr(existing_dsge_dfm_model, 'dsge_priors'):\n",
    "        print(\"Warning: Input model doesn't appear to be DSGE-informed\")\n",
    "        print(\"Will attempt to extract DSGE information from VAR estimation results\")\n",
    "    \n",
    "    # Create DSGE-informed enhanced model (will extract DSGE priors automatically)\n",
    "    enhanced_dfm = DSGEInformedEnhancedDFMTheta(existing_dsge_dfm_model)\n",
    "    \n",
    "    if enhanced_dfm.dsge_priors is not None:\n",
    "        print(\"‚úì DSGE priors successfully extracted - will be preserved throughout theta optimization\")\n",
    "        print(f\"  Available DSGE parameters: {list(enhanced_dfm.dsge_priors.keys())}\")\n",
    "    else:\n",
    "        print(\"! No DSGE priors found - using econometric constraints only\")\n",
    "    \n",
    "    # Run complete analysis with DSGE consistency\n",
    "    results = enhanced_dfm.run_complete_dsge_theta_analysis(strategy, forecast_horizon)\n",
    "    \n",
    "    return enhanced_dfm, results\n",
    "\n",
    "\n",
    "def compare_dsge_theta_methods(existing_dsge_dfm_model):\n",
    "    \"\"\"\n",
    "    Run comprehensive comparison of DSGE-informed theta methods\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    existing_dsge_dfm_model : EconometricDFM\n",
    "        Fitted DSGE-informed DFM model\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    enhanced_dfm : DSGEInformedEnhancedDFMTheta\n",
    "        Enhanced model object\n",
    "    comparison_results : dict\n",
    "        Comprehensive results with DSGE consistency metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    enhanced_dfm = DSGEInformedEnhancedDFMTheta(existing_dsge_dfm_model)\n",
    "    \n",
    "    # Run method comparison\n",
    "    all_results = enhanced_dfm.run_dsge_theta_comparison()\n",
    "    \n",
    "    enhanced_dfm.print_dsge_theta_results()\n",
    "    \n",
    "    return enhanced_dfm, all_results\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# INTEGRATION WITH DOCUMENT 1 - MAIN EXECUTION FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def integrate_dsge_theta_with_document1_results(dsge_posterior_estimates=None, start_date=\"2000-01-01\", forecast_horizon=8):\n",
    "    \"\"\"\n",
    "    FIXED: Complete integration function that uses Document 1's DSGE estimation results\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dsge_posterior_estimates : dict\n",
    "        DSGE posterior parameter estimates from Document 1's dsge.posterior_table\n",
    "        Should contain keys like 'sigma', 'theta', 'phi_pi', 'phi_y', etc. with 'mean' values\n",
    "    start_date : str\n",
    "        Start date for data fetching\n",
    "    forecast_horizon : int\n",
    "        Number of quarters to forecast\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with keys:\n",
    "        'base_dsge_dfm': Base DSGE-informed DFM model\n",
    "        'enhanced_theta_dfm': Theta-enhanced version\n",
    "        'theta_results': Theta optimization results\n",
    "        'comparison': Method comparison results\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"COMPLETE DSGE-THETA INTEGRATION PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Import necessary functions from Document 1\n",
    "    try:\n",
    "        from run_core_economic_analysis import run_core_economic_analysis\n",
    "    except ImportError:\n",
    "        print(\"Warning: Cannot import Document 1 functions. Please ensure Document 1 is available.\")\n",
    "        return None\n",
    "    \n",
    "    # STEP 1: Run base DSGE-informed DFM from Document 1\n",
    "    print(\"\\n1. Running base DSGE-informed DFM estimation...\")\n",
    "    base_analysis = run_core_economic_analysis(\n",
    "        dsge_posterior_estimates=dsge_posterior_estimates,\n",
    "        start_date=start_date,\n",
    "        forecast_horizon=forecast_horizon\n",
    "    )\n",
    "    \n",
    "    if base_analysis is None:\n",
    "        print(\"Failed to run base DSGE-informed DFM\")\n",
    "        return None\n",
    "    \n",
    "    base_dsge_dfm = base_analysis['model']\n",
    "    base_results = base_analysis['results']\n",
    "    \n",
    "    print(\"‚úì Base DSGE-informed DFM completed successfully\")\n",
    "    \n",
    "    # STEP 2: Enhance with theta optimization\n",
    "    print(\"\\n2. Enhancing with DSGE-informed theta optimization...\")\n",
    "    enhanced_dfm, theta_results = enhance_dsge_dfm_with_theta(\n",
    "        base_dsge_dfm, \n",
    "        strategy='auto', \n",
    "        forecast_horizon=forecast_horizon\n",
    "    )\n",
    "    \n",
    "    print(\"‚úì Theta enhancement completed successfully\")\n",
    "    \n",
    "    # STEP 3: Compare methods\n",
    "    print(\"\\n3. Running comprehensive method comparison...\")\n",
    "    comparison_dfm, comparison_results = compare_dsge_theta_methods(base_dsge_dfm)\n",
    "    \n",
    "    # STEP 4: Final summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DSGE-THETA INTEGRATION COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"Pipeline Summary:\")\n",
    "    print(f\"  ‚Ä¢ DSGE structural estimation: {'‚úì' if dsge_posterior_estimates else '‚óã'}\")\n",
    "    print(f\"  ‚Ä¢ Base DFM with DSGE priors: ‚úì\")\n",
    "    print(f\"  ‚Ä¢ Theta optimization: ‚úì\")\n",
    "    print(f\"  ‚Ä¢ Method comparison: ‚úì\")\n",
    "    \n",
    "    if enhanced_dfm.dsge_priors is not None:\n",
    "        print(f\"  ‚Ä¢ DSGE parameters used: {len(enhanced_dfm.dsge_priors)}\")\n",
    "        print(f\"  ‚Ä¢ Structure preservation: ‚úì\")\n",
    "    \n",
    "    return {\n",
    "        'base_dsge_dfm': base_dsge_dfm,\n",
    "        'base_results': base_results,\n",
    "        'enhanced_theta_dfm': enhanced_dfm,\n",
    "        'theta_results': theta_results,\n",
    "        'comparison_dfm': comparison_dfm,\n",
    "        'comparison_results': comparison_results,\n",
    "        'dsge_parameters': dsge_posterior_estimates,\n",
    "        'integration_successful': True\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXAMPLE USAGE WITH DSGE INTEGRATION\n",
    "# ============================================================================\n",
    "\n",
    "def example_dsge_theta_usage():\n",
    "    \"\"\"\n",
    "    FIXED: Complete example showing DSGE-informed theta enhancement\n",
    "    \"\"\"\n",
    "    print(\"DSGE-INFORMED THETA ENHANCEMENT EXAMPLE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"\\nFIXED INTEGRATION APPROACH:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"\\n1. Complete Pipeline (uses Document 1's DSGE results):\")\n",
    "    print(\"   # This automatically runs DSGE estimation then theta enhancement\")\n",
    "    print(\"   results = integrate_dsge_theta_with_document1_results(\")\n",
    "    print(\"       dsge_posterior_estimates=dsge_estimates)\")\n",
    "    print(\"   \")\n",
    "    \n",
    "    print(\"2. Manual Two-Step Process:\")\n",
    "    print(\"   # Step 1: Run Document 1's DSGE-informed DFM\")\n",
    "    print(\"   base_analysis = run_core_economic_analysis(dsge_posterior_estimates)\")\n",
    "    print(\"   base_dfm = base_analysis['model']\")\n",
    "    print(\"   \")\n",
    "    print(\"   # Step 2: Enhance with theta (automatically extracts DSGE priors)\")\n",
    "    print(\"   enhanced_dfm, results = enhance_dsge_dfm_with_theta(base_dfm)\")\n",
    "    print(\"   \")\n",
    "    \n",
    "    print(\"3. Method Comparison with DSGE Consistency:\")\n",
    "    print(\"   enhanced_dfm, results = compare_dsge_theta_methods(base_dfm)\")\n",
    "    print(\"   \")\n",
    "    \n",
    "    print(\"KEY FIXES IN THIS VERSION:\")\n",
    "    print(\"‚Ä¢ _extract_dsge_posterior_estimates() properly extracts DSGE priors\")\n",
    "    print(\"‚Ä¢ _construct_priors_from_dsge_estimates() handles missing prior_info\")\n",
    "    print(\"‚Ä¢ Integration function imports and uses Document 1 functions\")\n",
    "    print(\"‚Ä¢ DSGE parameter extraction from posterior_table format\")\n",
    "    print(\"‚Ä¢ Automatic fallback to econometric constraints if no DSGE priors\")\n",
    "    print(\"   \")\n",
    "    \n",
    "    print(\"DSGE-Informed Methods Available:\")\n",
    "    print(\"‚Ä¢ DSGE_HP_Trend_Cycle: DSGE persistence guides trend-cycle weights\")\n",
    "    print(\"‚Ä¢ DSGE_Regime_Switching: Structural break regimes from DSGE parameters\")  \n",
    "    print(\"‚Ä¢ DSGE_Time_Varying: Parameter evolution consistent with DSGE stability\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    example_dsge_theta_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSGE-INFORMED VAR-DFM ANALYSIS\n",
      "================================================================================\n",
      "Using DSGE-estimated priors for VAR coefficient restrictions\n",
      "PREPARING ECONOMETRIC DATA FOR DSGE-INFORMED DFM\n",
      "============================================================\n",
      "Fetching economic data from FRED...\n",
      "\n",
      "Fetching Demand_Block:\n",
      "  GDPC1 ‚úì (102 obs)\n",
      "  PAYEMS ‚úì (308 obs)\n",
      "  INDPRO ‚úì (307 obs)\n",
      "  ICSA ‚úì (1341 obs)\n",
      "\n",
      "Fetching Supply_Block:\n",
      "  CPIAUCSL ‚úì (308 obs)\n",
      "  PCEPI ‚úì (307 obs)\n",
      "  AHETPI ‚úì (308 obs)\n",
      "  DCOILWTICO ‚úì (6441 obs)\n",
      "\n",
      "Fetching Monetary_Block:\n",
      "  FEDFUNDS ‚úì (308 obs)\n",
      "  DGS10 ‚úì (6428 obs)\n",
      "  M2SL ‚úì (307 obs)\n",
      "  AAA ‚úì (308 obs)\n",
      "\n",
      "Successfully fetched 12 series\n",
      "Common date range: 2000-01 to 2025-04\n",
      "Quarterly observations: 101\n",
      "Final dataset shape: (97, 12)\n",
      "Date range: 2001-Qq to 2025-Qq\n",
      "Demand_Block: ['GDPC1', 'PAYEMS', 'INDPRO', 'ICSA']\n",
      "Supply_Block: ['CPIAUCSL', 'PCEPI', 'AHETPI', 'DCOILWTICO']\n",
      "Monetary_Block: ['FEDFUNDS', 'DGS10', 'M2SL', 'AAA']\n",
      "\n",
      "INITIALIZING DSGE-INFORMED DFM\n",
      "============================================================\n",
      "DSGE priors available: ['sigma', 'theta', 'phi_pi', 'phi_y', 'rho_a', 'sigma_a', 'rho_v', 'sigma_v', 'rho_d', 'sigma_d', 'rho_s', 'sigma_s']\n",
      "\n",
      "DSGE-Informed DFM Setup:\n",
      "  Variables: 12\n",
      "  Observations: 97\n",
      "  Factors: 3\n",
      "  DSGE priors: 12 parameters\n",
      "DSGE-INFORMED DYNAMIC FACTOR MODEL - COMPLETE ESTIMATION\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "STEP 1: FACTOR EXTRACTION VIA PCA\n",
      "============================================================\n",
      "PCA explained variance: [0.3059512  0.21843536 0.18527432]\n",
      "Cumulative explained variance: [0.3059512  0.52438655 0.70966088]\n",
      "\n",
      "============================================================\n",
      "STEP 2: FACTOR LOADING ESTIMATION\n",
      "============================================================\n",
      "\n",
      "Factor Loading Results:\n",
      "======================================================================\n",
      "Variable     R¬≤     Demand     Supply     Monetary  \n",
      "----------------------------------------------------------------------\n",
      "GDPC1        0.736  0.220      -0.370     -0.300    \n",
      "PAYEMS       0.863  0.304      -0.381     -0.254    \n",
      "INDPRO       0.592  0.193      -0.335     -0.269    \n",
      "ICSA         0.581  0.373      -0.065     -0.162    \n",
      "CPIAUCSL     0.888  0.380      -0.053     0.397     \n",
      "PCEPI        0.903  0.389      -0.069     0.389     \n",
      "AHETPI       0.701  0.194      0.043      0.501     \n",
      "DCOILWTICO   0.291  0.183      -0.212     0.150     \n",
      "FEDFUNDS     0.708  0.336      0.334      0.002     \n",
      "DGS10        0.878  0.289      0.429      -0.200    \n",
      "M2SL         0.581  -0.312     -0.186     0.244     \n",
      "AAA          0.794  0.148      0.465      -0.257    \n",
      "\n",
      "Average R¬≤: 0.710\n",
      "\n",
      "============================================================\n",
      "STEP 3: DSGE-INFORMED FACTOR VAR ESTIMATION\n",
      "============================================================\n",
      "Optimal lag selected: 1 (using BIC)\n",
      "\n",
      "üìã Constructing DSGE-informed priors for VAR(1)...\n",
      "   Prior mean range: [-0.073, 0.557]\n",
      "   Prior variance range: [0.050, 1.000]\n",
      "üéØ Using DSGE-informed Bayesian estimation\n",
      "Bayesian VAR(1) estimation completed:\n",
      "  Effective sample: 96\n",
      "  Log-likelihood: -328.55\n",
      "  DSGE prior influence: Moderate\n",
      "\n",
      "Bayesian VAR Stability Check:\n",
      "  Maximum eigenvalue modulus: 0.8964\n",
      "  Model is stable ‚úì\n",
      "\n",
      "============================================================\n",
      "VAR FORECASTING WITH COMPANION FORM\n",
      "============================================================\n",
      "Forecasting 3 factors for 8 periods using Bayesian VAR(1)\n",
      "\n",
      "Forecast Summary (1-quarter ahead):\n",
      "--------------------------------------------------\n",
      "Demand_Factor:   1.236 ¬± 1.162\n",
      "Supply_Factor:   1.174 ¬± 0.985\n",
      "Monetary_Factor:  -0.235 ¬± 0.979\n",
      "\n",
      "============================================================\n",
      "VARIABLE FORECASTING VIA FACTOR MODEL\n",
      "============================================================\n",
      "Generated forecasts for 12 variables\n",
      "\n",
      "====================================================================================================\n",
      "5-FOLD CROSS-VALIDATION WITH COMPREHENSIVE METRICS\n",
      "====================================================================================================\n",
      "Total observations: 97\n",
      "Fold size: 19\n",
      "Forecast horizon: 4\n",
      "\n",
      "Processing Fold 1/5...\n",
      "  Train: 0 to 19 (20 obs)\n",
      "  Test: 20 to 23 (4 obs)\n",
      "\n",
      "DSGE-Informed DFM Setup:\n",
      "  Variables: 12\n",
      "  Observations: 20\n",
      "  Factors: 3\n",
      "  DSGE priors: 12 parameters\n",
      "\n",
      "============================================================\n",
      "STEP 1: FACTOR EXTRACTION VIA PCA\n",
      "============================================================\n",
      "PCA explained variance: [0.50549909 0.24050851 0.09553986]\n",
      "Cumulative explained variance: [0.50549909 0.7460076  0.84154746]\n",
      "\n",
      "============================================================\n",
      "STEP 2: FACTOR LOADING ESTIMATION\n",
      "============================================================\n",
      "\n",
      "Factor Loading Results:\n",
      "======================================================================\n",
      "Variable     R¬≤     Demand     Supply     Monetary  \n",
      "----------------------------------------------------------------------\n",
      "GDPC1        0.555  0.215      -0.292     0.157     \n",
      "PAYEMS       0.904  0.382      0.031      0.126     \n",
      "INDPRO       0.773  0.171      -0.282     0.565     \n",
      "ICSA         0.919  0.349      0.188      0.265     \n",
      "CPIAUCSL     0.830  0.207      0.433      -0.159    \n",
      "PCEPI        0.879  0.313      0.284      -0.211    \n",
      "AHETPI       0.836  -0.255     0.390      -0.026    \n",
      "DCOILWTICO   0.921  0.375      0.150      0.056     \n",
      "FEDFUNDS     0.889  -0.024     0.538      0.206     \n",
      "DGS10        0.825  -0.197     0.218      0.627     \n",
      "M2SL         0.883  -0.381     -0.009     -0.040    \n",
      "AAA          0.885  -0.355     0.138      0.242     \n",
      "\n",
      "Average R¬≤: 0.842\n",
      "\n",
      "============================================================\n",
      "STEP 3: DSGE-INFORMED FACTOR VAR ESTIMATION\n",
      "============================================================\n",
      "Optimal lag selected: 1 (using BIC)\n",
      "\n",
      "üìã Constructing DSGE-informed priors for VAR(1)...\n",
      "   Prior mean range: [-0.073, 0.557]\n",
      "   Prior variance range: [0.050, 1.000]\n",
      "üéØ Using DSGE-informed Bayesian estimation\n",
      "Bayesian VAR(1) estimation completed:\n",
      "  Effective sample: 19\n",
      "  Log-likelihood: -58.99\n",
      "  DSGE prior influence: Moderate\n",
      "\n",
      "Bayesian VAR Stability Check:\n",
      "  Maximum eigenvalue modulus: 0.7987\n",
      "  Model is stable ‚úì\n",
      "\n",
      "============================================================\n",
      "VAR FORECASTING WITH COMPANION FORM\n",
      "============================================================\n",
      "Forecasting 3 factors for 4 periods using Bayesian VAR(1)\n",
      "\n",
      "Forecast Summary (1-quarter ahead):\n",
      "--------------------------------------------------\n",
      "Demand_Factor:   2.620 ¬± 0.487\n",
      "Supply_Factor:   1.661 ¬± 0.836\n",
      "Monetary_Factor:   0.843 ¬± 1.042\n",
      "\n",
      "============================================================\n",
      "VARIABLE FORECASTING VIA FACTOR MODEL\n",
      "============================================================\n",
      "Generated forecasts for 12 variables\n",
      "  Fold 1 completed successfully\n",
      "\n",
      "Processing Fold 2/5...\n",
      "  Train: 0 to 38 (39 obs)\n",
      "  Test: 39 to 42 (4 obs)\n",
      "\n",
      "DSGE-Informed DFM Setup:\n",
      "  Variables: 12\n",
      "  Observations: 39\n",
      "  Factors: 3\n",
      "  DSGE priors: 12 parameters\n",
      "\n",
      "============================================================\n",
      "STEP 1: FACTOR EXTRACTION VIA PCA\n",
      "============================================================\n",
      "PCA explained variance: [0.39695425 0.24998253 0.17266303]\n",
      "Cumulative explained variance: [0.39695425 0.64693678 0.8195998 ]\n",
      "\n",
      "============================================================\n",
      "STEP 2: FACTOR LOADING ESTIMATION\n",
      "============================================================\n",
      "\n",
      "Factor Loading Results:\n",
      "======================================================================\n",
      "Variable     R¬≤     Demand     Supply     Monetary  \n",
      "----------------------------------------------------------------------\n",
      "GDPC1        0.794  0.290      -0.251     -0.315    \n",
      "PAYEMS       0.916  0.410      -0.158     -0.140    \n",
      "INDPRO       0.682  0.194      -0.291     -0.347    \n",
      "ICSA         0.878  0.420      0.113      0.011     \n",
      "CPIAUCSL     0.766  0.359      0.135      0.217     \n",
      "PCEPI        0.826  0.390      0.043      0.217     \n",
      "AHETPI       0.794  0.037      0.441      0.313     \n",
      "DCOILWTICO   0.790  0.096      -0.185     0.557     \n",
      "FEDFUNDS     0.815  0.309      0.335      0.103     \n",
      "DGS10        0.872  0.282      0.315      -0.307    \n",
      "M2SL         0.861  -0.260     0.409      -0.136    \n",
      "AAA          0.842  -0.008     0.432      -0.368    \n",
      "\n",
      "Average R¬≤: 0.820\n",
      "\n",
      "============================================================\n",
      "STEP 3: DSGE-INFORMED FACTOR VAR ESTIMATION\n",
      "============================================================\n",
      "Optimal lag selected: 1 (using BIC)\n",
      "\n",
      "üìã Constructing DSGE-informed priors for VAR(1)...\n",
      "   Prior mean range: [-0.073, 0.557]\n",
      "   Prior variance range: [0.050, 1.000]\n",
      "üéØ Using DSGE-informed Bayesian estimation\n",
      "Bayesian VAR(1) estimation completed:\n",
      "  Effective sample: 38\n",
      "  Log-likelihood: -127.60\n",
      "  DSGE prior influence: Moderate\n",
      "\n",
      "Bayesian VAR Stability Check:\n",
      "  Maximum eigenvalue modulus: 0.8703\n",
      "  Model is stable ‚úì\n",
      "\n",
      "============================================================\n",
      "VAR FORECASTING WITH COMPANION FORM\n",
      "============================================================\n",
      "Forecasting 3 factors for 4 periods using Bayesian VAR(1)\n",
      "\n",
      "Forecast Summary (1-quarter ahead):\n",
      "--------------------------------------------------\n",
      "Demand_Factor:  -0.487 ¬± 1.056\n",
      "Supply_Factor:  -3.126 ¬± 0.608\n",
      "Monetary_Factor:   0.865 ¬± 0.647\n",
      "\n",
      "============================================================\n",
      "VARIABLE FORECASTING VIA FACTOR MODEL\n",
      "============================================================\n",
      "Generated forecasts for 12 variables\n",
      "  Fold 2 completed successfully\n",
      "\n",
      "Processing Fold 3/5...\n",
      "  Train: 0 to 57 (58 obs)\n",
      "  Test: 58 to 61 (4 obs)\n",
      "\n",
      "DSGE-Informed DFM Setup:\n",
      "  Variables: 12\n",
      "  Observations: 58\n",
      "  Factors: 3\n",
      "  DSGE priors: 12 parameters\n",
      "\n",
      "============================================================\n",
      "STEP 1: FACTOR EXTRACTION VIA PCA\n",
      "============================================================\n",
      "PCA explained variance: [0.32347913 0.29919616 0.13021873]\n",
      "Cumulative explained variance: [0.32347913 0.6226753  0.75289403]\n",
      "\n",
      "============================================================\n",
      "STEP 2: FACTOR LOADING ESTIMATION\n",
      "============================================================\n",
      "\n",
      "Factor Loading Results:\n",
      "======================================================================\n",
      "Variable     R¬≤     Demand     Supply     Monetary  \n",
      "----------------------------------------------------------------------\n",
      "GDPC1        0.719  -0.041     0.372      -0.372    \n",
      "PAYEMS       0.881  -0.099     0.482      -0.081    \n",
      "INDPRO       0.662  -0.097     0.295      -0.448    \n",
      "ICSA         0.575  0.066      0.393      0.048     \n",
      "CPIAUCSL     0.830  0.293      0.284      0.366     \n",
      "PCEPI        0.853  0.269      0.337      0.322     \n",
      "AHETPI       0.791  0.419      -0.144     0.150     \n",
      "DCOILWTICO   0.708  -0.221     0.195      0.494     \n",
      "FEDFUNDS     0.805  0.443      0.109      0.033     \n",
      "DGS10        0.935  0.461      0.023      -0.264    \n",
      "M2SL         0.365  -0.026     -0.308     0.116     \n",
      "AAA          0.910  0.428      -0.167     -0.251    \n",
      "\n",
      "Average R¬≤: 0.753\n",
      "\n",
      "============================================================\n",
      "STEP 3: DSGE-INFORMED FACTOR VAR ESTIMATION\n",
      "============================================================\n",
      "Optimal lag selected: 1 (using BIC)\n",
      "\n",
      "üìã Constructing DSGE-informed priors for VAR(1)...\n",
      "   Prior mean range: [-0.073, 0.557]\n",
      "   Prior variance range: [0.050, 1.000]\n",
      "üéØ Using DSGE-informed Bayesian estimation\n",
      "Bayesian VAR(1) estimation completed:\n",
      "  Effective sample: 57\n",
      "  Log-likelihood: -171.81\n",
      "  DSGE prior influence: Moderate\n",
      "\n",
      "Bayesian VAR Stability Check:\n",
      "  Maximum eigenvalue modulus: 0.9379\n",
      "  Model is stable ‚úì\n",
      "\n",
      "============================================================\n",
      "VAR FORECASTING WITH COMPANION FORM\n",
      "============================================================\n",
      "Forecasting 3 factors for 4 periods using Bayesian VAR(1)\n",
      "\n",
      "Forecast Summary (1-quarter ahead):\n",
      "--------------------------------------------------\n",
      "Demand_Factor:  -2.314 ¬± 0.630\n",
      "Supply_Factor:   0.753 ¬± 0.872\n",
      "Monetary_Factor:  -0.194 ¬± 0.753\n",
      "\n",
      "============================================================\n",
      "VARIABLE FORECASTING VIA FACTOR MODEL\n",
      "============================================================\n",
      "Generated forecasts for 12 variables\n",
      "  Fold 3 completed successfully\n",
      "\n",
      "Processing Fold 4/5...\n",
      "  Train: 0 to 76 (77 obs)\n",
      "  Test: 77 to 80 (4 obs)\n",
      "\n",
      "DSGE-Informed DFM Setup:\n",
      "  Variables: 12\n",
      "  Observations: 77\n",
      "  Factors: 3\n",
      "  DSGE priors: 12 parameters\n",
      "\n",
      "============================================================\n",
      "STEP 1: FACTOR EXTRACTION VIA PCA\n",
      "============================================================\n",
      "PCA explained variance: [0.30066193 0.28838524 0.11921408]\n",
      "Cumulative explained variance: [0.30066193 0.58904717 0.70826125]\n",
      "\n",
      "============================================================\n",
      "STEP 2: FACTOR LOADING ESTIMATION\n",
      "============================================================\n",
      "\n",
      "Factor Loading Results:\n",
      "======================================================================\n",
      "Variable     R¬≤     Demand     Supply     Monetary  \n",
      "----------------------------------------------------------------------\n",
      "GDPC1        0.740  -0.110     0.391      0.341     \n",
      "PAYEMS       0.817  -0.208     0.437      0.013     \n",
      "INDPRO       0.720  -0.119     0.319      0.470     \n",
      "ICSA         0.520  -0.140     0.338      -0.193    \n",
      "CPIAUCSL     0.791  0.295      0.313      -0.312    \n",
      "PCEPI        0.802  0.276      0.354      -0.256    \n",
      "AHETPI       0.678  0.398      -0.062     -0.255    \n",
      "DCOILWTICO   0.386  -0.148     0.196      -0.349    \n",
      "FEDFUNDS     0.757  0.417      0.184      -0.090    \n",
      "DGS10        0.942  0.448      0.110      0.349     \n",
      "M2SL         0.442  0.045      -0.353     -0.053    \n",
      "AAA          0.904  0.436      -0.063     0.379     \n",
      "\n",
      "Average R¬≤: 0.708\n",
      "\n",
      "============================================================\n",
      "STEP 3: DSGE-INFORMED FACTOR VAR ESTIMATION\n",
      "============================================================\n",
      "Optimal lag selected: 1 (using BIC)\n",
      "\n",
      "üìã Constructing DSGE-informed priors for VAR(1)...\n",
      "   Prior mean range: [-0.073, 0.557]\n",
      "   Prior variance range: [0.050, 1.000]\n",
      "üéØ Using DSGE-informed Bayesian estimation\n",
      "Bayesian VAR(1) estimation completed:\n",
      "  Effective sample: 76\n",
      "  Log-likelihood: -244.89\n",
      "  DSGE prior influence: Moderate\n",
      "\n",
      "Bayesian VAR Stability Check:\n",
      "  Maximum eigenvalue modulus: 0.9362\n",
      "  Model is stable ‚úì\n",
      "\n",
      "============================================================\n",
      "VAR FORECASTING WITH COMPANION FORM\n",
      "============================================================\n",
      "Forecasting 3 factors for 4 periods using Bayesian VAR(1)\n",
      "\n",
      "Forecast Summary (1-quarter ahead):\n",
      "--------------------------------------------------\n",
      "Demand_Factor:  -0.839 ¬± 0.617\n",
      "Supply_Factor:  -5.615 ¬± 1.107\n",
      "Monetary_Factor:  -0.864 ¬± 0.666\n",
      "\n",
      "============================================================\n",
      "VARIABLE FORECASTING VIA FACTOR MODEL\n",
      "============================================================\n",
      "Generated forecasts for 12 variables\n",
      "  Fold 4 completed successfully\n",
      "\n",
      "Processing Fold 5/5...\n",
      "  Train: 0 to 95 (96 obs)\n",
      "  Test: 96 to 96 (1 obs)\n",
      "\n",
      "DSGE-Informed DFM Setup:\n",
      "  Variables: 12\n",
      "  Observations: 96\n",
      "  Factors: 3\n",
      "  DSGE priors: 12 parameters\n",
      "\n",
      "============================================================\n",
      "STEP 1: FACTOR EXTRACTION VIA PCA\n",
      "============================================================\n",
      "PCA explained variance: [0.30557063 0.218366   0.18564966]\n",
      "Cumulative explained variance: [0.30557063 0.52393663 0.70958629]\n",
      "\n",
      "============================================================\n",
      "STEP 2: FACTOR LOADING ESTIMATION\n",
      "============================================================\n",
      "\n",
      "Factor Loading Results:\n",
      "======================================================================\n",
      "Variable     R¬≤     Demand     Supply     Monetary  \n",
      "----------------------------------------------------------------------\n",
      "GDPC1        0.735  0.226      -0.365     -0.299    \n",
      "PAYEMS       0.863  0.307      -0.378     -0.252    \n",
      "INDPRO       0.591  0.194      -0.334     -0.268    \n",
      "ICSA         0.580  0.373      -0.067     -0.162    \n",
      "CPIAUCSL     0.891  0.382      -0.047     0.396     \n",
      "PCEPI        0.903  0.390      -0.063     0.388     \n",
      "AHETPI       0.702  0.193      0.045      0.502     \n",
      "DCOILWTICO   0.292  0.182      -0.214     0.151     \n",
      "FEDFUNDS     0.705  0.333      0.337      0.003     \n",
      "DGS10        0.879  0.285      0.433      -0.201    \n",
      "M2SL         0.578  -0.310     -0.187     0.244     \n",
      "AAA          0.796  0.144      0.467      -0.258    \n",
      "\n",
      "Average R¬≤: 0.710\n",
      "\n",
      "============================================================\n",
      "STEP 3: DSGE-INFORMED FACTOR VAR ESTIMATION\n",
      "============================================================\n",
      "Optimal lag selected: 1 (using BIC)\n",
      "\n",
      "üìã Constructing DSGE-informed priors for VAR(1)...\n",
      "   Prior mean range: [-0.073, 0.557]\n",
      "   Prior variance range: [0.050, 1.000]\n",
      "üéØ Using DSGE-informed Bayesian estimation\n",
      "Bayesian VAR(1) estimation completed:\n",
      "  Effective sample: 95\n",
      "  Log-likelihood: -325.71\n",
      "  DSGE prior influence: Moderate\n",
      "\n",
      "Bayesian VAR Stability Check:\n",
      "  Maximum eigenvalue modulus: 0.8962\n",
      "  Model is stable ‚úì\n",
      "\n",
      "============================================================\n",
      "VAR FORECASTING WITH COMPANION FORM\n",
      "============================================================\n",
      "Forecasting 3 factors for 1 periods using Bayesian VAR(1)\n",
      "\n",
      "Forecast Summary (1-quarter ahead):\n",
      "--------------------------------------------------\n",
      "Demand_Factor:   1.561 ¬± 1.172\n",
      "Supply_Factor:   1.231 ¬± 0.977\n",
      "Monetary_Factor:  -0.134 ¬± 0.978\n",
      "\n",
      "============================================================\n",
      "VARIABLE FORECASTING VIA FACTOR MODEL\n",
      "============================================================\n",
      "Generated forecasts for 12 variables\n",
      "  Fold 5 completed successfully\n",
      "\n",
      "============================================================================================================================================\n",
      "DSGE-INFORMED DFM CROSS-VALIDATION SUMMARY\n",
      "============================================================================================================================================\n",
      "Variable        CV RMSE    CV MAE     CV MAPE    CV SMAPE   CV Theil_U1  CV Theil_U2  CV MdAPE   CV MASE    CV R¬≤   \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GDPC1           5.9884     4.9397     325.57     124.56     0.7630       0.9860       197.14     0.7702     -1.566  \n",
      "PAYEMS          3.9595     3.1252     52.48      74.25      0.4282       0.6062       47.83      1.0368     -3.370  \n",
      "INDPRO          5.4438     4.5954     233.28     127.37     0.7852       1.4064       112.63     0.7542     -0.740  \n",
      "ICSA            0.3224     0.2994     2.23       2.27       0.0173       5.0046       1.96       7.3985     -221.544\n",
      "CPIAUCSL        1.1185     1.0528     894.68     77.82      0.4555       1.5866       70.30      1.8050     -2.537  \n",
      "PCEPI           0.8816     0.8387     173.02     73.47      0.4200       1.7630       89.76      2.1546     -4.007  \n",
      "AHETPI          1.0925     1.0671     27.56      32.25      0.2271       2.1037       28.01      8.2226     -98.779 \n",
      "DCOILWTICO      0.3020     0.2867     7.25       6.99       0.0520       5.6118       7.14       2.2961     -10.560 \n",
      "FEDFUNDS        0.9958     0.9463     451.52     97.41      0.5721       5.1455       447.18     31.3770    -2310.881\n",
      "DGS10           0.6392     0.5531     40.84      26.95      0.1919       1.1373       39.73      1.7849     -2.854  \n",
      "M2SL            4.0145     3.8421     26.71      35.04      0.2606       4.2883       26.89      5.4682     -106.028\n",
      "AAA             0.6992     0.6573     22.16      16.96      0.1221       1.8836       22.77      2.5010     -9.021  \n",
      "\n",
      "======================================================================\n",
      "DSGE-INFORMED MODEL SUMMARY STATISTICS\n",
      "======================================================================\n",
      "Average CV RMSE: 2.1215\n",
      "Median CV RMSE: 1.0442\n",
      "Average CV MAE: 1.8503\n",
      "Average CV R¬≤: -230.991\n",
      "Average CV Theil's U1: 0.3579\n",
      "Average CV Theil's U2: 2.6269\n",
      "Average CV MASE: 5.4641\n",
      "Median CV MASE: 2.2254\n",
      "Variables with valid metrics: 12/12\n",
      "DSGE priors used: 12 structural parameters\n",
      "Model uses Bayesian VAR with DSGE-informed coefficient restrictions\n",
      "\n",
      "================================================================================\n",
      "DSGE-INFORMED DFM ESTIMATION COMPLETED SUCCESSFULLY\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "DSGE-INFORMED ANALYSIS COMPLETED SUCCESSFULLY\n",
      "================================================================================\n",
      "Model Summary:\n",
      "  ‚Ä¢ 12 macroeconomic variables\n",
      "  ‚Ä¢ 97 quarterly observations\n",
      "  ‚Ä¢ 3 economic factors extracted\n",
      "  ‚Ä¢ VAR(1) dynamics estimated (DSGE-Informed Bayesian)\n",
      "  ‚Ä¢ 8 quarter forecasts generated\n",
      "  ‚Ä¢ DSGE structural priors: 12 parameters\n",
      "ENHANCING DSGE-INFORMED DFM WITH THETA OPTIMIZATION\n",
      "============================================================\n",
      "DSGE-Informed Enhanced DFM-Theta initialized:\n",
      "  Factors: 3, Variables: 12\n",
      "  DSGE priors: Available\n",
      "  Base VAR estimation: Bayesian\n",
      "‚úì DSGE priors successfully extracted - will be preserved throughout theta optimization\n",
      "  Available DSGE parameters: ['sigma', 'theta', 'phi_pi', 'phi_y', 'rho_a', 'sigma_a', 'rho_v', 'sigma_v', 'rho_d', 'sigma_d', 'rho_s', 'sigma_s']\n",
      "DSGE-INFORMED ENHANCED DFM-THETA ANALYSIS\n",
      "================================================================================\n",
      "‚úì Using DSGE structural priors for VAR coefficient adaptation\n",
      "‚úì Preserving original factor loadings throughout\n",
      "‚úì Maintaining economic interpretation of factors\n",
      "\n",
      "====================================================================================================\n",
      "DSGE-INFORMED THETA METHOD COMPARISON\n",
      "====================================================================================================\n",
      "Using Bayesian VAR with DSGE structure preservation\n",
      "\n",
      "--- DSGE_HP_Trend_Cycle Method ---\n",
      "Running DSGE-Constrained HP Trend-Cycle Method...\n",
      "  Adapting DSGE priors for HP_Trend_Cycle transformation...\n",
      "Evaluating DSGE_HP_Trend_Cycle with DSGE consistency...\n",
      "Average R¬≤: 0.632\n",
      "CV RMSE: 0.9066\n",
      "DSGE-Informed: Yes\n",
      "Original Loadings Preserved: True\n",
      "\n",
      "--- DSGE_Regime_Switching Method ---\n",
      "Running DSGE-Informed Regime Switching Method...\n",
      "Evaluating DSGE_Regime_Switching with DSGE consistency...\n",
      "Average R¬≤: 0.665\n",
      "CV RMSE: 0.5702\n",
      "DSGE-Informed: Yes\n",
      "Original Loadings Preserved: True\n",
      "\n",
      "--- DSGE_Time_Varying Method ---\n",
      "Running DSGE-Informed Time-Varying Method...\n",
      "Evaluating DSGE_Time_Varying with DSGE consistency...\n",
      "Average R¬≤: 0.699\n",
      "CV RMSE: 0.6356\n",
      "DSGE-Informed: Yes\n",
      "Original Loadings Preserved: True\n",
      "Debug: run_dsge_theta_comparison returning: ['DSGE_HP_Trend_Cycle', 'DSGE_Regime_Switching', 'DSGE_Time_Varying']\n",
      "Debug: After assignment, method_results has: ['DSGE_HP_Trend_Cycle', 'DSGE_Regime_Switching', 'DSGE_Time_Varying']\n",
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE METHOD SELECTION\n",
      "================================================================================\n",
      "Method                    Composite Score Avg RMSE   Avg R¬≤   Avg Theil_U1 Avg Theil_U2 Avg MASE   DSGE  \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "DSGE_Time_Varying         0.7481          0.5619     0.699    0.5330       2.6005       1.9686     Yes   \n",
      "DSGE_Regime_Switching     0.7481          0.5152     0.665    0.4902       2.3391       1.7567     Yes   \n",
      "DSGE_HP_Trend_Cycle       0.2000          0.7375     0.632    0.7643       3.4978       2.7418     Yes   \n",
      "\n",
      "Selected Best Method: DSGE_Time_Varying (Score: 0.7481)\n",
      "Debug: After select_best_method, method_results has: ['DSGE_HP_Trend_Cycle', 'DSGE_Regime_Switching', 'DSGE_Time_Varying']\n",
      "\n",
      "============================================================================================================================================\n",
      "DSGE-INFORMED THETA METHOD COMPARISON RESULTS\n",
      "============================================================================================================================================\n",
      "\n",
      "Method                    Avg R¬≤   CV RMSE    CV MAE     CV MAPE    DSGE   Loadings \n",
      "--------------------------------------------------------------------------------\n",
      "DSGE_HP_Trend_Cycle       0.632    0.9066     0.6926     134.77     Yes    Original \n",
      "DSGE_Regime_Switching     0.665    0.5702     0.4592     281.94     Yes    Original \n",
      "DSGE_Time_Varying         0.699    0.6356     0.5070     262.72     Yes    Original \n",
      "\n",
      "\n",
      "================================================================================\n",
      "DSGE PRIOR INTEGRATION SUMMARY\n",
      "================================================================================\n",
      "DSGE Parameters Used:\n",
      "  sigma: 1.362\n",
      "  theta: 0.210\n",
      "  phi_pi: 2.768\n",
      "  phi_y: 0.326\n",
      "  rho_a: 0.204\n",
      "  sigma_a: 0.621\n",
      "  rho_v: 0.557\n",
      "  sigma_v: 0.177\n",
      "  rho_d: 0.736\n",
      "  sigma_d: 0.186\n",
      "  rho_s: 0.511\n",
      "  sigma_s: 0.097\n",
      "\n",
      "Structural Consistency:\n",
      "  ‚Ä¢ Original factor loadings preserved: YES\n",
      "  ‚Ä¢ VAR priors adapted to theta transformations: YES\n",
      "  ‚Ä¢ Economic interpretation maintained: YES\n",
      "  ‚Ä¢ DSGE constraints applied to theta parameters: YES\n",
      "\n",
      "\n",
      "DETAILED RESULTS FOR BEST METHOD: DSGE_Time_Varying\n",
      "================================================================================\n",
      "\n",
      "Variable Fit (using original DSGE-informed loadings):\n",
      "------------------------------------------------------------\n",
      "Variable        R¬≤       Factor_1     Factor_2     Factor_3    \n",
      "------------------------------------------------------------\n",
      "GDPC1           0.768    0.220        -0.370       -0.300      \n",
      "PAYEMS          0.893    0.304        -0.381       -0.254      \n",
      "INDPRO          0.550    0.193        -0.335       -0.269      \n",
      "ICSA            0.600    0.373        -0.065       -0.162      \n",
      "CPIAUCSL        0.887    0.380        -0.053       0.397       \n",
      "PCEPI           0.903    0.389        -0.069       0.389       \n",
      "AHETPI          0.689    0.194        0.043        0.501       \n",
      "DCOILWTICO      0.252    0.183        -0.212       0.150       \n",
      "FEDFUNDS        0.682    0.336        0.334        0.002       \n",
      "DGS10           0.813    0.289        0.429        -0.200      \n",
      "M2SL            0.641    -0.312       -0.186       0.244       \n",
      "AAA             0.710    0.148        0.465        -0.257      \n",
      "\n",
      "Average R¬≤ (Best Method): 0.699\n",
      "\n",
      "VAR Model Comparison:\n",
      "  Base VAR Log-Likelihood: -328.55\n",
      "  Theta VAR Log-Likelihood: -334.13\n",
      "  Improvement: -5.58\n",
      "\n",
      "======================================================================================================================================================\n",
      "DETAILED VARIABLE-LEVEL CROSS-VALIDATION RESULTS\n",
      "======================================================================================================================================================\n",
      "\n",
      "Method: DSGE_HP_Trend_Cycle\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Variable        CV RMSE  CV MAE   CV MAPE   CV SMAPE   CV Theil_U1  CV Theil_U2  CV MdAPE   CV MASE   CV R¬≤   \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GDPC1           0.2586   0.2142   101.16    176.13     0.9331       0.8549       99.13      0.3257    -0.275  \n",
      "PAYEMS          0.1861   0.1730   102.48    154.68     0.7608       2.1459       90.91      0.4100    -6.717  \n",
      "INDPRO          0.4513   0.3903   125.50    183.68     0.9559       0.9033       99.93      0.4989    -0.069  \n",
      "ICSA            0.9455   0.9394   86.01     152.33     0.7589       17.5110      86.64      3.9137    -424.693\n",
      "CPIAUCSL        0.9141   0.8371   72.83     118.93     0.6649       1.3516       78.67      2.1542    -4.482  \n",
      "PCEPI           0.9548   0.9014   89.09     139.42     0.7258       1.8101       85.11      2.6360    -4.701  \n",
      "AHETPI          1.1469   1.1309   93.89     169.82     0.8318       4.6654       94.01      4.9493    -41.421 \n",
      "DCOILWTICO      0.6183   0.5704   93.91     164.39     0.8444       1.5479       94.34      1.6344    -6.660  \n",
      "FEDFUNDS        1.3551   1.3100   94.20     149.85     0.7530       6.3183       87.20      9.3765    -277.344\n",
      "DGS10           0.5687   0.5239   82.78     116.99     0.5992       1.7327       73.48      1.6304    -4.562  \n",
      "M2SL            1.2152   1.1172   81.05     141.06     0.7649       2.1447       84.93      4.5232    -11.671 \n",
      "AAA             0.2351   0.2040   594.37    109.76     0.5786       0.9878       83.49      0.8497    -0.924  \n",
      "\n",
      "Method: DSGE_Regime_Switching\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Variable        CV RMSE  CV MAE   CV MAPE   CV SMAPE   CV Theil_U1  CV Theil_U2  CV MdAPE   CV MASE   CV R¬≤   \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GDPC1           0.3575   0.3263   193.64    171.44     0.8282       1.1676       201.96     0.4934    -1.656  \n",
      "PAYEMS          0.2057   0.1916   132.68    158.48     0.7479       2.3774       108.65     0.4542    -8.345  \n",
      "INDPRO          0.4661   0.4224   287.96    153.88     0.7592       0.9325       122.46     0.5405    -0.146  \n",
      "ICSA            0.5040   0.4822   44.33     60.36      0.3108       9.1827       45.21      2.0206    -126.104\n",
      "CPIAUCSL        0.5122   0.4187   118.38    63.83      0.3318       1.1150       83.16      1.0717    -2.849  \n",
      "PCEPI           0.4104   0.3498   92.39     45.74      0.2563       1.0283       45.54      1.0209    -0.689  \n",
      "AHETPI          0.5184   0.4624   47.69     71.76      0.3616       2.8870       46.49      2.0135    -16.929 \n",
      "DCOILWTICO      0.4931   0.4468   77.32     126.76     0.6534       1.3309       80.27      1.2815    -5.359  \n",
      "FEDFUNDS        0.9199   0.8250   105.41    69.75      0.3532       3.3452       74.52      6.0297    -64.170 \n",
      "DGS10           0.4716   0.3872   120.52    54.12      0.2958       1.1880       68.28      1.2143    -2.224  \n",
      "M2SL            0.7552   0.6785   71.82     61.56      0.3344       1.2091       47.00      2.7691    -3.175  \n",
      "AAA             0.5680   0.5200   2091.17   135.10     0.6498       2.3060       361.60     2.1707    -11.601 \n",
      "\n",
      "Method: DSGE_Time_Varying\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Variable        CV RMSE  CV MAE   CV MAPE   CV SMAPE   CV Theil_U1  CV Theil_U2  CV MdAPE   CV MASE   CV R¬≤   \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GDPC1           0.3204   0.2920   168.39    172.94     0.8321       1.0818       168.39     0.4426    -1.122  \n",
      "PAYEMS          0.2148   0.2028   142.12    166.81     0.8069       2.4891       116.08     0.4815    -9.707  \n",
      "INDPRO          0.4556   0.4064   244.42    157.11     0.7898       0.9135       110.66     0.5199    -0.102  \n",
      "ICSA            0.6060   0.5907   54.10     76.57      0.3888       11.1794      54.91      2.4674    -176.306\n",
      "CPIAUCSL        0.5737   0.4655   80.02     69.63      0.3249       0.9257       48.42      1.1964    -1.430  \n",
      "PCEPI           0.5295   0.4533   78.02     70.59      0.3077       1.0216       51.58      1.3263    -0.835  \n",
      "AHETPI          0.7497   0.7235   67.07     107.84     0.5241       3.6676       66.02      3.1594    -26.542 \n",
      "DCOILWTICO      0.5623   0.4912   84.11     136.79     0.7314       1.4928       85.80      1.4093    -6.727  \n",
      "FEDFUNDS        0.9498   0.8940   98.78     79.36      0.3909       3.8114       70.57      6.4965    -90.161 \n",
      "DGS10           0.4102   0.3248   101.31    48.31      0.2788       1.0545       49.07      1.0168    -1.404  \n",
      "M2SL            0.8185   0.7378   72.20     69.30      0.3780       1.3232       51.75      3.0091    -3.953  \n",
      "AAA             0.5520   0.5025   1962.10   134.02     0.6429       2.2451       339.05     2.0983    -11.087 \n",
      "\n",
      "\n",
      "DSGE-INFORMED FORECAST SUMMARY (8 periods ahead):\n",
      "==========================================================================================\n",
      "\n",
      "Variable             Latest Forecast CV RMSE    Original R¬≤ \n",
      "------------------------------------------------------------\n",
      "GDPC1                          1.88    0.6356       0.768\n",
      "PAYEMS                         0.38    0.6356       0.893\n",
      "INDPRO                         0.26    0.6356       0.550\n",
      "ICSA                         -12.72    0.6356       0.600\n",
      "CPIAUCSL                       1.89    0.6356       0.887\n",
      "PCEPI                          1.64    0.6356       0.903\n",
      "AHETPI                         2.81    0.6356       0.689\n",
      "DCOILWTICO                     3.98    0.6356       0.252\n",
      "FEDFUNDS                       2.12    0.6356       0.682\n",
      "DGS10                          3.66    0.6356       0.813\n",
      "M2SL                           5.10    0.6356       0.641\n",
      "AAA                            5.19    0.6356       0.710\n",
      "\n",
      "DSGE-INFORMED ENHANCED DFM-THETA ANALYSIS COMPLETE\n",
      "Key advantages:\n",
      "‚Ä¢ Theta transformations respect DSGE economic structure\n",
      "‚Ä¢ VAR priors properly adapted to transformed factor space\n",
      "‚Ä¢ Original loadings preserved (no loss of economic interpretation)\n",
      "‚Ä¢ Cross-validation accounts for DSGE temporal structure\n"
     ]
    }
   ],
   "source": [
    "base_analysis = run_core_economic_analysis(dsge_posterior_estimates)\n",
    "base_dfm = base_analysis['model']\n",
    "enhanced_dfm, initial_results = enhance_dsge_dfm_with_theta(base_dfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSGE-INFORMED ENHANCED DFM-THETA ANALYSIS\n",
      "================================================================================\n",
      "‚úì Using DSGE structural priors for VAR coefficient adaptation\n",
      "‚úì Preserving original factor loadings throughout\n",
      "‚úì Maintaining economic interpretation of factors\n",
      "\n",
      "====================================================================================================\n",
      "DSGE-INFORMED THETA METHOD COMPARISON\n",
      "====================================================================================================\n",
      "Using Bayesian VAR with DSGE structure preservation\n",
      "\n",
      "--- DSGE_HP_Trend_Cycle Method ---\n",
      "Running DSGE-Constrained HP Trend-Cycle Method...\n",
      "Evaluating DSGE_HP_Trend_Cycle with DSGE consistency...\n",
      "Average R¬≤: 0.632\n",
      "CV RMSE: 0.9066\n",
      "DSGE-Informed: Yes\n",
      "Original Loadings Preserved: True\n",
      "\n",
      "--- DSGE_Regime_Switching Method ---\n",
      "Running DSGE-Informed Regime Switching Method...\n",
      "Evaluating DSGE_Regime_Switching with DSGE consistency...\n",
      "Average R¬≤: 0.665\n",
      "CV RMSE: 0.5702\n",
      "DSGE-Informed: Yes\n",
      "Original Loadings Preserved: True\n",
      "\n",
      "--- DSGE_Time_Varying Method ---\n",
      "Running DSGE-Informed Time-Varying Method...\n",
      "Evaluating DSGE_Time_Varying with DSGE consistency...\n",
      "Average R¬≤: 0.699\n",
      "CV RMSE: 0.6356\n",
      "DSGE-Informed: Yes\n",
      "Original Loadings Preserved: True\n",
      "Debug: run_dsge_theta_comparison returning: ['DSGE_HP_Trend_Cycle', 'DSGE_Regime_Switching', 'DSGE_Time_Varying']\n",
      "Debug: After assignment, method_results has: ['DSGE_HP_Trend_Cycle', 'DSGE_Regime_Switching', 'DSGE_Time_Varying']\n",
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE METHOD SELECTION\n",
      "================================================================================\n",
      "Method                    Composite Score Avg RMSE   Avg R¬≤   Avg Theil_U1 Avg Theil_U2 Avg MASE   DSGE  \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "DSGE_Time_Varying         0.7481          0.5619     0.699    0.5330       2.6005       1.9686     Yes   \n",
      "DSGE_Regime_Switching     0.7481          0.5152     0.665    0.4902       2.3391       1.7567     Yes   \n",
      "DSGE_HP_Trend_Cycle       0.2000          0.7375     0.632    0.7643       3.4978       2.7418     Yes   \n",
      "\n",
      "Selected Best Method: DSGE_Time_Varying (Score: 0.7481)\n",
      "Debug: After select_best_method, method_results has: ['DSGE_HP_Trend_Cycle', 'DSGE_Regime_Switching', 'DSGE_Time_Varying']\n",
      "\n",
      "============================================================================================================================================\n",
      "DSGE-INFORMED THETA METHOD COMPARISON RESULTS\n",
      "============================================================================================================================================\n",
      "\n",
      "Method                    Avg R¬≤   CV RMSE    CV MAE     CV MAPE    DSGE   Loadings \n",
      "--------------------------------------------------------------------------------\n",
      "DSGE_HP_Trend_Cycle       0.632    0.9066     0.6926     134.77     Yes    Original \n",
      "DSGE_Regime_Switching     0.665    0.5702     0.4592     281.94     Yes    Original \n",
      "DSGE_Time_Varying         0.699    0.6356     0.5070     262.72     Yes    Original \n",
      "\n",
      "\n",
      "================================================================================\n",
      "DSGE PRIOR INTEGRATION SUMMARY\n",
      "================================================================================\n",
      "DSGE Parameters Used:\n",
      "  sigma: 1.362\n",
      "  theta: 0.210\n",
      "  phi_pi: 2.768\n",
      "  phi_y: 0.326\n",
      "  rho_a: 0.204\n",
      "  sigma_a: 0.621\n",
      "  rho_v: 0.557\n",
      "  sigma_v: 0.177\n",
      "  rho_d: 0.736\n",
      "  sigma_d: 0.186\n",
      "  rho_s: 0.511\n",
      "  sigma_s: 0.097\n",
      "\n",
      "Structural Consistency:\n",
      "  ‚Ä¢ Original factor loadings preserved: YES\n",
      "  ‚Ä¢ VAR priors adapted to theta transformations: YES\n",
      "  ‚Ä¢ Economic interpretation maintained: YES\n",
      "  ‚Ä¢ DSGE constraints applied to theta parameters: YES\n",
      "\n",
      "\n",
      "DETAILED RESULTS FOR BEST METHOD: DSGE_Time_Varying\n",
      "================================================================================\n",
      "\n",
      "Variable Fit (using original DSGE-informed loadings):\n",
      "------------------------------------------------------------\n",
      "Variable        R¬≤       Factor_1     Factor_2     Factor_3    \n",
      "------------------------------------------------------------\n",
      "GDPC1           0.768    0.220        -0.370       -0.300      \n",
      "PAYEMS          0.893    0.304        -0.381       -0.254      \n",
      "INDPRO          0.550    0.193        -0.335       -0.269      \n",
      "ICSA            0.600    0.373        -0.065       -0.162      \n",
      "CPIAUCSL        0.887    0.380        -0.053       0.397       \n",
      "PCEPI           0.903    0.389        -0.069       0.389       \n",
      "AHETPI          0.689    0.194        0.043        0.501       \n",
      "DCOILWTICO      0.252    0.183        -0.212       0.150       \n",
      "FEDFUNDS        0.682    0.336        0.334        0.002       \n",
      "DGS10           0.813    0.289        0.429        -0.200      \n",
      "M2SL            0.641    -0.312       -0.186       0.244       \n",
      "AAA             0.710    0.148        0.465        -0.257      \n",
      "\n",
      "Average R¬≤ (Best Method): 0.699\n",
      "\n",
      "VAR Model Comparison:\n",
      "  Base VAR Log-Likelihood: -328.55\n",
      "  Theta VAR Log-Likelihood: -334.13\n",
      "  Improvement: -5.58\n",
      "\n",
      "======================================================================================================================================================\n",
      "DETAILED VARIABLE-LEVEL CROSS-VALIDATION RESULTS\n",
      "======================================================================================================================================================\n",
      "\n",
      "Method: DSGE_HP_Trend_Cycle\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Variable        CV RMSE  CV MAE   CV MAPE   CV SMAPE   CV Theil_U1  CV Theil_U2  CV MdAPE   CV MASE   CV R¬≤   \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GDPC1           0.2586   0.2142   101.16    176.13     0.9331       0.8549       99.13      0.3257    -0.275  \n",
      "PAYEMS          0.1861   0.1730   102.48    154.68     0.7608       2.1459       90.91      0.4100    -6.717  \n",
      "INDPRO          0.4513   0.3903   125.50    183.68     0.9559       0.9033       99.93      0.4989    -0.069  \n",
      "ICSA            0.9455   0.9394   86.01     152.33     0.7589       17.5110      86.64      3.9137    -424.693\n",
      "CPIAUCSL        0.9141   0.8371   72.83     118.93     0.6649       1.3516       78.67      2.1542    -4.482  \n",
      "PCEPI           0.9548   0.9014   89.09     139.42     0.7258       1.8101       85.11      2.6360    -4.701  \n",
      "AHETPI          1.1469   1.1309   93.89     169.82     0.8318       4.6654       94.01      4.9493    -41.421 \n",
      "DCOILWTICO      0.6183   0.5704   93.91     164.39     0.8444       1.5479       94.34      1.6344    -6.660  \n",
      "FEDFUNDS        1.3551   1.3100   94.20     149.85     0.7530       6.3183       87.20      9.3765    -277.344\n",
      "DGS10           0.5687   0.5239   82.78     116.99     0.5992       1.7327       73.48      1.6304    -4.562  \n",
      "M2SL            1.2152   1.1172   81.05     141.06     0.7649       2.1447       84.93      4.5232    -11.671 \n",
      "AAA             0.2351   0.2040   594.37    109.76     0.5786       0.9878       83.49      0.8497    -0.924  \n",
      "\n",
      "Method: DSGE_Regime_Switching\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Variable        CV RMSE  CV MAE   CV MAPE   CV SMAPE   CV Theil_U1  CV Theil_U2  CV MdAPE   CV MASE   CV R¬≤   \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GDPC1           0.3575   0.3263   193.64    171.44     0.8282       1.1676       201.96     0.4934    -1.656  \n",
      "PAYEMS          0.2057   0.1916   132.68    158.48     0.7479       2.3774       108.65     0.4542    -8.345  \n",
      "INDPRO          0.4661   0.4224   287.96    153.88     0.7592       0.9325       122.46     0.5405    -0.146  \n",
      "ICSA            0.5040   0.4822   44.33     60.36      0.3108       9.1827       45.21      2.0206    -126.104\n",
      "CPIAUCSL        0.5122   0.4187   118.38    63.83      0.3318       1.1150       83.16      1.0717    -2.849  \n",
      "PCEPI           0.4104   0.3498   92.39     45.74      0.2563       1.0283       45.54      1.0209    -0.689  \n",
      "AHETPI          0.5184   0.4624   47.69     71.76      0.3616       2.8870       46.49      2.0135    -16.929 \n",
      "DCOILWTICO      0.4931   0.4468   77.32     126.76     0.6534       1.3309       80.27      1.2815    -5.359  \n",
      "FEDFUNDS        0.9199   0.8250   105.41    69.75      0.3532       3.3452       74.52      6.0297    -64.170 \n",
      "DGS10           0.4716   0.3872   120.52    54.12      0.2958       1.1880       68.28      1.2143    -2.224  \n",
      "M2SL            0.7552   0.6785   71.82     61.56      0.3344       1.2091       47.00      2.7691    -3.175  \n",
      "AAA             0.5680   0.5200   2091.17   135.10     0.6498       2.3060       361.60     2.1707    -11.601 \n",
      "\n",
      "Method: DSGE_Time_Varying\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Variable        CV RMSE  CV MAE   CV MAPE   CV SMAPE   CV Theil_U1  CV Theil_U2  CV MdAPE   CV MASE   CV R¬≤   \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "GDPC1           0.3204   0.2920   168.39    172.94     0.8321       1.0818       168.39     0.4426    -1.122  \n",
      "PAYEMS          0.2148   0.2028   142.12    166.81     0.8069       2.4891       116.08     0.4815    -9.707  \n",
      "INDPRO          0.4556   0.4064   244.42    157.11     0.7898       0.9135       110.66     0.5199    -0.102  \n",
      "ICSA            0.6060   0.5907   54.10     76.57      0.3888       11.1794      54.91      2.4674    -176.306\n",
      "CPIAUCSL        0.5737   0.4655   80.02     69.63      0.3249       0.9257       48.42      1.1964    -1.430  \n",
      "PCEPI           0.5295   0.4533   78.02     70.59      0.3077       1.0216       51.58      1.3263    -0.835  \n",
      "AHETPI          0.7497   0.7235   67.07     107.84     0.5241       3.6676       66.02      3.1594    -26.542 \n",
      "DCOILWTICO      0.5623   0.4912   84.11     136.79     0.7314       1.4928       85.80      1.4093    -6.727  \n",
      "FEDFUNDS        0.9498   0.8940   98.78     79.36      0.3909       3.8114       70.57      6.4965    -90.161 \n",
      "DGS10           0.4102   0.3248   101.31    48.31      0.2788       1.0545       49.07      1.0168    -1.404  \n",
      "M2SL            0.8185   0.7378   72.20     69.30      0.3780       1.3232       51.75      3.0091    -3.953  \n",
      "AAA             0.5520   0.5025   1962.10   134.02     0.6429       2.2451       339.05     2.0983    -11.087 \n",
      "\n",
      "\n",
      "DSGE-INFORMED FORECAST SUMMARY (8 periods ahead):\n",
      "==========================================================================================\n",
      "\n",
      "Variable             Latest Forecast CV RMSE    Original R¬≤ \n",
      "------------------------------------------------------------\n",
      "GDPC1                          1.88    0.6356       0.768\n",
      "PAYEMS                         0.38    0.6356       0.893\n",
      "INDPRO                         0.26    0.6356       0.550\n",
      "ICSA                         -12.72    0.6356       0.600\n",
      "CPIAUCSL                       1.89    0.6356       0.887\n",
      "PCEPI                          1.64    0.6356       0.903\n",
      "AHETPI                         2.81    0.6356       0.689\n",
      "DCOILWTICO                     3.98    0.6356       0.252\n",
      "FEDFUNDS                       2.12    0.6356       0.682\n",
      "DGS10                          3.66    0.6356       0.813\n",
      "M2SL                           5.10    0.6356       0.641\n",
      "AAA                            5.19    0.6356       0.710\n",
      "\n",
      "DSGE-INFORMED ENHANCED DFM-THETA ANALYSIS COMPLETE\n",
      "Key advantages:\n",
      "‚Ä¢ Theta transformations respect DSGE economic structure\n",
      "‚Ä¢ VAR priors properly adapted to transformed factor space\n",
      "‚Ä¢ Original loadings preserved (no loss of economic interpretation)\n",
      "‚Ä¢ Cross-validation accounts for DSGE temporal structure\n"
     ]
    }
   ],
   "source": [
    "# Now run the complete analysis which includes comparison + selection + printing\n",
    "final_results = enhanced_dfm.run_complete_dsge_theta_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIVE THETA STRATEGIES EXAMPLE\n",
      "==================================================\n",
      "\n",
      "The Five Core Theta Strategies:\n",
      "==================================================\n",
      "\n",
      "1. FREQUENCY_DUAL:\n",
      "   ‚Ä¢ Decomposes factors into trend, cyclical, and high-frequency components\n",
      "   ‚Ä¢ Optimizes weights: F_theta = Œ∏1*trend + Œ∏2*cyclical + Œ∏3*high_freq\n",
      "   ‚Ä¢ Best for: Capturing multiple time scales in economic data\n",
      "\n",
      "2. LAGGED:\n",
      "   ‚Ä¢ Uses multi-lag structure with current and lagged factor values\n",
      "   ‚Ä¢ Optimizes weights: F_theta[t] = Œ∏1*F[t] + Œ∏2*F[t-1] + Œ∏3*F[t-2]\n",
      "   ‚Ä¢ Best for: Modeling temporal dependencies and persistence\n",
      "\n",
      "3. SEQUENTIAL:\n",
      "   ‚Ä¢ Factor-by-factor optimization with convergence checking\n",
      "   ‚Ä¢ Iteratively optimizes each factor while holding others fixed\n",
      "   ‚Ä¢ Best for: Handling factor interdependencies systematically\n",
      "\n",
      "4. CONSTRAINED:\n",
      "   ‚Ä¢ Incorporates DSGE structural constraints and economic theory\n",
      "   ‚Ä¢ Penalizes violations of economic relationships\n",
      "   ‚Ä¢ Best for: Maintaining theoretical consistency with DSGE models\n",
      "\n",
      "5. GLOBAL:\n",
      "   ‚Ä¢ Multi-algorithm global optimization with ensemble metrics\n",
      "   ‚Ä¢ Uses differential evolution, basin hopping, dual annealing\n",
      "   ‚Ä¢ Best for: Finding global optimum across complex parameter space\n",
      "\n",
      "Usage Examples:\n",
      "==================================================\n",
      "\n",
      "# Compare all five strategies and select best:\n",
      "enhanced_dfm, results = enhance_dsge_dfm_with_five_theta_strategies(\n",
      "    existing_dsge_dfm_model, strategy='auto')\n",
      "\n",
      "# Use specific strategy:\n",
      "enhanced_dfm, results = enhance_dsge_dfm_with_five_theta_strategies(\n",
      "    existing_dsge_dfm_model, strategy='constrained')\n",
      "\n",
      "# Compare all strategies without selection:\n",
      "enhanced_dfm, results = compare_five_theta_strategies(existing_dsge_dfm_model)\n"
     ]
    }
   ],
   "source": [
    "# DSGE-Informed Enhanced DFM with Five Core Theta Strategies\n",
    "# UPDATED: Now implements the five specific theta strategies: FREQUENCY_DUAL, LAGGED, SEQUENTIAL, CONSTRAINED, GLOBAL\n",
    "\n",
    "class DSGEInformedEnhancedDFMTheta:\n",
    "    \"\"\"\n",
    "    Enhanced DFM with theta optimization using five core strategies\n",
    "    Implements: FREQUENCY_DUAL, LAGGED, SEQUENTIAL, CONSTRAINED, GLOBAL\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_dfm_model):\n",
    "        # Import structural components from DSGE-informed base model\n",
    "        self.factors = base_dfm_model.factors.copy()\n",
    "        self.loadings = base_dfm_model.loadings.copy()\n",
    "        self.data_standardized = base_dfm_model.data_standardized.copy()\n",
    "        self.scaler = base_dfm_model.scaler\n",
    "        self.combined_data = base_dfm_model.combined_data.copy()\n",
    "        \n",
    "        # CRITICAL: Preserve DSGE-informed VAR structure\n",
    "        self.base_factor_var = base_dfm_model.factor_var\n",
    "        \n",
    "        # Extract DSGE priors from base model's estimation results\n",
    "        self.dsge_priors = self._extract_dsge_posterior_estimates(base_dfm_model)\n",
    "        self.idiosyncratic_var = base_dfm_model.idiosyncratic_var.copy()\n",
    "\n",
    "        # Model dimensions\n",
    "        self.T_obs, self.n_factors = self.factors.shape\n",
    "        self.N_vars = len(self.data_standardized.columns)\n",
    "\n",
    "        # Initialize theta components\n",
    "        self.optimal_theta = None\n",
    "        self.theta_strategy = None\n",
    "        self.method_results = {}\n",
    "        \n",
    "        # Results storage for each method\n",
    "        self.method_forecasts = {}\n",
    "        self.method_var_models = {}\n",
    "        self.method_r2 = {}\n",
    "        self.method_metrics = {}\n",
    "        \n",
    "        # Cross-validation setup\n",
    "        self.tscv = TimeSeriesSplit(n_splits=3, test_size=4)\n",
    "\n",
    "        print(f\"DSGE-Informed Enhanced DFM-Theta initialized:\")\n",
    "        print(f\"  Factors: {self.n_factors}, Variables: {self.N_vars}\")\n",
    "        print(f\"  DSGE priors: {'Available' if self.dsge_priors else 'None'}\")\n",
    "        print(f\"  Base VAR estimation: {'Bayesian' if self.base_factor_var.get('bayesian', False) else 'OLS'}\")\n",
    "\n",
    "    def _extract_dsge_posterior_estimates(self, base_dfm_model):\n",
    "        \"\"\"Extract DSGE posterior estimates from the base model's DSGE estimation\"\"\"\n",
    "        # Try to get DSGE priors from the base model\n",
    "        if hasattr(base_dfm_model, 'dsge_priors') and base_dfm_model.dsge_priors is not None:\n",
    "            return base_dfm_model.dsge_priors\n",
    "            \n",
    "        # If base model was created with DSGE posterior estimates, extract them\n",
    "        if hasattr(base_dfm_model, 'factor_var') and base_dfm_model.factor_var.get('bayesian', False):\n",
    "            prior_info = base_dfm_model.factor_var.get('prior_info')\n",
    "            if prior_info and 'dsge_params' in prior_info:\n",
    "                dsge_params = prior_info['dsge_params']\n",
    "                return {\n",
    "                    'sigma': {'mean': dsge_params.get('sigma', 1.25), 'std': 0.15},\n",
    "                    'theta': {'mean': dsge_params.get('theta', 0.75), 'std': 0.08},\n",
    "                    'phi_pi': {'mean': dsge_params.get('phi_pi', 1.65), 'std': 0.25},\n",
    "                    'phi_y': {'mean': dsge_params.get('phi_y', 0.35), 'std': 0.12},\n",
    "                    'rho_a': {'mean': dsge_params.get('rho_a', 0.82), 'std': 0.10},\n",
    "                    'rho_v': {'mean': dsge_params.get('rho_v', 0.45), 'std': 0.18},\n",
    "                }\n",
    "        \n",
    "        # Try to reconstruct from any DSGE calibration in the base model\n",
    "        if hasattr(base_dfm_model, 'organized_blocks'):\n",
    "            return {\n",
    "                'sigma': {'mean': 1.30, 'std': 0.20},\n",
    "                'theta': {'mean': 0.75, 'std': 0.10},\n",
    "                'phi_pi': {'mean': 1.50, 'std': 0.35},\n",
    "                'phi_y': {'mean': 0.25, 'std': 0.10},\n",
    "                'rho_a': {'mean': 0.80, 'std': 0.15},\n",
    "                'rho_v': {'mean': 0.50, 'std': 0.20},\n",
    "            }\n",
    "            \n",
    "        print(\"  No DSGE priors found - theta optimization will use econometric constraints only\")\n",
    "        return None\n",
    "\n",
    "    # ============================================================================\n",
    "    # FIVE CORE THETA STRATEGIES\n",
    "    # ============================================================================\n",
    "\n",
    "    def frequency_dual_theta_strategy(self):\n",
    "        \"\"\"\n",
    "        FREQUENCY_DUAL Strategy: Dual frequency decomposition with theta optimization\n",
    "        Separates factors into trend, low-frequency, and high-frequency components\n",
    "        FIXED VERSION - Prevents NaN errors during cross-validation\n",
    "        \"\"\"\n",
    "        print(\"FREQUENCY_DUAL Strategy: Optimizing dual frequency decomposition with robustness...\")\n",
    "\n",
    "        def extract_frequency_components(series, window_short=4, window_long=12):\n",
    "            \"\"\"Extract trend, low-freq, and high-freq components with NaN prevention\"\"\"\n",
    "            series_length = len(series)\n",
    "            \n",
    "            # Minimum length check and adjust windows dynamically\n",
    "            if series_length < 8:  # Minimum viable series length\n",
    "                # Return simple decomposition for very short series\n",
    "                trend = pd.Series([series.mean()] * series_length, index=series.index)\n",
    "                cyclical = pd.Series([0.0] * series_length, index=series.index) \n",
    "                high_freq = series - trend\n",
    "                return trend, cyclical, high_freq\n",
    "            \n",
    "            # More conservative window sizing\n",
    "            window_short = max(3, min(window_short, series_length // 6))  # Changed from //4\n",
    "            window_long = max(window_short * 2, min(window_long, series_length // 3))  # Changed from //2\n",
    "            \n",
    "            # Robust trend extraction with fallback\n",
    "            try:\n",
    "                trend = series.rolling(window=window_long, center=True, min_periods=1).mean()\n",
    "            except:\n",
    "                # Fallback to simple linear trend\n",
    "                x = np.arange(len(series))\n",
    "                coeffs = np.polyfit(x, series.values, 1)\n",
    "                trend = pd.Series(coeffs[0] * x + coeffs[1], index=series.index)\n",
    "            \n",
    "            # Handle edge cases in trend\n",
    "            if trend.isna().any():\n",
    "                # Forward/backward fill with boundary handling\n",
    "                trend = trend.fillna(method='bfill').fillna(method='ffill')\n",
    "                if trend.isna().any():  # Still NaN after filling\n",
    "                    trend = trend.fillna(series.mean())\n",
    "            \n",
    "            # Robust cyclical component\n",
    "            try:\n",
    "                cyclical = series.rolling(window=window_short, center=True, min_periods=1).mean()\n",
    "                if cyclical.isna().any():\n",
    "                    cyclical = cyclical.fillna(method='bfill').fillna(method='ffill')\n",
    "                    if cyclical.isna().any():\n",
    "                        cyclical = cyclical.fillna(series.mean())\n",
    "            except:\n",
    "                cyclical = pd.Series([0.0] * len(series), index=series.index)\n",
    "            \n",
    "            cyclical = cyclical - trend\n",
    "            \n",
    "            # High-frequency with validation\n",
    "            high_freq = series - trend - cyclical\n",
    "            \n",
    "            # Final NaN check and cleanup\n",
    "            components = [(trend, 'trend'), (cyclical, 'cyclical'), (high_freq, 'high_freq')]\n",
    "            cleaned_components = []\n",
    "            \n",
    "            for component, name in components:\n",
    "                if component.isna().any() or np.isinf(component.values).any():\n",
    "                    print(f\"Warning: Invalid values in {name} component, using fallback\")\n",
    "                    if name == 'trend':\n",
    "                        component = pd.Series([series.mean()] * len(series), index=series.index)\n",
    "                    else:\n",
    "                        component = pd.Series([0.0] * len(series), index=series.index)\n",
    "                cleaned_components.append(component)\n",
    "            \n",
    "            return cleaned_components[0], cleaned_components[1], cleaned_components[2]\n",
    "\n",
    "        def frequency_dual_objective(theta_vector):\n",
    "            \"\"\"Objective function with comprehensive NaN prevention\"\"\"\n",
    "            # Three parameters per factor: trend weight, cyclical weight, high-freq weight\n",
    "            n_params_per_factor = 3\n",
    "            if len(theta_vector) != n_params_per_factor * self.n_factors:\n",
    "                return 1e10\n",
    "                \n",
    "            F_theta = np.zeros((self.T_obs, self.n_factors))\n",
    "            \n",
    "            for i, factor_name in enumerate(self.factors.columns):\n",
    "                factor_series = self.factors[factor_name]\n",
    "                \n",
    "                # Add input validation\n",
    "                if factor_series.isna().any() or np.isinf(factor_series.values).any():\n",
    "                    print(f\"Warning: Invalid input data for factor {factor_name}\")\n",
    "                    return 1e10\n",
    "                    \n",
    "                trend, cyclical, high_freq = extract_frequency_components(factor_series)\n",
    "                \n",
    "                # Get theta parameters for this factor\n",
    "                idx_start = i * n_params_per_factor\n",
    "                theta_trend = theta_vector[idx_start]\n",
    "                theta_cyclical = theta_vector[idx_start + 1] \n",
    "                theta_high = theta_vector[idx_start + 2]\n",
    "                \n",
    "                # Validate theta parameters\n",
    "                if any(np.isnan([theta_trend, theta_cyclical, theta_high])) or \\\n",
    "                any(np.isinf([theta_trend, theta_cyclical, theta_high])):\n",
    "                    return 1e10\n",
    "                \n",
    "                # Combine components with validation\n",
    "                combined = (theta_trend * trend + \n",
    "                        theta_cyclical * cyclical + \n",
    "                        theta_high * high_freq)\n",
    "                \n",
    "                # Validate combined result\n",
    "                if combined.isna().any() or np.isinf(combined.values).any():\n",
    "                    print(f\"Warning: Invalid combined values for factor {factor_name}\")\n",
    "                    return 1e10\n",
    "                    \n",
    "                F_theta[:, i] = combined.values\n",
    "\n",
    "            # Final validation before VAR estimation\n",
    "            if np.isnan(F_theta).any() or np.isinf(F_theta).any():\n",
    "                print(\"Warning: NaN/Inf values in F_theta matrix\")\n",
    "                return 1e10\n",
    "\n",
    "            try:\n",
    "                # Estimate theta-aware VAR\n",
    "                theta_var = self._estimate_theta_aware_var(\n",
    "                    pd.DataFrame(F_theta, columns=self.factors.columns), \n",
    "                    theta_vector, 'FREQUENCY_DUAL')\n",
    "                \n",
    "                # Validate VAR results\n",
    "                if theta_var is None or 'coefficients' not in theta_var:\n",
    "                    return 1e10\n",
    "                    \n",
    "                # Calculate reconstruction error using original loadings\n",
    "                Y_reconstructed = F_theta @ self.loadings.values.T\n",
    "                \n",
    "                # Validate reconstruction\n",
    "                if np.isnan(Y_reconstructed).any() or np.isinf(Y_reconstructed).any():\n",
    "                    return 1e10\n",
    "                    \n",
    "                reconstruction_error = np.sum((self.data_standardized.values - Y_reconstructed)**2)\n",
    "                \n",
    "                # Validate error calculation\n",
    "                if np.isnan(reconstruction_error) or np.isinf(reconstruction_error):\n",
    "                    return 1e10\n",
    "                \n",
    "                # Add VAR stability penalty\n",
    "                stability_penalty = self._calculate_var_stability_penalty(theta_var)\n",
    "                if np.isnan(stability_penalty) or np.isinf(stability_penalty):\n",
    "                    stability_penalty = 1000.0\n",
    "                \n",
    "                total_objective = reconstruction_error + stability_penalty\n",
    "                \n",
    "                # Final objective validation\n",
    "                if np.isnan(total_objective) or np.isinf(total_objective):\n",
    "                    return 1e10\n",
    "                    \n",
    "                return total_objective\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Exception in frequency_dual_objective: {e}\")\n",
    "                return 1e10\n",
    "\n",
    "        # More conservative bounds to prevent extreme values\n",
    "        bounds = []\n",
    "        for _ in range(self.n_factors):\n",
    "            bounds.extend([\n",
    "                (0.8, 1.2),   # Trend weight - narrower range\n",
    "                (-0.3, 0.3),  # Cyclical weight - narrower range  \n",
    "                (0.7, 1.3)    # High-freq weight - narrower range\n",
    "            ])\n",
    "        \n",
    "        # More conservative initial guess\n",
    "        initial_guess = []\n",
    "        for _ in range(self.n_factors):\n",
    "            initial_guess.extend([1.0, 0.05, 1.0])  # Smaller cyclical component\n",
    "\n",
    "        # Add multiple attempts with fallbacks\n",
    "        for attempt in range(3):\n",
    "            try:\n",
    "                result = minimize(frequency_dual_objective, initial_guess, bounds=bounds,\n",
    "                                method='L-BFGS-B', options={'maxiter': 200, 'ftol': 1e-6})\n",
    "                \n",
    "                if result.success and not np.isnan(result.fun):\n",
    "                    return result.x, lambda factors, theta_params: self._apply_frequency_dual_transform(factors, theta_params)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Optimization attempt {attempt + 1} failed: {e}\")\n",
    "                # Adjust initial guess for next attempt\n",
    "                initial_guess = [x * (0.9 + 0.2 * np.random.random()) for x in initial_guess]\n",
    "        \n",
    "        # Final fallback\n",
    "        print(\"All optimization attempts failed, using conservative defaults\")\n",
    "        default_params = [1.0, 0.0, 1.0] * self.n_factors\n",
    "        return default_params, lambda factors, theta_params: self._apply_frequency_dual_transform(factors, theta_params)\n",
    "\n",
    "    def _apply_frequency_dual_transform(self, factors, theta_params):\n",
    "        \"\"\"Apply frequency dual transformation with NaN prevention\"\"\"\n",
    "        F_theta_df = factors.copy()\n",
    "        n_params_per_factor = 3\n",
    "        \n",
    "        def extract_frequency_components(series, window_short=4, window_long=12):\n",
    "            \"\"\"Same robust extraction function as in objective\"\"\"\n",
    "            series_length = len(series)\n",
    "            \n",
    "            if series_length < 8:\n",
    "                trend = pd.Series([series.mean()] * series_length, index=series.index)\n",
    "                cyclical = pd.Series([0.0] * series_length, index=series.index) \n",
    "                high_freq = series - trend\n",
    "                return trend, cyclical, high_freq\n",
    "            \n",
    "            window_short = max(3, min(window_short, series_length // 6))\n",
    "            window_long = max(window_short * 2, min(window_long, series_length // 3))\n",
    "            \n",
    "            try:\n",
    "                trend = series.rolling(window=window_long, center=True, min_periods=1).mean()\n",
    "            except:\n",
    "                x = np.arange(len(series))\n",
    "                coeffs = np.polyfit(x, series.values, 1)\n",
    "                trend = pd.Series(coeffs[0] * x + coeffs[1], index=series.index)\n",
    "            \n",
    "            if trend.isna().any():\n",
    "                trend = trend.fillna(method='bfill').fillna(method='ffill')\n",
    "                if trend.isna().any():\n",
    "                    trend = trend.fillna(series.mean())\n",
    "            \n",
    "            try:\n",
    "                cyclical = series.rolling(window=window_short, center=True, min_periods=1).mean()\n",
    "                if cyclical.isna().any():\n",
    "                    cyclical = cyclical.fillna(method='bfill').fillna(method='ffill')\n",
    "                    if cyclical.isna().any():\n",
    "                        cyclical = cyclical.fillna(series.mean())\n",
    "            except:\n",
    "                cyclical = pd.Series([0.0] * len(series), index=series.index)\n",
    "            \n",
    "            cyclical = cyclical - trend\n",
    "            high_freq = series - trend - cyclical\n",
    "            \n",
    "            components = [(trend, 'trend'), (cyclical, 'cyclical'), (high_freq, 'high_freq')]\n",
    "            cleaned_components = []\n",
    "            \n",
    "            for component, name in components:\n",
    "                if component.isna().any() or np.isinf(component.values).any():\n",
    "                    if name == 'trend':\n",
    "                        component = pd.Series([series.mean()] * len(series), index=series.index)\n",
    "                    else:\n",
    "                        component = pd.Series([0.0] * len(series), index=series.index)\n",
    "                cleaned_components.append(component)\n",
    "            \n",
    "            return cleaned_components[0], cleaned_components[1], cleaned_components[2]\n",
    "        \n",
    "        for i, factor_name in enumerate(factors.columns):\n",
    "            # Input validation\n",
    "            if factors[factor_name].isna().any():\n",
    "                print(f\"Warning: NaN input for factor {factor_name}, using interpolation\")\n",
    "                factors[factor_name] = factors[factor_name].interpolate().fillna(factors[factor_name].mean())\n",
    "            \n",
    "            trend, cyclical, high_freq = extract_frequency_components(factors[factor_name])\n",
    "            \n",
    "            idx_start = i * n_params_per_factor\n",
    "            theta_trend = theta_params[idx_start]\n",
    "            theta_cyclical = theta_params[idx_start + 1]\n",
    "            theta_high = theta_params[idx_start + 2]\n",
    "            \n",
    "            # Parameter validation\n",
    "            if any(np.isnan([theta_trend, theta_cyclical, theta_high])):\n",
    "                print(f\"Warning: NaN theta parameters for factor {factor_name}, using defaults\")\n",
    "                theta_trend, theta_cyclical, theta_high = 1.0, 0.05, 1.0\n",
    "            \n",
    "            combined = theta_trend * trend + theta_cyclical * cyclical + theta_high * high_freq\n",
    "            \n",
    "            # Output validation  \n",
    "            if combined.isna().any():\n",
    "                print(f\"Warning: NaN in transformed factor {factor_name}, using fallback\")\n",
    "                combined = factors[factor_name]  # Fallback to original\n",
    "            \n",
    "            F_theta_df[factor_name] = combined\n",
    "        \n",
    "        return F_theta_df\n",
    "\n",
    "    def lagged_theta_strategy(self):\n",
    "        \"\"\"\n",
    "        LAGGED Strategy: Incorporates lagged factor values with theta weights\n",
    "        F_theta[t] = theta1 * F[t] + theta2 * F[t-1] + theta3 * F[t-2]\n",
    "        \"\"\"\n",
    "        print(\"LAGGED Strategy: Optimizing with multi-lag factor transformation...\")\n",
    "\n",
    "        def lagged_objective(theta_vector):\n",
    "            \"\"\"Objective with multi-lag structure\"\"\"\n",
    "            # Three parameters per factor: current, lag-1, lag-2 weights\n",
    "            n_params_per_factor = 3\n",
    "            if len(theta_vector) != n_params_per_factor * self.n_factors:\n",
    "                return 1e10\n",
    "                \n",
    "            F_theta = np.zeros((self.T_obs, self.n_factors))\n",
    "            \n",
    "            for i, factor_name in enumerate(self.factors.columns):\n",
    "                factor_values = self.factors[factor_name].values\n",
    "                \n",
    "                idx_start = i * n_params_per_factor\n",
    "                theta_current = theta_vector[idx_start]\n",
    "                theta_lag1 = theta_vector[idx_start + 1]\n",
    "                theta_lag2 = theta_vector[idx_start + 2]\n",
    "                \n",
    "                # Apply lagged transformation\n",
    "                F_theta[0, i] = theta_current * factor_values[0]  # First observation\n",
    "                F_theta[1, i] = theta_current * factor_values[1] + theta_lag1 * factor_values[0]  # Second observation\n",
    "                \n",
    "                for t in range(2, self.T_obs):\n",
    "                    F_theta[t, i] = (theta_current * factor_values[t] + \n",
    "                                   theta_lag1 * factor_values[t-1] + \n",
    "                                   theta_lag2 * factor_values[t-2])\n",
    "\n",
    "            try:\n",
    "                theta_var = self._estimate_theta_aware_var(\n",
    "                    pd.DataFrame(F_theta, columns=self.factors.columns),\n",
    "                    theta_vector, 'LAGGED')\n",
    "                \n",
    "                Y_reconstructed = F_theta @ self.loadings.values.T\n",
    "                reconstruction_error = np.sum((self.data_standardized.values - Y_reconstructed)**2)\n",
    "                \n",
    "                stability_penalty = self._calculate_var_stability_penalty(theta_var)\n",
    "                return reconstruction_error + stability_penalty\n",
    "            except:\n",
    "                return 1e10\n",
    "\n",
    "        # Bounds: current weight [0.5, 1.5], lag weights [-0.8, 0.8]\n",
    "        bounds = []\n",
    "        for _ in range(self.n_factors):\n",
    "            bounds.extend([(0.5, 1.5), (-0.8, 0.8), (-0.8, 0.8)])\n",
    "        \n",
    "        initial_guess = []\n",
    "        for _ in range(self.n_factors):\n",
    "            initial_guess.extend([1.0, 0.3, 0.1])\n",
    "\n",
    "        result = minimize(lagged_objective, initial_guess, bounds=bounds,\n",
    "                         method='L-BFGS-B', options={'maxiter': 250})\n",
    "\n",
    "        if result.success:\n",
    "            return result.x, lambda factors, theta_params: self._apply_lagged_transform(factors, theta_params)\n",
    "        else:\n",
    "            return initial_guess, lambda factors, theta_params: self._apply_lagged_transform(factors, theta_params)\n",
    "\n",
    "    def _apply_lagged_transform(self, factors, theta_params):\n",
    "        \"\"\"Apply multi-lag transformation\"\"\"\n",
    "        F_theta_df = factors.copy()\n",
    "        n_params_per_factor = 3\n",
    "        \n",
    "        for i, factor_name in enumerate(factors.columns):\n",
    "            factor_values = factors[factor_name].values\n",
    "            transformed_values = np.zeros_like(factor_values)\n",
    "            \n",
    "            idx_start = i * n_params_per_factor\n",
    "            theta_current = theta_params[idx_start]\n",
    "            theta_lag1 = theta_params[idx_start + 1]\n",
    "            theta_lag2 = theta_params[idx_start + 2]\n",
    "            \n",
    "            # Apply transformation\n",
    "            transformed_values[0] = theta_current * factor_values[0]\n",
    "            transformed_values[1] = theta_current * factor_values[1] + theta_lag1 * factor_values[0]\n",
    "            \n",
    "            for t in range(2, len(factor_values)):\n",
    "                transformed_values[t] = (theta_current * factor_values[t] + \n",
    "                                       theta_lag1 * factor_values[t-1] + \n",
    "                                       theta_lag2 * factor_values[t-2])\n",
    "            \n",
    "            F_theta_df[factor_name] = transformed_values\n",
    "        \n",
    "        return F_theta_df\n",
    "\n",
    "    def sequential_theta_strategy(self):\n",
    "        \"\"\"\n",
    "        SEQUENTIAL Strategy: Sequential factor-by-factor theta optimization\n",
    "        Optimizes each factor's theta parameters sequentially while holding others fixed\n",
    "        \"\"\"\n",
    "        print(\"SEQUENTIAL Strategy: Factor-by-factor sequential optimization...\")\n",
    "\n",
    "        # Initialize with basic parameters\n",
    "        theta_params = np.ones(2 * self.n_factors)  # Two parameters per factor\n",
    "        theta_params[self.n_factors:] = 0.1  # Initialize second parameter set\n",
    "        \n",
    "        max_iterations = 5\n",
    "        tolerance = 1e-4\n",
    "        \n",
    "        for iteration in range(max_iterations):\n",
    "            old_params = theta_params.copy()\n",
    "            \n",
    "            for factor_idx in range(self.n_factors):\n",
    "                # Define single-factor objective\n",
    "                def single_factor_objective(factor_theta_params):\n",
    "                    \"\"\"Objective for optimizing single factor\"\"\"\n",
    "                    full_params = theta_params.copy()\n",
    "                    full_params[factor_idx] = factor_theta_params[0]\n",
    "                    full_params[factor_idx + self.n_factors] = factor_theta_params[1]\n",
    "                    \n",
    "                    try:\n",
    "                        F_theta = self._apply_sequential_transform(self.factors, full_params)\n",
    "                        theta_var = self._estimate_theta_aware_var(F_theta, full_params, 'SEQUENTIAL')\n",
    "                        \n",
    "                        Y_reconstructed = F_theta.values @ self.loadings.values.T\n",
    "                        reconstruction_error = np.sum((self.data_standardized.values - Y_reconstructed)**2)\n",
    "                        \n",
    "                        stability_penalty = self._calculate_var_stability_penalty(theta_var)\n",
    "                        return reconstruction_error + stability_penalty\n",
    "                    except:\n",
    "                        return 1e10\n",
    "                \n",
    "                # Optimize this factor\n",
    "                factor_bounds = [(0.1, 2.0), (-1.0, 1.0)]\n",
    "                factor_initial = [theta_params[factor_idx], theta_params[factor_idx + self.n_factors]]\n",
    "                \n",
    "                factor_result = minimize(single_factor_objective, factor_initial, \n",
    "                                       bounds=factor_bounds, method='L-BFGS-B')\n",
    "                \n",
    "                if factor_result.success:\n",
    "                    theta_params[factor_idx] = factor_result.x[0]\n",
    "                    theta_params[factor_idx + self.n_factors] = factor_result.x[1]\n",
    "            \n",
    "            # Check convergence\n",
    "            if np.abs(theta_params - old_params).max() < tolerance:\n",
    "                print(f\"Sequential optimization converged after {iteration + 1} iterations\")\n",
    "                break\n",
    "\n",
    "        return theta_params, lambda factors, theta_params: self._apply_sequential_transform(factors, theta_params)\n",
    "\n",
    "    def _apply_sequential_transform(self, factors, theta_params):\n",
    "        \"\"\"Apply sequential transformation (nonlinear with trend-deviation structure)\"\"\"\n",
    "        F_theta_df = factors.copy()\n",
    "        \n",
    "        for i, factor_name in enumerate(factors.columns):\n",
    "            theta1 = theta_params[i]\n",
    "            theta2 = theta_params[i + self.n_factors]\n",
    "            \n",
    "            # Extract trend and deviation\n",
    "            trend = self._extract_trend_linear(factors[factor_name])\n",
    "            deviation = factors[factor_name] - trend\n",
    "            \n",
    "            # Apply nonlinear transformation\n",
    "            F_theta_df[factor_name] = trend + theta1 * deviation + theta2 * (deviation ** 2)\n",
    "        \n",
    "        return F_theta_df\n",
    "\n",
    "    def constrained_theta_strategy(self):\n",
    "        \"\"\"\n",
    "        CONSTRAINED Strategy: Theta optimization with DSGE-based constraints\n",
    "        Incorporates structural economic constraints from DSGE parameters\n",
    "        \"\"\"\n",
    "        print(\"CONSTRAINED Strategy: DSGE-constrained theta optimization...\")\n",
    "\n",
    "        def constrained_objective(theta_vector):\n",
    "            \"\"\"Objective with DSGE constraints\"\"\"\n",
    "            F_theta = self._apply_constrained_transform(self.factors, theta_vector)\n",
    "            \n",
    "            try:\n",
    "                theta_var = self._estimate_theta_aware_var(F_theta, theta_vector, 'CONSTRAINED')\n",
    "                \n",
    "                Y_reconstructed = F_theta.values @ self.loadings.values.T\n",
    "                reconstruction_error = np.sum((self.data_standardized.values - Y_reconstructed)**2)\n",
    "                \n",
    "                # Add DSGE consistency penalty\n",
    "                dsge_penalty = self._calculate_dsge_constraint_penalty(theta_vector)\n",
    "                stability_penalty = self._calculate_var_stability_penalty(theta_var)\n",
    "                \n",
    "                return reconstruction_error + dsge_penalty + stability_penalty\n",
    "            except:\n",
    "                return 1e10\n",
    "\n",
    "        # DSGE-informed bounds\n",
    "        if self.dsge_priors is not None:\n",
    "            bounds = self._get_dsge_informed_bounds()\n",
    "            initial_guess = self._get_dsge_informed_initial_guess()\n",
    "        else:\n",
    "            # Fallback bounds\n",
    "            bounds = [(0.5, 1.5) for _ in range(self.n_factors)] + [(-0.5, 0.5) for _ in range(self.n_factors)]\n",
    "            initial_guess = [1.0] * self.n_factors + [0.0] * self.n_factors\n",
    "\n",
    "        result = minimize(constrained_objective, initial_guess, bounds=bounds,\n",
    "                         method='L-BFGS-B', options={'maxiter': 300})\n",
    "\n",
    "        if result.success:\n",
    "            return result.x, lambda factors, theta_params: self._apply_constrained_transform(factors, theta_params)\n",
    "        else:\n",
    "            return initial_guess, lambda factors, theta_params: self._apply_constrained_transform(factors, theta_params)\n",
    "\n",
    "    def _apply_constrained_transform(self, factors, theta_params):\n",
    "        \"\"\"Apply DSGE-constrained transformation\"\"\"\n",
    "        F_theta_df = factors.copy()\n",
    "        \n",
    "        for i, factor_name in enumerate(factors.columns):\n",
    "            theta1 = theta_params[i]\n",
    "            theta2 = theta_params[i + self.n_factors] if i + self.n_factors < len(theta_params) else 0.0\n",
    "            \n",
    "            # Apply constrained transformation\n",
    "            if i == 0:  # Demand factor - output gap transformation\n",
    "                hp_trend, hp_cycle = self._hp_filter(factors[factor_name])\n",
    "                F_theta_df[factor_name] = theta1 * hp_trend + theta2 * hp_cycle\n",
    "            elif i == 1:  # Supply factor - inflation persistence\n",
    "                F_theta_df[factor_name] = theta1 * factors[factor_name] + theta2 * factors[factor_name].shift(1).fillna(0)\n",
    "            else:  # Monetary/other factors - standard transformation\n",
    "                trend = self._extract_trend_linear(factors[factor_name])\n",
    "                deviation = factors[factor_name] - trend\n",
    "                F_theta_df[factor_name] = trend + theta1 * deviation\n",
    "        \n",
    "        return F_theta_df\n",
    "\n",
    "    def global_theta_strategy(self):\n",
    "        \"\"\"\n",
    "        GLOBAL Strategy: Global optimization across all factors simultaneously\n",
    "        Uses multiple algorithms and selects best result\n",
    "        \"\"\"\n",
    "        print(\"GLOBAL Strategy: Multi-algorithm global optimization...\")\n",
    "\n",
    "        def global_objective(theta_vector):\n",
    "            \"\"\"Global objective with ensemble error metrics\"\"\"\n",
    "            F_theta = self._apply_global_transform(self.factors, theta_vector)\n",
    "            \n",
    "            try:\n",
    "                theta_var = self._estimate_theta_aware_var(F_theta, theta_vector, 'GLOBAL')\n",
    "                \n",
    "                Y_reconstructed = F_theta.values @ self.loadings.values.T\n",
    "                errors = self.data_standardized.values - Y_reconstructed\n",
    "                \n",
    "                # Ensemble error metrics\n",
    "                mse_error = np.mean(errors**2)\n",
    "                mae_error = np.mean(np.abs(errors))\n",
    "                huber_error = np.mean(np.where(np.abs(errors) < 1, 0.5 * errors**2, np.abs(errors) - 0.5))\n",
    "                \n",
    "                # Cross-validation penalty\n",
    "                cv_penalty = self._calculate_cv_penalty(F_theta)\n",
    "                \n",
    "                # Weighted combination\n",
    "                ensemble_error = 0.5 * mse_error + 0.3 * mae_error + 0.1 * huber_error + 0.1 * cv_penalty\n",
    "                return ensemble_error\n",
    "            except:\n",
    "                return 1e10\n",
    "\n",
    "        bounds = [(0.1, 2.5) for _ in range(self.n_factors)] + [(-1.2, 1.2) for _ in range(self.n_factors)]\n",
    "\n",
    "        # Try multiple global optimization algorithms\n",
    "        best_result = None\n",
    "        best_objective = float('inf')\n",
    "        \n",
    "        try:\n",
    "            from scipy.optimize import differential_evolution, basinhopping, dual_annealing\n",
    "        except ImportError:\n",
    "            from scipy.optimize import differential_evolution\n",
    "            basinhopping = None\n",
    "            dual_annealing = None\n",
    "\n",
    "        algorithms = [\n",
    "            ('differential_evolution', lambda: differential_evolution(\n",
    "                global_objective, bounds, seed=42, maxiter=100, popsize=15))\n",
    "        ]\n",
    "        \n",
    "        if basinhopping is not None:\n",
    "            algorithms.append(('basinhopping', lambda: basinhopping(\n",
    "                global_objective, [1.0] * len(bounds), minimizer_kwargs={'bounds': bounds})))\n",
    "        \n",
    "        if dual_annealing is not None:\n",
    "            algorithms.append(('dual_annealing', lambda: dual_annealing(\n",
    "                global_objective, bounds, seed=42, maxiter=200)))\n",
    "        \n",
    "        for alg_name, alg_func in algorithms:\n",
    "            try:\n",
    "                print(f\"  Trying {alg_name}...\")\n",
    "                result = alg_func()\n",
    "                if result.success and result.fun < best_objective:\n",
    "                    best_result = result\n",
    "                    best_objective = result.fun\n",
    "                    print(f\"  {alg_name} succeeded with objective: {result.fun:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  {alg_name} failed: {e}\")\n",
    "                continue\n",
    "\n",
    "        if best_result:\n",
    "            return best_result.x, lambda factors, theta_params: self._apply_global_transform(factors, theta_params)\n",
    "        else:\n",
    "            # Fallback\n",
    "            default_params = [1.0] * self.n_factors + [0.1] * self.n_factors\n",
    "            return default_params, lambda factors, theta_params: self._apply_global_transform(factors, theta_params)\n",
    "\n",
    "    def _apply_global_transform(self, factors, theta_params):\n",
    "        \"\"\"Apply global transformation (adaptive nonlinear)\"\"\"\n",
    "        F_theta_df = factors.copy()\n",
    "        \n",
    "        for i, factor_name in enumerate(factors.columns):\n",
    "            theta1 = theta_params[i]\n",
    "            theta2 = theta_params[i + self.n_factors] if i + self.n_factors < len(theta_params) else 0.1\n",
    "            \n",
    "            # Adaptive transformation based on factor characteristics\n",
    "            factor_std = factors[factor_name].std()\n",
    "            \n",
    "            if factor_std > 1.0:  # High volatility factor\n",
    "                trend = self._extract_trend_linear(factors[factor_name])\n",
    "                deviation = factors[factor_name] - trend\n",
    "                F_theta_df[factor_name] = trend + theta1 * deviation + theta2 * np.sign(deviation) * (deviation ** 2)\n",
    "            else:  # Low volatility factor\n",
    "                F_theta_df[factor_name] = theta1 * factors[factor_name] + theta2 * factors[factor_name].shift(1).fillna(factors[factor_name].iloc[0])\n",
    "        \n",
    "        return F_theta_df\n",
    "\n",
    "    # ============================================================================\n",
    "    # HELPER METHODS FOR THETA STRATEGIES\n",
    "    # ============================================================================\n",
    "\n",
    "    def _calculate_var_stability_penalty(self, theta_var):\n",
    "        \"\"\"Calculate VAR stability penalty\"\"\"\n",
    "        try:\n",
    "            coeffs = theta_var['coefficients']\n",
    "            eigenvals = np.linalg.eigvals(coeffs)\n",
    "            max_eigenval = np.max(np.abs(eigenvals))\n",
    "            \n",
    "            if max_eigenval >= 1.0:\n",
    "                return 1000 * (max_eigenval - 0.99)**2  # Heavy penalty for instability\n",
    "            else:\n",
    "                return 0.0\n",
    "        except:\n",
    "            return 1000.0\n",
    "\n",
    "    def _calculate_dsge_constraint_penalty(self, theta_params):\n",
    "        \"\"\"Calculate penalty for violating DSGE constraints\"\"\"\n",
    "        if self.dsge_priors is None:\n",
    "            return 0.0\n",
    "        \n",
    "        penalty = 0.0\n",
    "        \n",
    "        # Check if theta parameters are consistent with DSGE persistence\n",
    "        for i in range(min(len(theta_params), self.n_factors)):\n",
    "            theta_val = theta_params[i]\n",
    "            \n",
    "            # Demand factor should have high persistence (close to 1)\n",
    "            if i == 0 and self.dsge_priors.get('rho_a'):\n",
    "                target_persistence = self.dsge_priors['rho_a']['mean']\n",
    "                penalty += 10 * (theta_val - target_persistence)**2\n",
    "            \n",
    "            # Supply factor should reflect price stickiness\n",
    "            elif i == 1 and self.dsge_priors.get('theta'):\n",
    "                target_stickiness = self.dsge_priors['theta']['mean']\n",
    "                penalty += 10 * (theta_val - target_stickiness)**2\n",
    "        \n",
    "        return penalty\n",
    "\n",
    "    def _calculate_cv_penalty(self, F_theta):\n",
    "        \"\"\"Calculate cross-validation penalty\"\"\"\n",
    "        try:\n",
    "            n_splits = min(3, self.T_obs // 10)\n",
    "            cv_errors = []\n",
    "            \n",
    "            for i in range(n_splits):\n",
    "                split_point = int((i + 1) * self.T_obs / (n_splits + 1))\n",
    "                train_data = F_theta.iloc[:split_point]\n",
    "                test_data = F_theta.iloc[split_point:split_point + 4]\n",
    "                \n",
    "                if len(test_data) < 2:\n",
    "                    continue\n",
    "                \n",
    "                # Simple VAR forecast\n",
    "                try:\n",
    "                    from sklearn.linear_model import LinearRegression\n",
    "                    if len(train_data) > 2:\n",
    "                        X_train = train_data.values[:-1]\n",
    "                        y_train = train_data.values[1:]\n",
    "                        \n",
    "                        reg = LinearRegression().fit(X_train, y_train)\n",
    "                        \n",
    "                        X_test = test_data.values[:-1]\n",
    "                        y_test = test_data.values[1:]\n",
    "                        y_pred = reg.predict(X_test)\n",
    "                        \n",
    "                        cv_error = np.mean((y_test - y_pred)**2)\n",
    "                        cv_errors.append(cv_error)\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            return np.mean(cv_errors) if cv_errors else 0.0\n",
    "        except:\n",
    "            return 0.0\n",
    "\n",
    "    def _get_dsge_informed_bounds(self):\n",
    "        \"\"\"Get DSGE-informed parameter bounds\"\"\"\n",
    "        bounds = []\n",
    "        \n",
    "        if self.dsge_priors:\n",
    "            for i in range(self.n_factors):\n",
    "                if i == 0:  # Demand factor\n",
    "                    rho_a = self.dsge_priors.get('rho_a', {'mean': 0.8, 'std': 0.1})\n",
    "                    bounds.append((max(0.1, rho_a['mean'] - 2*rho_a['std']), \n",
    "                                 min(1.5, rho_a['mean'] + 2*rho_a['std'])))\n",
    "                elif i == 1:  # Supply factor\n",
    "                    theta_dsge = self.dsge_priors.get('theta', {'mean': 0.75, 'std': 0.1})\n",
    "                    bounds.append((max(0.1, theta_dsge['mean'] - 2*theta_dsge['std']), \n",
    "                                 min(1.5, theta_dsge['mean'] + 2*theta_dsge['std'])))\n",
    "                else:  # Other factors\n",
    "                    bounds.append((0.5, 1.5))\n",
    "            \n",
    "            # Second parameter bounds (interaction terms)\n",
    "            for i in range(self.n_factors):\n",
    "                bounds.append((-0.5, 0.5))\n",
    "        else:\n",
    "            bounds = [(0.5, 1.5) for _ in range(self.n_factors)] + [(-0.5, 0.5) for _ in range(self.n_factors)]\n",
    "        \n",
    "        return bounds\n",
    "\n",
    "    def _get_dsge_informed_initial_guess(self):\n",
    "        \"\"\"Get DSGE-informed initial parameter guess\"\"\"\n",
    "        initial_guess = []\n",
    "        \n",
    "        if self.dsge_priors:\n",
    "            for i in range(self.n_factors):\n",
    "                if i == 0:  # Demand factor\n",
    "                    rho_a = self.dsge_priors.get('rho_a', {'mean': 0.8})\n",
    "                    initial_guess.append(rho_a['mean'])\n",
    "                elif i == 1:  # Supply factor\n",
    "                    theta_dsge = self.dsge_priors.get('theta', {'mean': 0.75})\n",
    "                    initial_guess.append(theta_dsge['mean'])\n",
    "                else:  # Other factors\n",
    "                    initial_guess.append(1.0)\n",
    "            \n",
    "            # Second parameter initial values\n",
    "            for i in range(self.n_factors):\n",
    "                initial_guess.append(0.1)\n",
    "        else:\n",
    "            initial_guess = [1.0] * self.n_factors + [0.1] * self.n_factors\n",
    "        \n",
    "        return initial_guess\n",
    "\n",
    "    def _hp_filter(self, series, lamb=1600):\n",
    "        \"\"\"Hodrick-Prescott filter\"\"\"\n",
    "        n = len(series)\n",
    "        I = np.eye(n)\n",
    "        D2 = np.diff(np.eye(n), 2, axis=0)\n",
    "        trend = np.linalg.solve(I + lamb * D2.T @ D2, series.values)\n",
    "        cycle = series.values - trend\n",
    "        return pd.Series(trend, index=series.index), pd.Series(cycle, index=series.index)\n",
    "\n",
    "    def _extract_trend_linear(self, series):\n",
    "        \"\"\"Extract linear trend\"\"\"\n",
    "        n = len(series)\n",
    "        x = np.arange(n)\n",
    "        X = np.column_stack([np.ones(n), x])\n",
    "        coeffs = np.linalg.lstsq(X, series.values, rcond=None)[0]\n",
    "        return pd.Series(coeffs[0] + coeffs[1] * x, index=series.index)\n",
    "\n",
    "    # ============================================================================\n",
    "    # VAR ESTIMATION METHODS (DSGE-INFORMED)\n",
    "    # ============================================================================\n",
    "\n",
    "    def _adapt_dsge_priors_to_theta(self, transformed_factors, theta_params, method_name):\n",
    "        \"\"\"Adapt DSGE priors to transformed factor space while preserving economic structure\"\"\"\n",
    "        if self.dsge_priors is None:\n",
    "            return None\n",
    "            \n",
    "        # Get original prior structure\n",
    "        base_priors = self.base_factor_var.get('prior_info')\n",
    "        if base_priors is None:\n",
    "            return self._construct_priors_from_dsge_estimates(transformed_factors, theta_params)\n",
    "            \n",
    "        # Calculate transformation scaling factors for each factor\n",
    "        original_factors = self.factors.values\n",
    "        theta_factors = transformed_factors.values if hasattr(transformed_factors, 'values') else transformed_factors\n",
    "        \n",
    "        scaling_factors = []\n",
    "        for i in range(self.n_factors):\n",
    "            orig_std = np.std(original_factors[:, i])\n",
    "            theta_std = np.std(theta_factors[:, i])\n",
    "            if orig_std > 0:\n",
    "                scaling_factors.append(theta_std / orig_std)\n",
    "            else:\n",
    "                scaling_factors.append(1.0)\n",
    "        \n",
    "        # Adapt prior means and variances\n",
    "        adapted_prior_mean = base_priors['mean'].copy()\n",
    "        adapted_prior_var = base_priors['variance'].copy()\n",
    "        \n",
    "        # Adjust VAR coefficient priors based on transformation scaling\n",
    "        K = self.n_factors\n",
    "        lags = self.base_factor_var['lags']\n",
    "        \n",
    "        # Skip constants, adjust VAR coefficients\n",
    "        coeff_start = K\n",
    "        for lag in range(1, lags + 1):\n",
    "            for i in range(K):  # Each factor equation\n",
    "                for j in range(K):  # Each factor lag\n",
    "                    coeff_idx = coeff_start + (lag-1)*K*K + i*K + j\n",
    "                    if coeff_idx < len(adapted_prior_mean):\n",
    "                        # Scale coefficient priors by transformation ratios\n",
    "                        scale_ratio = scaling_factors[i] / scaling_factors[j]\n",
    "                        adapted_prior_mean[coeff_idx] *= scale_ratio\n",
    "                        # Increase uncertainty for transformed relationships\n",
    "                        adapted_prior_var[coeff_idx] *= (1.0 + 0.1 * abs(1 - scale_ratio))\n",
    "        \n",
    "        return {\n",
    "            'mean': adapted_prior_mean,\n",
    "            'variance': adapted_prior_var,\n",
    "            'dsge_params': base_priors.get('dsge_params', {}),\n",
    "            'scaling_factors': scaling_factors\n",
    "        }\n",
    "\n",
    "    def _construct_priors_from_dsge_estimates(self, transformed_factors, theta_params):\n",
    "        \"\"\"Construct VAR priors directly from DSGE posterior estimates when prior_info unavailable\"\"\"\n",
    "        if self.dsge_priors is None:\n",
    "            return None\n",
    "            \n",
    "        K = self.n_factors\n",
    "        lags = self.base_factor_var['lags']\n",
    "        n_coeffs = K * K * lags + K  # VAR coeffs + constants\n",
    "        \n",
    "        # Extract key DSGE parameters (using posterior means)\n",
    "        dsge_params = {}\n",
    "        for param_name in ['sigma', 'theta', 'phi_pi', 'phi_y', 'rho_a', 'rho_v']:\n",
    "            if param_name in self.dsge_priors:\n",
    "                dsge_params[param_name] = self.dsge_priors[param_name]['mean']\n",
    "        \n",
    "        # Construct theory-consistent priors\n",
    "        prior_mean = np.zeros(n_coeffs)\n",
    "        prior_var = np.ones(n_coeffs)\n",
    "        \n",
    "        # Constants (intercepts) - weakly informative\n",
    "        prior_var[:K] = 1.0\n",
    "        \n",
    "        # VAR coefficient priors based on DSGE structure\n",
    "        coeff_start = K\n",
    "        \n",
    "        for lag in range(1, lags + 1):\n",
    "            for i in range(K):  # Each factor equation\n",
    "                for j in range(K):  # Each factor lag\n",
    "                    coeff_idx = coeff_start + (lag-1)*K*K + i*K + j\n",
    "                    \n",
    "                    if coeff_idx >= n_coeffs:\n",
    "                        continue\n",
    "                        \n",
    "                    if i == j:  # Own lags\n",
    "                        if lag == 1:\n",
    "                            # First own lag - use DSGE persistence parameters\n",
    "                            if i == 0:  # Demand factor - related to output persistence\n",
    "                                prior_mean[coeff_idx] = dsge_params.get('rho_a', 0.5) * 0.7\n",
    "                                prior_var[coeff_idx] = 0.1\n",
    "                            elif i == 1:  # Supply factor - related to price stickiness\n",
    "                                stickiness = dsge_params.get('theta', 0.7)\n",
    "                                prior_mean[coeff_idx] = min(0.9, stickiness * 1.2)\n",
    "                                prior_var[coeff_idx] = 0.1\n",
    "                            else:  # Monetary factor - use monetary persistence\n",
    "                                prior_mean[coeff_idx] = dsge_params.get('rho_v', 0.3)\n",
    "                                prior_var[coeff_idx] = 0.15\n",
    "                        else:\n",
    "                            # Higher order own lags - decay\n",
    "                            first_lag_idx = coeff_start + (i*K + j)\n",
    "                            if first_lag_idx < len(prior_mean):\n",
    "                                prior_mean[coeff_idx] = prior_mean[first_lag_idx] * 0.5\n",
    "                            prior_var[coeff_idx] = 0.2\n",
    "                    else:  # Cross-lags\n",
    "                        if lag == 1:\n",
    "                            # Theory-based cross-effects\n",
    "                            if (i == 0 and j == 2):  # Monetary -> Demand (IS curve)\n",
    "                                prior_mean[coeff_idx] = -1.0 / dsge_params.get('sigma', 1.0) * 0.1\n",
    "                                prior_var[coeff_idx] = 0.05\n",
    "                            elif (i == 1 and j == 0):  # Demand -> Supply (Phillips curve)  \n",
    "                                prior_mean[coeff_idx] = dsge_params.get('phi_y', 0.5) * 0.2\n",
    "                                prior_var[coeff_idx] = 0.05\n",
    "                            elif (i == 2 and j == 1):  # Supply -> Monetary (Taylor rule)\n",
    "                                prior_mean[coeff_idx] = dsge_params.get('phi_pi', 1.5) * 0.1\n",
    "                                prior_var[coeff_idx] = 0.05\n",
    "                            else:\n",
    "                                prior_mean[coeff_idx] = 0.0\n",
    "                                prior_var[coeff_idx] = 0.1\n",
    "                        else:\n",
    "                            # Higher order cross-lags - shrink to zero\n",
    "                            prior_mean[coeff_idx] = 0.0\n",
    "                            prior_var[coeff_idx] = 0.1 / lag\n",
    "        \n",
    "        return {\n",
    "            'mean': prior_mean,\n",
    "            'variance': prior_var,\n",
    "            'dsge_params': dsge_params\n",
    "        }\n",
    "\n",
    "    def _estimate_theta_aware_var(self, transformed_factors, theta_params, method_name):\n",
    "        \"\"\"Estimate VAR on transformed factors using adapted DSGE priors\"\"\"\n",
    "        F_theta = transformed_factors.values if hasattr(transformed_factors, 'values') else transformed_factors\n",
    "        \n",
    "        # Get adapted DSGE priors\n",
    "        adapted_priors = self._adapt_dsge_priors_to_theta(transformed_factors, theta_params, method_name)\n",
    "        \n",
    "        if adapted_priors is not None and self.dsge_priors is not None:\n",
    "            # Bayesian estimation with adapted priors\n",
    "            return self._estimate_bayesian_var_theta(F_theta, adapted_priors)\n",
    "        else:\n",
    "            # OLS fallback\n",
    "            return self._estimate_var_ols(F_theta, self.base_factor_var['lags'])\n",
    "\n",
    "    def _estimate_bayesian_var_theta(self, F_theta, adapted_priors):\n",
    "        \"\"\"Bayesian VAR estimation for theta-transformed factors with adapted DSGE priors\"\"\"\n",
    "        T, K = F_theta.shape\n",
    "        lags = self.base_factor_var['lags']\n",
    "        \n",
    "        # Construct regression matrices\n",
    "        Y = F_theta[lags:, :]\n",
    "        T_eff = Y.shape[0]\n",
    "        \n",
    "        # Design matrix\n",
    "        X = np.ones((T_eff, 1))  # Constant\n",
    "        for lag in range(1, lags + 1):\n",
    "            X = np.hstack([X, F_theta[lags-lag:-lag, :]])\n",
    "        \n",
    "        n_regressors = X.shape[1]\n",
    "        \n",
    "        # Prior parameters (adapted)\n",
    "        beta_prior = adapted_priors['mean'][:n_regressors*K].reshape(-1, 1)\n",
    "        V_prior = np.diag(adapted_priors['variance'][:n_regressors*K])\n",
    "        \n",
    "        # Bayesian updating\n",
    "        V_prior_inv = np.linalg.inv(V_prior)\n",
    "        XtX = X.T @ X\n",
    "        \n",
    "        # Posterior covariance and mean\n",
    "        V_posterior_inv = V_prior_inv + np.kron(np.eye(K), XtX)\n",
    "        V_posterior = np.linalg.inv(V_posterior_inv)\n",
    "        \n",
    "        XtY = X.T @ Y\n",
    "        beta_posterior_vec = V_posterior @ (V_prior_inv @ beta_prior + XtY.flatten('F').reshape(-1, 1))\n",
    "        beta_posterior = beta_posterior_vec.reshape((n_regressors, K), order='F')\n",
    "        \n",
    "        # Residuals and covariance\n",
    "        Y_fitted = X @ beta_posterior\n",
    "        residuals = Y - Y_fitted\n",
    "        sigma_u = (residuals.T @ residuals) / T_eff\n",
    "        \n",
    "        # Coefficient matrices\n",
    "        const = beta_posterior[0, :]\n",
    "        var_coeffs = beta_posterior[1:, :].T\n",
    "        \n",
    "        # Model statistics\n",
    "        log_likelihood = self._compute_log_likelihood(residuals, sigma_u)\n",
    "        \n",
    "        return {\n",
    "            'coefficients': var_coeffs,\n",
    "            'constant': const,\n",
    "            'sigma_u': sigma_u,\n",
    "            'residuals': residuals,\n",
    "            'log_likelihood': log_likelihood,\n",
    "            'lags': lags,\n",
    "            'T_eff': T_eff,\n",
    "            'bayesian': True,\n",
    "            'adapted_priors': adapted_priors,\n",
    "            'theta_informed': True\n",
    "        }\n",
    "\n",
    "    def _estimate_var_ols(self, F_theta, lags):\n",
    "        \"\"\"OLS VAR estimation fallback\"\"\"\n",
    "        T, K = F_theta.shape\n",
    "        \n",
    "        # Construct regression matrices\n",
    "        Y = F_theta[lags:, :]\n",
    "        T_eff = Y.shape[0]\n",
    "        \n",
    "        X = np.ones((T_eff, 1))\n",
    "        for lag in range(1, lags + 1):\n",
    "            X = np.hstack([X, F_theta[lags-lag:-lag, :]])\n",
    "        \n",
    "        # OLS estimation\n",
    "        XtX_inv = np.linalg.inv(X.T @ X)\n",
    "        beta = XtX_inv @ X.T @ Y\n",
    "        \n",
    "        u = Y - X @ beta\n",
    "        sigma_u = (u.T @ u) / T_eff\n",
    "        \n",
    "        const = beta[0, :]\n",
    "        var_coeffs = beta[1:, :].T\n",
    "        \n",
    "        log_likelihood = self._compute_log_likelihood(u, sigma_u)\n",
    "        \n",
    "        return {\n",
    "            'coefficients': var_coeffs,\n",
    "            'constant': const,\n",
    "            'sigma_u': sigma_u,\n",
    "            'residuals': u,\n",
    "            'log_likelihood': log_likelihood,\n",
    "            'lags': lags,\n",
    "            'T_eff': T_eff,\n",
    "            'bayesian': False,\n",
    "            'theta_informed': True\n",
    "        }\n",
    "\n",
    "    def _compute_log_likelihood(self, residuals, sigma_u):\n",
    "        \"\"\"Compute VAR log-likelihood\"\"\"\n",
    "        T, K = residuals.shape\n",
    "        log_likelihood = -0.5 * T * K * np.log(2 * np.pi)\n",
    "        log_likelihood -= 0.5 * T * np.log(np.linalg.det(sigma_u))\n",
    "        log_likelihood -= 0.5 * np.trace(residuals.T @ residuals @ np.linalg.inv(sigma_u))\n",
    "        return log_likelihood\n",
    "\n",
    "    # ============================================================================\n",
    "    # EVALUATION METHODS\n",
    "    # ============================================================================\n",
    "\n",
    "    def detailed_variable_cv_analysis(self, method_name, theta_params, theta_func):\n",
    "        \"\"\"Detailed cross-validation analysis at the variable level\"\"\"\n",
    "        variable_cv_results = {}\n",
    "        \n",
    "        for train_idx, test_idx in self.tscv.split(self.factors):\n",
    "            if len(test_idx) < 2:\n",
    "                continue\n",
    "                \n",
    "            # Split data maintaining temporal structure\n",
    "            factors_train = self.factors.iloc[train_idx]\n",
    "            factors_test = self.factors.iloc[test_idx]\n",
    "            data_train = self.data_standardized.iloc[train_idx]\n",
    "            data_test = self.data_standardized.iloc[test_idx]\n",
    "            \n",
    "            try:\n",
    "                # Apply theta transformation to training factors\n",
    "                F_theta_train = theta_func(factors_train, theta_params)\n",
    "                F_theta_test = theta_func(factors_test, theta_params)\n",
    "                \n",
    "                # Estimate theta-aware VAR on training data\n",
    "                theta_var_cv = self._estimate_theta_aware_var(F_theta_train, theta_params, method_name)\n",
    "                \n",
    "                # Generate forecasts\n",
    "                test_forecasts = self._forecast_theta_var(F_theta_test, theta_var_cv, len(test_idx))\n",
    "                F_theta_forecast = test_forecasts['mean'].values\n",
    "                \n",
    "                # Use original loadings for variable forecasts\n",
    "                X_pred = F_theta_forecast @ self.loadings.values.T\n",
    "                \n",
    "                # Calculate metrics for each variable\n",
    "                for i, var_name in enumerate(self.data_standardized.columns):\n",
    "                    if var_name not in variable_cv_results:\n",
    "                        variable_cv_results[var_name] = {\n",
    "                            'RMSE': [], 'MAE': [], 'MAPE': [], 'SMAPE': [], \n",
    "                            'Theil_U1': [], 'Theil_U2': [], 'MdAPE': [], 'MASE': [], 'R2': []\n",
    "                        }\n",
    "                    \n",
    "                    y_true_var = data_test.values[:, i]\n",
    "                    y_pred_var = X_pred[:, i]\n",
    "                    \n",
    "                    # Skip if either contains NaN/Inf\n",
    "                    if np.isnan(y_true_var).any() or np.isnan(y_pred_var).any():\n",
    "                        continue\n",
    "                    if np.isinf(y_true_var).any() or np.isinf(y_pred_var).any():\n",
    "                        continue\n",
    "                    \n",
    "                    # Calculate all metrics\n",
    "                    metrics = self._calculate_comprehensive_metrics(y_true_var, y_pred_var, data_train.values[:, i])\n",
    "                    \n",
    "                    for metric_name, value in metrics.items():\n",
    "                        if not (np.isnan(value) or np.isinf(value)):\n",
    "                            variable_cv_results[var_name][metric_name].append(value)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"CV fold failed for {method_name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Average across folds\n",
    "        averaged_results = {}\n",
    "        for var_name, metrics in variable_cv_results.items():\n",
    "            averaged_results[var_name] = {}\n",
    "            for metric_name, values in metrics.items():\n",
    "                if values:\n",
    "                    averaged_results[var_name][metric_name] = np.mean(values)\n",
    "                else:\n",
    "                    averaged_results[var_name][metric_name] = np.nan\n",
    "        \n",
    "        return averaged_results\n",
    "    \n",
    "    def _calculate_comprehensive_metrics(self, y_true, y_pred, y_train):\n",
    "        \"\"\"Calculate comprehensive forecast accuracy metrics\"\"\"\n",
    "        epsilon = 1e-8\n",
    "        \n",
    "        # Basic metrics\n",
    "        rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "        mae = np.mean(np.abs(y_true - y_pred))\n",
    "        \n",
    "        # MAPE\n",
    "        mape = np.mean(np.abs((y_true - y_pred) / np.maximum(np.abs(y_true), epsilon))) * 100\n",
    "        \n",
    "        # SMAPE\n",
    "        smape = np.mean(2 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred) + epsilon)) * 100\n",
    "        \n",
    "        # Theil's U1\n",
    "        numerator = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "        denominator = np.sqrt(np.mean(y_true**2)) + np.sqrt(np.mean(y_pred**2))\n",
    "        theil_u1 = numerator / (denominator + epsilon)\n",
    "        \n",
    "        # Theil's U2\n",
    "        naive_forecast = np.full_like(y_true, y_true[0] if len(y_true) > 0 else 0)\n",
    "        theil_u2 = rmse / (np.sqrt(np.mean((y_true - naive_forecast)**2)) + epsilon)\n",
    "        \n",
    "        # MdAPE (Median Absolute Percentage Error)\n",
    "        mdape = np.median(np.abs((y_true - y_pred) / np.maximum(np.abs(y_true), epsilon))) * 100\n",
    "        \n",
    "        # MASE (Mean Absolute Scaled Error)\n",
    "        if len(y_train) > 1:\n",
    "            seasonal_naive_mae = np.mean(np.abs(np.diff(y_train)))\n",
    "            mase = mae / (seasonal_naive_mae + epsilon)\n",
    "        else:\n",
    "            mase = np.nan\n",
    "        \n",
    "        # R-squared\n",
    "        ss_res = np.sum((y_true - y_pred)**2)\n",
    "        ss_tot = np.sum((y_true - np.mean(y_true))**2)\n",
    "        r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'SMAPE': smape,\n",
    "            'Theil_U1': theil_u1, 'Theil_U2': theil_u2, 'MdAPE': mdape, \n",
    "            'MASE': mase, 'R2': r2\n",
    "        }\n",
    "\n",
    "    def evaluate_theta_method(self, method_name, theta_params, theta_func, horizon=8):\n",
    "        \"\"\"Evaluate theta method using DSGE-consistent approach\"\"\"\n",
    "        print(f\"Evaluating {method_name} with DSGE consistency...\")\n",
    "        \n",
    "        # Apply theta transformation\n",
    "        F_theta = theta_func(self.factors, theta_params)\n",
    "        \n",
    "        # Estimate theta-aware VAR with adapted DSGE priors\n",
    "        theta_var_model = self._estimate_theta_aware_var(F_theta, theta_params, method_name)\n",
    "        \n",
    "        # Calculate fit using ORIGINAL loadings (preserve economic structure)\n",
    "        Lambda_original = self.loadings.values  # N x K (PRESERVE)\n",
    "        Y_fitted = F_theta.values @ Lambda_original.T\n",
    "        residuals = self.data_standardized.values - Y_fitted\n",
    "        \n",
    "        # Variable R-squared with original loadings\n",
    "        variable_r2 = {}\n",
    "        for i, var_name in enumerate(self.data_standardized.columns):\n",
    "            ss_res = np.sum(residuals[:, i]**2)\n",
    "            ss_tot = np.sum((self.data_standardized.values[:, i] - \n",
    "                        np.mean(self.data_standardized.values[:, i]))**2)\n",
    "            r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "            variable_r2[var_name] = max(0, r2)\n",
    "        \n",
    "        # Generate forecasts using theta-aware VAR\n",
    "        theta_factor_forecasts = self._forecast_theta_var(F_theta, theta_var_model, horizon)\n",
    "        \n",
    "        # Variable forecasts using ORIGINAL loadings\n",
    "        F_theta_forecast = theta_factor_forecasts['mean'].values\n",
    "        X_forecast_std = F_theta_forecast @ Lambda_original.T\n",
    "        \n",
    "        # Transform back to original scale\n",
    "        X_forecast_original = self.scaler.inverse_transform(X_forecast_std)\n",
    "        \n",
    "        # Create forecast DataFrame\n",
    "        forecast_dates = pd.date_range(\n",
    "            start=self.factors.index[-1] + pd.DateOffset(months=3),\n",
    "            periods=horizon, freq='Q'\n",
    "        )\n",
    "        \n",
    "        variable_forecasts = pd.DataFrame(\n",
    "            X_forecast_original,\n",
    "            index=forecast_dates,\n",
    "            columns=self.combined_data.columns\n",
    "        )\n",
    "        \n",
    "        # Cross-validation metrics (DSGE-aware)\n",
    "        cv_metrics = self._cross_validate_dsge_theta_method(method_name, theta_func, theta_params)\n",
    "        \n",
    "        # Detailed variable-level CV analysis\n",
    "        variable_cv_metrics = self.detailed_variable_cv_analysis(method_name, theta_params, theta_func)\n",
    "        \n",
    "        return {\n",
    "            'theta_var_model': theta_var_model,\n",
    "            'variable_r2': variable_r2,\n",
    "            'forecasts': variable_forecasts,\n",
    "            'factor_forecasts': theta_factor_forecasts,\n",
    "            'cv_metrics': cv_metrics,\n",
    "            'variable_cv_metrics': variable_cv_metrics,\n",
    "            'theta_params': theta_params,\n",
    "            'theta_func': theta_func,\n",
    "            'preserved_loadings': True,\n",
    "            'dsge_informed': self.dsge_priors is not None\n",
    "        }\n",
    "\n",
    "    def _forecast_theta_var(self, F_theta, theta_var_model, horizon):\n",
    "        \"\"\"Generate forecasts using theta-aware VAR model\"\"\"\n",
    "        Phi = theta_var_model['coefficients']\n",
    "        c = theta_var_model['constant']\n",
    "        p = theta_var_model['lags']\n",
    "        K = Phi.shape[0]\n",
    "\n",
    "        forecasts = np.zeros((horizon, K))\n",
    "\n",
    "        if p == 1:\n",
    "            F_last = F_theta.values[-1, :]\n",
    "            for h in range(horizon):\n",
    "                if h == 0:\n",
    "                    forecasts[h, :] = c + Phi @ F_last\n",
    "                else:\n",
    "                    forecasts[h, :] = c + Phi @ forecasts[h-1, :]\n",
    "        else:\n",
    "            F_history = F_theta.values[-p:, :].copy()\n",
    "            for h in range(horizon):\n",
    "                F_lagged = F_history.flatten('F')\n",
    "                F_forecast = c + Phi @ F_lagged\n",
    "                forecasts[h, :] = F_forecast\n",
    "                F_history = np.vstack([F_history[1:, :], F_forecast.reshape(1, -1)])\n",
    "\n",
    "        forecast_dates = pd.date_range(\n",
    "            start=self.factors.index[-1] + pd.DateOffset(months=3),\n",
    "            periods=horizon, freq='Q'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'mean': pd.DataFrame(forecasts, index=forecast_dates, columns=self.factors.columns)\n",
    "        }\n",
    "\n",
    "    def _cross_validate_dsge_theta_method(self, method_name, theta_func, theta_params):\n",
    "        \"\"\"Cross-validate theta method preserving DSGE structure throughout\"\"\"\n",
    "        cv_metrics = []\n",
    "        \n",
    "        for train_idx, test_idx in self.tscv.split(self.factors):\n",
    "            if len(test_idx) < 2:\n",
    "                continue\n",
    "                \n",
    "            # Split data maintaining temporal structure\n",
    "            factors_train = self.factors.iloc[train_idx]\n",
    "            factors_test = self.factors.iloc[test_idx]\n",
    "            data_train = self.data_standardized.iloc[train_idx]\n",
    "            data_test = self.data_standardized.iloc[test_idx]\n",
    "            \n",
    "            try:\n",
    "                # Apply theta transformation to training factors\n",
    "                F_theta_train = theta_func(factors_train, theta_params)\n",
    "                F_theta_test = theta_func(factors_test, theta_params)\n",
    "                \n",
    "                # Check for valid data\n",
    "                if F_theta_train.isna().all().any() or F_theta_test.isna().all().any():\n",
    "                    print(f\"Warning: NaN values detected in CV fold for {method_name}\")\n",
    "                    continue\n",
    "                \n",
    "                # Estimate theta-aware VAR on training data with DSGE priors\n",
    "                theta_var_cv = self._estimate_theta_aware_var(F_theta_train, theta_params, method_name)\n",
    "                \n",
    "                # Generate forecasts using theta VAR\n",
    "                test_forecasts = self._forecast_theta_var(F_theta_test, theta_var_cv, len(test_idx))\n",
    "                F_theta_forecast = test_forecasts['mean'].values\n",
    "                \n",
    "                # Check for valid forecasts\n",
    "                if np.isnan(F_theta_forecast).any():\n",
    "                    print(f\"Warning: NaN forecasts detected in CV fold for {method_name}\")\n",
    "                    continue\n",
    "                \n",
    "                # Use ORIGINAL loadings for variable forecasts (preserve structure)\n",
    "                X_pred = F_theta_forecast @ self.loadings.values.T\n",
    "                \n",
    "                # Calculate metrics\n",
    "                metrics = self._calculate_forecast_metrics(data_test.values, X_pred)\n",
    "                cv_metrics.append(metrics)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"CV fold failed for {method_name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if cv_metrics:\n",
    "            # Average across folds\n",
    "            avg_metrics = {}\n",
    "            for metric in cv_metrics[0].keys():\n",
    "                values = [fold[metric] for fold in cv_metrics if not np.isnan(fold[metric])]\n",
    "                avg_metrics[metric] = np.mean(values) if values else np.nan\n",
    "            return avg_metrics\n",
    "        \n",
    "        return {'RMSE': np.nan, 'MAE': np.nan, 'MAPE': np.nan, 'R2': np.nan}\n",
    "\n",
    "    def _calculate_forecast_metrics(self, y_true, y_pred):\n",
    "        \"\"\"Calculate forecast accuracy metrics\"\"\"\n",
    "        y_true_flat = y_true.flatten()\n",
    "        y_pred_flat = y_pred.flatten()\n",
    "        \n",
    "        mask = ~(np.isnan(y_true_flat) | np.isnan(y_pred_flat))\n",
    "        y_true_clean = y_true_flat[mask]\n",
    "        y_pred_clean = y_pred_flat[mask]\n",
    "        \n",
    "        if len(y_true_clean) == 0:\n",
    "            return {'RMSE': np.nan, 'MAE': np.nan, 'MAPE': np.nan, 'R2': np.nan}\n",
    "        \n",
    "        # Basic metrics\n",
    "        rmse = np.sqrt(np.mean((y_true_clean - y_pred_clean)**2))\n",
    "        mae = np.mean(np.abs(y_true_clean - y_pred_clean))\n",
    "        \n",
    "        # MAPE\n",
    "        epsilon = 1e-8\n",
    "        mape = np.mean(np.abs((y_true_clean - y_pred_clean) / \n",
    "                            np.maximum(np.abs(y_true_clean), epsilon))) * 100\n",
    "        \n",
    "        # R-squared\n",
    "        ss_res = np.sum((y_true_clean - y_pred_clean)**2)\n",
    "        ss_tot = np.sum((y_true_clean - np.mean(y_true_clean))**2)\n",
    "        r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "        \n",
    "        return {'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2}\n",
    "\n",
    "    # ============================================================================\n",
    "    # MAIN EXECUTION METHODS - UPDATED TO USE FIVE STRATEGIES\n",
    "    # ============================================================================\n",
    "\n",
    "    def run_five_theta_strategies_comparison(self, horizon=8):\n",
    "        \"\"\"Run the five core theta strategies and compare results\"\"\"\n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(\"FIVE CORE THETA STRATEGIES COMPARISON\")\n",
    "        print(\"=\"*100)\n",
    "        print(f\"Using {'Bayesian' if self.dsge_priors else 'OLS'} VAR with DSGE structure preservation\")\n",
    "\n",
    "        # THE FIVE CORE STRATEGIES\n",
    "        strategies = {\n",
    "            'FREQUENCY_DUAL': self.frequency_dual_theta_strategy,\n",
    "            'LAGGED': self.lagged_theta_strategy, \n",
    "            'SEQUENTIAL': self.sequential_theta_strategy,\n",
    "            'CONSTRAINED': self.constrained_theta_strategy,\n",
    "            'GLOBAL': self.global_theta_strategy,\n",
    "        }\n",
    "\n",
    "        all_results = {}\n",
    "\n",
    "        for strategy_name, strategy_func in strategies.items():\n",
    "            print(f\"\\n--- {strategy_name} Strategy ---\")\n",
    "            try:\n",
    "                # Get optimal parameters and transformation function\n",
    "                theta_params, theta_func = strategy_func()\n",
    "                \n",
    "                # Evaluate method with DSGE consistency\n",
    "                results = self.evaluate_theta_method(strategy_name, theta_params, theta_func, horizon)\n",
    "                all_results[strategy_name] = results\n",
    "                \n",
    "                # Print summary\n",
    "                avg_r2 = np.mean(list(results['variable_r2'].values()))\n",
    "                cv_rmse = results['cv_metrics']['RMSE']\n",
    "                dsge_informed = \"Yes\" if results['dsge_informed'] else \"No\"\n",
    "                print(f\"Average R¬≤: {avg_r2:.3f}\")\n",
    "                print(f\"CV RMSE: {cv_rmse:.4f}\")\n",
    "                print(f\"DSGE-Informed: {dsge_informed}\")\n",
    "                print(f\"Original Loadings Preserved: {results['preserved_loadings']}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Strategy {strategy_name} failed: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        return all_results\n",
    "\n",
    "    def select_best_strategy(self, all_results, selection_criteria=None):\n",
    "        \"\"\"Select best strategy based on comprehensive forecasting and fit metrics\"\"\"\n",
    "        if not all_results:\n",
    "            print(\"No results available for selection\")\n",
    "            return None, None\n",
    "            \n",
    "        if selection_criteria is None:\n",
    "            # Simplified weighting scheme - only 4 core metrics\n",
    "            selection_criteria = {\n",
    "                'cv_rmse_weight': 0.30,      # Increased weight\n",
    "                'mase_weight': 0.25,         # Substantial weight for MASE\n",
    "                'theil_u1_weight': 0.20,     # Increased weight\n",
    "                'theil_u2_weight': 0.20,     # Increased weight\n",
    "                'dsge_bonus': 0.05           # Keep DSGE bonus\n",
    "            }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"COMPREHENSIVE STRATEGY SELECTION\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        strategy_scores = {}\n",
    "        detailed_scores = {}\n",
    "        \n",
    "        for strategy_name, results in all_results.items():\n",
    "            if 'variable_cv_metrics' not in results:\n",
    "                print(f\"Skipping {strategy_name} - incomplete metrics\")\n",
    "                continue\n",
    "                \n",
    "            # Calculate component scores\n",
    "            cv_metrics = results['cv_metrics']\n",
    "            var_cv_metrics = results['variable_cv_metrics']\n",
    "            \n",
    "            # Aggregate variable-level metrics\n",
    "            all_rmse = [metrics.get('RMSE', np.nan) for metrics in var_cv_metrics.values()]\n",
    "            all_mase = [metrics.get('MASE', np.nan) for metrics in var_cv_metrics.values()]\n",
    "            all_theil_u1 = [metrics.get('Theil_U1', np.nan) for metrics in var_cv_metrics.values()]\n",
    "            all_theil_u2 = [metrics.get('Theil_U2', np.nan) for metrics in var_cv_metrics.values()]\n",
    "            \n",
    "            avg_var_rmse = np.nanmean(all_rmse)\n",
    "            avg_mase = np.nanmean(all_mase)\n",
    "            avg_theil_u1 = np.nanmean(all_theil_u1)\n",
    "            avg_theil_u2 = np.nanmean(all_theil_u2)\n",
    "            \n",
    "            # Overall fit\n",
    "            avg_r2 = np.mean(list(results['variable_r2'].values()))\n",
    "            \n",
    "            detailed_scores[strategy_name] = {\n",
    "            'avg_var_rmse': avg_var_rmse,\n",
    "            'avg_mase': avg_mase,\n",
    "            'avg_theil_u1': avg_theil_u1,\n",
    "            'avg_theil_u2': avg_theil_u2,\n",
    "            'dsge_informed': results.get('dsge_informed', False)\n",
    "        }\n",
    "        \n",
    "        # Normalize scores across strategies\n",
    "        metric_ranges = {}\n",
    "        for metric in ['avg_var_rmse', 'avg_mase', 'avg_theil_u1', 'avg_theil_u2']:\n",
    "            values = [scores[metric] for scores in detailed_scores.values() if not np.isnan(scores[metric])]\n",
    "            if values:\n",
    "                metric_ranges[metric] = {'min': min(values), 'max': max(values)}\n",
    "            else:\n",
    "                metric_ranges[metric] = {'min': 0, 'max': 1}\n",
    "        \n",
    "        # Calculate composite scores\n",
    "        for strategy_name, scores in detailed_scores.items():\n",
    "            composite_score = 0.0\n",
    "            \n",
    "            # RMSE component (lower is better)\n",
    "            if not np.isnan(scores['avg_var_rmse']) and metric_ranges['avg_var_rmse']['max'] > metric_ranges['avg_var_rmse']['min']:\n",
    "                rmse_normalized = 1 - (scores['avg_var_rmse'] - metric_ranges['avg_var_rmse']['min']) / (metric_ranges['avg_var_rmse']['max'] - metric_ranges['avg_var_rmse']['min'])\n",
    "                composite_score += selection_criteria['cv_rmse_weight'] * rmse_normalized\n",
    "            \n",
    "            # MASE component (lower is better)\n",
    "            if not np.isnan(scores['avg_mase']) and metric_ranges['avg_mase']['max'] > metric_ranges['avg_mase']['min']:\n",
    "                mase_normalized = 1 - (scores['avg_mase'] - metric_ranges['avg_mase']['min']) / (metric_ranges['avg_mase']['max'] - metric_ranges['avg_mase']['min'])\n",
    "                composite_score += selection_criteria['mase_weight'] * mase_normalized\n",
    "            \n",
    "            # Theil U1 component (lower is better)\n",
    "            if not np.isnan(scores['avg_theil_u1']) and metric_ranges['avg_theil_u1']['max'] > metric_ranges['avg_theil_u1']['min']:\n",
    "                theil_u1_normalized = 1 - (scores['avg_theil_u1'] - metric_ranges['avg_theil_u1']['min']) / (metric_ranges['avg_theil_u1']['max'] - metric_ranges['avg_theil_u1']['min'])\n",
    "                composite_score += selection_criteria['theil_u1_weight'] * theil_u1_normalized\n",
    "            \n",
    "            # Theil U2 component (lower is better)\n",
    "            if not np.isnan(scores['avg_theil_u2']) and metric_ranges['avg_theil_u2']['max'] > metric_ranges['avg_theil_u2']['min']:\n",
    "                theil_u2_normalized = 1 - (scores['avg_theil_u2'] - metric_ranges['avg_theil_u2']['min']) / (metric_ranges['avg_theil_u2']['max'] - metric_ranges['avg_theil_u2']['min'])\n",
    "                composite_score += selection_criteria['theil_u2_weight'] * theil_u2_normalized\n",
    "            \n",
    "            # DSGE bonus\n",
    "            if scores['dsge_informed']:\n",
    "                composite_score += selection_criteria['dsge_bonus']\n",
    "            \n",
    "            strategy_scores[strategy_name] = composite_score\n",
    "        \n",
    "        # Print selection results\n",
    "        print(f\"{'Strategy':<15} {'Composite Score':<15} {'Avg RMSE':<10} {'Avg MASE':<10} {'Avg Theil_U1':<12} {'Avg Theil_U2':<12} {'DSGE':<6}\")\n",
    "        print(\"-\" * 85)\n",
    "        \n",
    "        for strategy_name in sorted(strategy_scores.keys(), key=lambda x: strategy_scores[x], reverse=True):\n",
    "            score = strategy_scores[strategy_name]\n",
    "            rmse = detailed_scores[strategy_name]['avg_var_rmse']\n",
    "            mase = detailed_scores[strategy_name]['avg_mase']\n",
    "            theil_u1 = detailed_scores[strategy_name]['avg_theil_u1']\n",
    "            theil_u2 = detailed_scores[strategy_name]['avg_theil_u2']\n",
    "            dsge = \"Yes\" if detailed_scores[strategy_name]['dsge_informed'] else \"No\"\n",
    "            \n",
    "            print(f\"{strategy_name:<15} {score:<15.4f} {rmse:<10.4f} {mase:<10.4f} {theil_u1:<12.4f} {theil_u2:<12.4f} {dsge:<6}\")\n",
    "        \n",
    "        # Select best strategy\n",
    "        best_strategy = max(strategy_scores.keys(), key=lambda x: strategy_scores[x])\n",
    "        best_score = strategy_scores[best_strategy]\n",
    "        \n",
    "        print(f\"\\nSelected Best Strategy: {best_strategy} (Score: {best_score:.4f})\")\n",
    "        \n",
    "        return best_strategy, strategy_scores\n",
    "\n",
    "    def print_five_strategies_results(self):\n",
    "        \"\"\"Print comprehensive results for the five theta strategies\"\"\"\n",
    "        if not hasattr(self, 'method_results') or not self.method_results:\n",
    "            print(\"No results available\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(\"FIVE THETA STRATEGIES COMPARISON RESULTS\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        # Summary table\n",
    "        print(f\"\\n{'Strategy':<15} {'Avg R¬≤':<8} {'CV RMSE':<10} {'CV MAE':<10} {'CV MAPE':<10} {'DSGE':<6} {'Loadings':<9}\")\n",
    "        print(\"-\" * 75)\n",
    "        \n",
    "        for strategy_name, results in self.method_results.items():\n",
    "            avg_r2 = np.mean(list(results['variable_r2'].values()))\n",
    "            cv_metrics = results['cv_metrics']\n",
    "            dsge_flag = \"Yes\" if results.get('dsge_informed', False) else \"No\"\n",
    "            loadings_flag = \"Original\" if results.get('preserved_loadings', False) else \"Re-est\"\n",
    "            \n",
    "            print(f\"{strategy_name:<15} {avg_r2:<8.3f} {cv_metrics['RMSE']:<10.4f} \"\n",
    "                f\"{cv_metrics['MAE']:<10.4f} {cv_metrics['MAPE']:<10.2f} \"\n",
    "                f\"{dsge_flag:<6} {loadings_flag:<9}\")\n",
    "        \n",
    "        # DSGE-specific information\n",
    "        if self.dsge_priors is not None:\n",
    "            print(f\"\\n\\n{'='*80}\")\n",
    "            print(\"DSGE PRIOR INTEGRATION SUMMARY\")\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            dsge_params = {k: v['mean'] for k, v in self.dsge_priors.items()}\n",
    "            if dsge_params:\n",
    "                print(\"DSGE Parameters Used:\")\n",
    "                for param, value in dsge_params.items():\n",
    "                    print(f\"  {param}: {value:.3f}\")\n",
    "            \n",
    "            print(f\"\\nStructural Consistency:\")\n",
    "            print(f\"  ‚Ä¢ Original factor loadings preserved: YES\")\n",
    "            print(f\"  ‚Ä¢ VAR priors adapted to theta transformations: YES\") \n",
    "            print(f\"  ‚Ä¢ Economic interpretation maintained: YES\")\n",
    "            print(f\"  ‚Ä¢ DSGE constraints applied to theta parameters: YES\")\n",
    "        \n",
    "        # Best strategy detailed results\n",
    "        if self.theta_strategy:\n",
    "            best_results = self.method_results[self.theta_strategy]\n",
    "            print(f\"\\n\\nDETAILED RESULTS FOR BEST STRATEGY: {self.theta_strategy}\")\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            print(\"\\nVariable Fit (using original DSGE-informed loadings):\")\n",
    "            print(\"-\"*60)\n",
    "            print(f\"{'Variable':<15} {'R¬≤':<8} {'Factor_1':<12} {'Factor_2':<12} {'Factor_3':<12}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            original_loadings = self.loadings\n",
    "            for var_name in original_loadings.index:\n",
    "                r2 = best_results['variable_r2'].get(var_name, 0.0)\n",
    "                print(f\"{var_name:<15} {r2:<8.3f}\", end=\"\")\n",
    "                for j, factor in enumerate(original_loadings.columns):\n",
    "                    if j < 3:\n",
    "                        loading_val = original_loadings.loc[var_name, factor]\n",
    "                        print(f\" {loading_val:<12.3f}\", end=\"\")\n",
    "                print()\n",
    "            \n",
    "            avg_r2_best = np.mean(list(best_results['variable_r2'].values()))\n",
    "            print(f\"\\nAverage R¬≤ (Best Strategy): {avg_r2_best:.3f}\")\n",
    "            \n",
    "            # VAR model comparison\n",
    "            theta_var = best_results['theta_var_model']\n",
    "            base_var = self.base_factor_var\n",
    "            \n",
    "            print(f\"\\nVAR Model Comparison:\")\n",
    "            print(f\"  Base VAR Log-Likelihood: {base_var['log_likelihood']:.2f}\")\n",
    "            print(f\"  Theta VAR Log-Likelihood: {theta_var['log_likelihood']:.2f}\")\n",
    "            print(f\"  Improvement: {theta_var['log_likelihood'] - base_var['log_likelihood']:.2f}\")\n",
    "\n",
    "        # Print variable-level CV results\n",
    "        self.print_variable_cv_results()\n",
    "\n",
    "    def print_variable_cv_results(self):\n",
    "        \"\"\"Print detailed variable-level cross-validation results\"\"\"\n",
    "        if not self.method_results:\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n{'='*120}\")\n",
    "        print(\"DETAILED VARIABLE-LEVEL CROSS-VALIDATION RESULTS\")\n",
    "        print(\"=\"*120)\n",
    "        \n",
    "        for strategy_name, results in self.method_results.items():\n",
    "            if 'variable_cv_metrics' not in results:\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\nStrategy: {strategy_name}\")\n",
    "            print(\"-\" * 115)\n",
    "            print(f\"{'Variable':<15} {'CV RMSE':<8} {'CV MAE':<8} {'CV MAPE':<9} {'CV SMAPE':<10} \"\n",
    "                f\"{'CV Theil_U1':<12} {'CV Theil_U2':<12} {'CV MdAPE':<10} {'CV MASE':<9} {'CV R¬≤':<8}\")\n",
    "            print(\"-\" * 115)\n",
    "            \n",
    "            var_cv_metrics = results['variable_cv_metrics']\n",
    "            for var_name, metrics in var_cv_metrics.items():\n",
    "                print(f\"{var_name:<15} {metrics.get('RMSE', np.nan):<8.4f} {metrics.get('MAE', np.nan):<8.4f} \"\n",
    "                    f\"{metrics.get('MAPE', np.nan):<9.2f} {metrics.get('SMAPE', np.nan):<10.2f} \"\n",
    "                    f\"{metrics.get('Theil_U1', np.nan):<12.4f} {metrics.get('Theil_U2', np.nan):<12.4f} \"\n",
    "                    f\"{metrics.get('MdAPE', np.nan):<10.2f} {metrics.get('MASE', np.nan):<9.4f} \"\n",
    "                    f\"{metrics.get('R2', np.nan):<8.3f}\")\n",
    "\n",
    "    def run_complete_five_strategies_analysis(self, strategy='auto', forecast_horizon=8):\n",
    "        \"\"\"Run complete analysis using the five core theta strategies\"\"\"\n",
    "        print(\"DSGE-INFORMED FIVE THETA STRATEGIES ANALYSIS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        if self.dsge_priors is not None:\n",
    "            print(\"‚úì Using DSGE structural priors for VAR coefficient adaptation\")\n",
    "            print(\"‚úì Preserving original factor loadings throughout\")\n",
    "            print(\"‚úì Maintaining economic interpretation of factors\")\n",
    "        else:\n",
    "            print(\"! No DSGE priors available - using econometric constraints only\")\n",
    "\n",
    "        # Step 1: Run five strategies comparison\n",
    "        if strategy == 'auto':\n",
    "            all_results = self.run_five_theta_strategies_comparison(forecast_horizon)\n",
    "            if not all_results:\n",
    "                print(\"No successful strategies found, analysis cannot continue\")\n",
    "                return None\n",
    "                \n",
    "            # Store results\n",
    "            self.method_results = all_results\n",
    "\n",
    "            # Select best strategy\n",
    "            best_strategy, strategy_scores = self.select_best_strategy(all_results)\n",
    "\n",
    "            # Set the selected strategy attributes\n",
    "            self.theta_strategy = best_strategy\n",
    "            if best_strategy in all_results:\n",
    "                self.optimal_theta = all_results[best_strategy]['theta_params']\n",
    "                \n",
    "        else:\n",
    "            # Run specific strategy\n",
    "            strategy_map = {\n",
    "                'frequency_dual': self.frequency_dual_theta_strategy,\n",
    "                'lagged': self.lagged_theta_strategy,\n",
    "                'sequential': self.sequential_theta_strategy,\n",
    "                'constrained': self.constrained_theta_strategy,\n",
    "                'global': self.global_theta_strategy,\n",
    "            }\n",
    "            \n",
    "            if strategy in strategy_map:\n",
    "                strategy_func = strategy_map[strategy]\n",
    "                theta_params, theta_func = strategy_func()\n",
    "                results = self.evaluate_theta_method(strategy.upper(), theta_params, theta_func, forecast_horizon)\n",
    "                self.method_results = {strategy.upper(): results}\n",
    "                self.theta_strategy = strategy.upper()\n",
    "                self.optimal_theta = theta_params\n",
    "            else:\n",
    "                print(f\"Unknown strategy: {strategy}\")\n",
    "                return None\n",
    "\n",
    "        # Step 2: Print comprehensive results\n",
    "        self.print_five_strategies_results()\n",
    "\n",
    "        # Step 3: Generate enhanced forecasts\n",
    "        if self.theta_strategy and self.theta_strategy in self.method_results:\n",
    "            best_results = self.method_results[self.theta_strategy]\n",
    "            \n",
    "            print(f\"\\n\\nDSGE-INFORMED FORECAST SUMMARY ({forecast_horizon} periods ahead):\")\n",
    "            print(\"=\"*90)\n",
    "            \n",
    "            forecasts_df = best_results['forecasts']\n",
    "            \n",
    "            print(f\"\\n{'Variable':<20} {'Latest Forecast':<15} {'CV RMSE':<10} {'Original R¬≤':<12}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            for var in forecasts_df.columns:\n",
    "                latest_forecast = forecasts_df[var].iloc[-1]\n",
    "                cv_rmse = best_results['cv_metrics'].get('RMSE', np.nan)\n",
    "                fit_r2 = best_results['variable_r2'].get(var, 0.0)\n",
    "                \n",
    "                print(f\"{var:<20} {latest_forecast:>14.2f} {cv_rmse:>9.4f} {fit_r2:>11.3f}\")\n",
    "\n",
    "        print(\"\\nFIVE THETA STRATEGIES ANALYSIS COMPLETE\")\n",
    "        print(\"Strategies implemented:\")\n",
    "        print(\"‚Ä¢ FREQUENCY_DUAL: Multi-frequency decomposition with trend/cyclical/high-freq weights\")\n",
    "        print(\"‚Ä¢ LAGGED: Multi-lag factor transformation with current/lag-1/lag-2 weights\")\n",
    "        print(\"‚Ä¢ SEQUENTIAL: Factor-by-factor sequential optimization with convergence\")\n",
    "        print(\"‚Ä¢ CONSTRAINED: DSGE-constrained optimization with economic theory penalties\")\n",
    "        print(\"‚Ä¢ GLOBAL: Multi-algorithm global optimization with ensemble metrics\")\n",
    "\n",
    "        return {\n",
    "            'strategy_used': self.theta_strategy,\n",
    "            'optimal_theta': self.optimal_theta,\n",
    "            'method_results': self.method_results,\n",
    "            'best_strategy_results': self.method_results.get(self.theta_strategy, {}),\n",
    "            'forecasts': self.method_results.get(self.theta_strategy, {}).get('forecasts', None),\n",
    "            'preserved_structure': True,\n",
    "            'dsge_informed': self.dsge_priors is not None\n",
    "        }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CONVENIENCE FUNCTIONS FOR FIVE THETA STRATEGIES\n",
    "# ============================================================================\n",
    "\n",
    "def enhance_dsge_dfm_with_five_theta_strategies(existing_dsge_dfm_model, strategy='auto', forecast_horizon=8):\n",
    "    \"\"\"\n",
    "    Enhance existing DSGE-informed DFM with the five core theta strategies\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    existing_dsge_dfm_model : EconometricDFM\n",
    "        Fitted DSGE-informed DFM model with Bayesian VAR and DSGE posterior estimates\n",
    "    strategy : str\n",
    "        'auto' - compare all five strategies and pick best\n",
    "        Or specific: 'frequency_dual', 'lagged', 'sequential', 'constrained', 'global'\n",
    "    forecast_horizon : int\n",
    "        Number of quarters to forecast\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    enhanced_dfm : DSGEInformedEnhancedDFMTheta\n",
    "        DSGE-consistent theta-enhanced model\n",
    "    results : dict\n",
    "        Dictionary with all results preserving DSGE structure\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ENHANCING DSGE-INFORMED DFM WITH FIVE THETA STRATEGIES\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create DSGE-informed enhanced model\n",
    "    enhanced_dfm = DSGEInformedEnhancedDFMTheta(existing_dsge_dfm_model)\n",
    "    \n",
    "    if enhanced_dfm.dsge_priors is not None:\n",
    "        print(\"‚úì DSGE priors successfully extracted - will be preserved throughout theta optimization\")\n",
    "        print(f\"  Available DSGE parameters: {list(enhanced_dfm.dsge_priors.keys())}\")\n",
    "    else:\n",
    "        print(\"! No DSGE priors found - using econometric constraints only\")\n",
    "    \n",
    "    # Run complete analysis with the five strategies\n",
    "    results = enhanced_dfm.run_complete_five_strategies_analysis(strategy, forecast_horizon)\n",
    "    \n",
    "    return enhanced_dfm, results\n",
    "\n",
    "\n",
    "def compare_five_theta_strategies(existing_dsge_dfm_model):\n",
    "    \"\"\"\n",
    "    Run comprehensive comparison of the five theta strategies\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    existing_dsge_dfm_model : EconometricDFM\n",
    "        Fitted DSGE-informed DFM model\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    enhanced_dfm : DSGEInformedEnhancedDFMTheta\n",
    "        Enhanced model object\n",
    "    comparison_results : dict\n",
    "        Comprehensive results with DSGE consistency metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    enhanced_dfm = DSGEInformedEnhancedDFMTheta(existing_dsge_dfm_model)\n",
    "    \n",
    "    # Run strategies comparison\n",
    "    all_results = enhanced_dfm.run_five_theta_strategies_comparison()\n",
    "    enhanced_dfm.method_results = all_results\n",
    "    \n",
    "    enhanced_dfm.print_five_strategies_results()\n",
    "    \n",
    "    return enhanced_dfm, all_results\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXAMPLE USAGE WITH FIVE THETA STRATEGIES\n",
    "# ============================================================================\n",
    "\n",
    "def example_five_theta_strategies_usage():\n",
    "    \"\"\"Complete example showing the five theta strategies\"\"\"\n",
    "    print(\"FIVE THETA STRATEGIES EXAMPLE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"\\nThe Five Core Theta Strategies:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"\\n1. FREQUENCY_DUAL:\")\n",
    "    print(\"   ‚Ä¢ Decomposes factors into trend, cyclical, and high-frequency components\")\n",
    "    print(\"   ‚Ä¢ Optimizes weights: F_theta = Œ∏1*trend + Œ∏2*cyclical + Œ∏3*high_freq\")\n",
    "    print(\"   ‚Ä¢ Best for: Capturing multiple time scales in economic data\")\n",
    "    \n",
    "    print(\"\\n2. LAGGED:\")\n",
    "    print(\"   ‚Ä¢ Uses multi-lag structure with current and lagged factor values\")\n",
    "    print(\"   ‚Ä¢ Optimizes weights: F_theta[t] = Œ∏1*F[t] + Œ∏2*F[t-1] + Œ∏3*F[t-2]\")\n",
    "    print(\"   ‚Ä¢ Best for: Modeling temporal dependencies and persistence\")\n",
    "    \n",
    "    print(\"\\n3. SEQUENTIAL:\")\n",
    "    print(\"   ‚Ä¢ Factor-by-factor optimization with convergence checking\")\n",
    "    print(\"   ‚Ä¢ Iteratively optimizes each factor while holding others fixed\")\n",
    "    print(\"   ‚Ä¢ Best for: Handling factor interdependencies systematically\")\n",
    "    \n",
    "    print(\"\\n4. CONSTRAINED:\")\n",
    "    print(\"   ‚Ä¢ Incorporates DSGE structural constraints and economic theory\")\n",
    "    print(\"   ‚Ä¢ Penalizes violations of economic relationships\")\n",
    "    print(\"   ‚Ä¢ Best for: Maintaining theoretical consistency with DSGE models\")\n",
    "    \n",
    "    print(\"\\n5. GLOBAL:\")\n",
    "    print(\"   ‚Ä¢ Multi-algorithm global optimization with ensemble metrics\")\n",
    "    print(\"   ‚Ä¢ Uses differential evolution, basin hopping, dual annealing\")\n",
    "    print(\"   ‚Ä¢ Best for: Finding global optimum across complex parameter space\")\n",
    "    \n",
    "    print(\"\\nUsage Examples:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"\\n# Compare all five strategies and select best:\")\n",
    "    print(\"enhanced_dfm, results = enhance_dsge_dfm_with_five_theta_strategies(\")\n",
    "    print(\"    existing_dsge_dfm_model, strategy='auto')\")\n",
    "    \n",
    "    print(\"\\n# Use specific strategy:\")\n",
    "    print(\"enhanced_dfm, results = enhance_dsge_dfm_with_five_theta_strategies(\")\n",
    "    print(\"    existing_dsge_dfm_model, strategy='constrained')\")\n",
    "    \n",
    "    print(\"\\n# Compare all strategies without selection:\")\n",
    "    print(\"enhanced_dfm, results = compare_five_theta_strategies(existing_dsge_dfm_model)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    example_five_theta_strategies_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENHANCING DSGE-INFORMED DFM WITH FIVE THETA STRATEGIES\n",
      "============================================================\n",
      "DSGE-Informed Enhanced DFM-Theta initialized:\n",
      "  Factors: 3, Variables: 12\n",
      "  DSGE priors: Available\n",
      "  Base VAR estimation: Bayesian\n",
      "‚úì DSGE priors successfully extracted - will be preserved throughout theta optimization\n",
      "  Available DSGE parameters: ['sigma', 'theta', 'phi_pi', 'phi_y', 'rho_a', 'sigma_a', 'rho_v', 'sigma_v', 'rho_d', 'sigma_d', 'rho_s', 'sigma_s']\n",
      "DSGE-INFORMED FIVE THETA STRATEGIES ANALYSIS\n",
      "================================================================================\n",
      "‚úì Using DSGE structural priors for VAR coefficient adaptation\n",
      "‚úì Preserving original factor loadings throughout\n",
      "‚úì Maintaining economic interpretation of factors\n",
      "\n",
      "====================================================================================================\n",
      "FIVE CORE THETA STRATEGIES COMPARISON\n",
      "====================================================================================================\n",
      "Using Bayesian VAR with DSGE structure preservation\n",
      "\n",
      "--- FREQUENCY_DUAL Strategy ---\n",
      "FREQUENCY_DUAL Strategy: Optimizing dual frequency decomposition with robustness...\n",
      "Evaluating FREQUENCY_DUAL with DSGE consistency...\n",
      "Average R¬≤: 0.664\n",
      "CV RMSE: 0.6443\n",
      "DSGE-Informed: Yes\n",
      "Original Loadings Preserved: True\n",
      "\n",
      "--- LAGGED Strategy ---\n",
      "LAGGED Strategy: Optimizing with multi-lag factor transformation...\n",
      "Evaluating LAGGED with DSGE consistency...\n",
      "Average R¬≤: 0.710\n",
      "CV RMSE: 0.6527\n",
      "DSGE-Informed: Yes\n",
      "Original Loadings Preserved: True\n",
      "\n",
      "--- SEQUENTIAL Strategy ---\n",
      "SEQUENTIAL Strategy: Factor-by-factor sequential optimization...\n",
      "Sequential optimization converged after 2 iterations\n",
      "Evaluating SEQUENTIAL with DSGE consistency...\n",
      "Average R¬≤: 0.710\n",
      "CV RMSE: 0.6527\n",
      "DSGE-Informed: Yes\n",
      "Original Loadings Preserved: True\n",
      "\n",
      "--- CONSTRAINED Strategy ---\n",
      "CONSTRAINED Strategy: DSGE-constrained theta optimization...\n",
      "Evaluating CONSTRAINED with DSGE consistency...\n",
      "Average R¬≤: 0.573\n",
      "CV RMSE: 0.7869\n",
      "DSGE-Informed: Yes\n",
      "Original Loadings Preserved: True\n",
      "\n",
      "--- GLOBAL Strategy ---\n",
      "GLOBAL Strategy: Multi-algorithm global optimization...\n",
      "  Trying differential_evolution...\n",
      "  differential_evolution succeeded with objective: 0.2904\n",
      "  Trying basinhopping...\n",
      "  basinhopping succeeded with objective: 0.2904\n",
      "  Trying dual_annealing...\n",
      "Evaluating GLOBAL with DSGE consistency...\n",
      "Average R¬≤: 0.708\n",
      "CV RMSE: 0.6393\n",
      "DSGE-Informed: Yes\n",
      "Original Loadings Preserved: True\n",
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE STRATEGY SELECTION\n",
      "================================================================================\n",
      "Strategy        Composite Score Avg RMSE   Avg MASE   Avg Theil_U1 Avg Theil_U2 DSGE  \n",
      "-------------------------------------------------------------------------------------\n",
      "GLOBAL          1.0000          0.5526     1.9658     0.5243       2.5318       Yes   \n",
      "LAGGED          0.8267          0.5739     2.0277     0.5418       2.7016       Yes   \n",
      "SEQUENTIAL      0.8267          0.5739     2.0277     0.5418       2.7016       Yes   \n",
      "FREQUENCY_DUAL  0.8186          0.5800     2.0068     0.5374       2.7482       Yes   \n",
      "CONSTRAINED     0.0500          0.6588     2.3855     0.6309       3.3144       Yes   \n",
      "\n",
      "Selected Best Strategy: GLOBAL (Score: 1.0000)\n",
      "\n",
      "====================================================================================================\n",
      "FIVE THETA STRATEGIES COMPARISON RESULTS\n",
      "====================================================================================================\n",
      "\n",
      "Strategy        Avg R¬≤   CV RMSE    CV MAE     CV MAPE    DSGE   Loadings \n",
      "---------------------------------------------------------------------------\n",
      "FREQUENCY_DUAL  0.664    0.6443     0.5275     289.83     Yes    Original \n",
      "LAGGED          0.710    0.6527     0.5220     254.58     Yes    Original \n",
      "SEQUENTIAL      0.710    0.6527     0.5220     254.58     Yes    Original \n",
      "CONSTRAINED     0.573    0.7869     0.6122     182.89     Yes    Original \n",
      "GLOBAL          0.708    0.6393     0.4984     223.78     Yes    Original \n",
      "\n",
      "\n",
      "================================================================================\n",
      "DSGE PRIOR INTEGRATION SUMMARY\n",
      "================================================================================\n",
      "DSGE Parameters Used:\n",
      "  sigma: 1.356\n",
      "  theta: 0.208\n",
      "  phi_pi: 2.772\n",
      "  phi_y: 0.321\n",
      "  rho_a: 0.201\n",
      "  sigma_a: 0.601\n",
      "  rho_v: 0.554\n",
      "  sigma_v: 0.176\n",
      "  rho_d: 0.746\n",
      "  sigma_d: 0.191\n",
      "  rho_s: 0.510\n",
      "  sigma_s: 0.103\n",
      "\n",
      "Structural Consistency:\n",
      "  ‚Ä¢ Original factor loadings preserved: YES\n",
      "  ‚Ä¢ VAR priors adapted to theta transformations: YES\n",
      "  ‚Ä¢ Economic interpretation maintained: YES\n",
      "  ‚Ä¢ DSGE constraints applied to theta parameters: YES\n",
      "\n",
      "\n",
      "DETAILED RESULTS FOR BEST STRATEGY: GLOBAL\n",
      "================================================================================\n",
      "\n",
      "Variable Fit (using original DSGE-informed loadings):\n",
      "------------------------------------------------------------\n",
      "Variable        R¬≤       Factor_1     Factor_2     Factor_3    \n",
      "------------------------------------------------------------\n",
      "GDPC1           0.755    0.220        -0.370       -0.299      \n",
      "PAYEMS          0.873    0.304        -0.381       -0.253      \n",
      "INDPRO          0.579    0.193        -0.335       -0.269      \n",
      "ICSA            0.577    0.373        -0.065       -0.162      \n",
      "CPIAUCSL        0.882    0.380        -0.053       0.397       \n",
      "PCEPI           0.897    0.389        -0.069       0.389       \n",
      "AHETPI          0.699    0.194        0.043        0.501       \n",
      "DCOILWTICO      0.284    0.183        -0.212       0.150       \n",
      "FEDFUNDS        0.694    0.336        0.334        0.002       \n",
      "DGS10           0.880    0.289        0.429        -0.200      \n",
      "M2SL            0.578    -0.312       -0.186       0.244       \n",
      "AAA             0.799    0.148        0.465        -0.257      \n",
      "\n",
      "Average R¬≤ (Best Strategy): 0.708\n",
      "\n",
      "VAR Model Comparison:\n",
      "  Base VAR Log-Likelihood: -328.56\n",
      "  Theta VAR Log-Likelihood: -323.35\n",
      "  Improvement: 5.21\n",
      "\n",
      "========================================================================================================================\n",
      "DETAILED VARIABLE-LEVEL CROSS-VALIDATION RESULTS\n",
      "========================================================================================================================\n",
      "\n",
      "Strategy: FREQUENCY_DUAL\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Variable        CV RMSE  CV MAE   CV MAPE   CV SMAPE   CV Theil_U1  CV Theil_U2  CV MdAPE   CV MASE   CV R¬≤   \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "GDPC1           0.3688   0.3310   212.87    165.87     0.7895       1.2432       201.53     0.5020    -1.874  \n",
      "PAYEMS          0.2925   0.2823   176.19    200.00     0.9781       3.3348       154.42     0.6680    -18.283 \n",
      "INDPRO          0.4728   0.4281   448.04    147.75     0.7321       0.9425       118.41     0.5479    -0.196  \n",
      "ICSA            0.6594   0.6450   58.60     84.48      0.4267       12.5802      59.04      2.6846    -222.722\n",
      "CPIAUCSL        0.6646   0.5695   132.02    73.02      0.3856       1.2071       100.97     1.4617    -2.962  \n",
      "PCEPI           0.5904   0.5355   105.00    58.24      0.3082       1.1800       56.85      1.5671    -1.430  \n",
      "AHETPI          0.6587   0.6439   54.81     77.85      0.3885       2.9048       55.51      2.8170    -15.867 \n",
      "DCOILWTICO      0.5410   0.4841   80.82     134.77     0.7187       1.4007       80.71      1.3877    -5.639  \n",
      "FEDFUNDS        0.9236   0.8789   96.39     78.14      0.3851       3.6340       66.54      6.4236    -82.314 \n",
      "DGS10           0.3965   0.2901   91.75     43.15      0.2806       1.0277       31.92      0.9074    -1.236  \n",
      "M2SL            0.8613   0.7757   69.34     75.20      0.4121       1.3591       54.56      3.1690    -4.258  \n",
      "AAA             0.5299   0.4662   1952.20   131.77     0.6430       2.1640       276.62     1.9462    -9.901  \n",
      "\n",
      "Strategy: LAGGED\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Variable        CV RMSE  CV MAE   CV MAPE   CV SMAPE   CV Theil_U1  CV Theil_U2  CV MdAPE   CV MASE   CV R¬≤   \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "GDPC1           0.3318   0.3046   177.97    173.32     0.8312       1.1172       177.48     0.4616    -1.276  \n",
      "PAYEMS          0.2354   0.2248   159.58    177.50     0.8462       2.7240       135.84     0.5335    -11.607 \n",
      "INDPRO          0.4542   0.4032   230.36    154.44     0.7745       0.9076       114.14     0.5158    -0.110  \n",
      "ICSA            0.6561   0.6393   58.43     84.98      0.4295       12.2130      59.58      2.6677    -208.729\n",
      "CPIAUCSL        0.6020   0.4984   86.44     69.13      0.3366       0.9503       55.12      1.2816    -1.504  \n",
      "PCEPI           0.5554   0.4934   78.98     63.52      0.3049       1.0188       47.64      1.4446    -0.907  \n",
      "AHETPI          0.7556   0.7351   65.88     104.54     0.5075       3.5331       65.39      3.2124    -24.208 \n",
      "DCOILWTICO      0.5569   0.4957   84.23     139.17     0.7349       1.4672       85.74      1.4217    -6.394  \n",
      "FEDFUNDS        0.9754   0.9315   98.24     84.25      0.4114       3.9910       70.14      6.7664    -100.575\n",
      "DGS10           0.3923   0.3038   91.69     46.09      0.2792       1.0333       40.84      0.9494    -1.187  \n",
      "M2SL            0.8677   0.7902   74.58     77.23      0.4147       1.4088       56.79      3.2213    -4.547  \n",
      "AAA             0.5047   0.4446   1848.56   129.95     0.6312       2.0545       289.74     1.8569    -9.126  \n",
      "\n",
      "Strategy: SEQUENTIAL\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Variable        CV RMSE  CV MAE   CV MAPE   CV SMAPE   CV Theil_U1  CV Theil_U2  CV MdAPE   CV MASE   CV R¬≤   \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "GDPC1           0.3318   0.3046   177.97    173.32     0.8312       1.1172       177.48     0.4616    -1.276  \n",
      "PAYEMS          0.2354   0.2248   159.58    177.50     0.8462       2.7240       135.84     0.5335    -11.607 \n",
      "INDPRO          0.4542   0.4032   230.36    154.44     0.7745       0.9076       114.14     0.5158    -0.110  \n",
      "ICSA            0.6561   0.6393   58.43     84.98      0.4295       12.2130      59.58      2.6677    -208.730\n",
      "CPIAUCSL        0.6020   0.4984   86.44     69.13      0.3366       0.9503       55.12      1.2816    -1.504  \n",
      "PCEPI           0.5554   0.4934   78.98     63.52      0.3049       1.0188       47.64      1.4446    -0.907  \n",
      "AHETPI          0.7556   0.7351   65.88     104.54     0.5075       3.5331       65.39      3.2124    -24.208 \n",
      "DCOILWTICO      0.5569   0.4957   84.23     139.17     0.7349       1.4672       85.74      1.4217    -6.394  \n",
      "FEDFUNDS        0.9754   0.9315   98.24     84.25      0.4114       3.9910       70.14      6.7664    -100.575\n",
      "DGS10           0.3923   0.3038   91.69     46.09      0.2792       1.0333       40.84      0.9494    -1.187  \n",
      "M2SL            0.8677   0.7902   74.58     77.23      0.4147       1.4088       56.79      3.2213    -4.547  \n",
      "AAA             0.5047   0.4446   1848.56   129.95     0.6312       2.0544       289.74     1.8569    -9.126  \n",
      "\n",
      "Strategy: CONSTRAINED\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Variable        CV RMSE  CV MAE   CV MAPE   CV SMAPE   CV Theil_U1  CV Theil_U2  CV MdAPE   CV MASE   CV R¬≤   \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "GDPC1           0.3726   0.3325   199.80    169.46     0.8405       1.2080       209.24     0.5023    -1.910  \n",
      "PAYEMS          0.3252   0.3164   173.30    200.00     0.9682       3.6635       160.38     0.7466    -23.262 \n",
      "INDPRO          0.4622   0.4196   345.73    152.72     0.7568       0.9169       122.51     0.5370    -0.120  \n",
      "ICSA            0.9115   0.9044   82.52     141.50     0.7061       17.0729      83.61      3.7637    -406.584\n",
      "CPIAUCSL        0.6906   0.6150   87.59     75.83      0.3773       0.9044       77.91      1.5840    -1.239  \n",
      "PCEPI           0.6946   0.6246   67.98     62.15      0.3595       1.1373       38.42      1.8307    -1.588  \n",
      "AHETPI          0.8215   0.7945   66.69     103.02     0.5278       3.5029       65.92      3.4758    -23.167 \n",
      "DCOILWTICO      0.5538   0.4999   81.59     141.95     0.7524       1.3986       80.58      1.4327    -5.357  \n",
      "FEDFUNDS        1.1851   1.1540   92.60     118.38     0.5818       5.4766       72.36      8.2728    -205.757\n",
      "DGS10           0.4709   0.4046   70.88     75.74      0.4278       1.4254       53.95      1.2589    -2.743  \n",
      "M2SL            1.1623   1.0667   77.50     128.21     0.6975       2.0082       80.10      4.3259    -10.037 \n",
      "AAA             0.2548   0.2146   848.47    123.17     0.5752       1.0585       113.85     0.8958    -1.459  \n",
      "\n",
      "Strategy: GLOBAL\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Variable        CV RMSE  CV MAE   CV MAPE   CV SMAPE   CV Theil_U1  CV Theil_U2  CV MdAPE   CV MASE   CV R¬≤   \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "GDPC1           0.2878   0.2538   132.76    177.54     0.8823       0.9624       138.69     0.3849    -0.650  \n",
      "PAYEMS          0.1600   0.1434   81.18     118.37     0.6067       1.8486       74.83      0.3397    -4.629  \n",
      "INDPRO          0.4451   0.3936   155.47    170.48     0.8514       0.8883       107.71     0.5033    -0.057  \n",
      "ICSA            0.6179   0.6008   54.95     78.22      0.3969       11.5055      55.93      2.5084    -186.346\n",
      "CPIAUCSL        0.6071   0.4934   96.93     65.52      0.3451       0.9960       67.23      1.2683    -1.683  \n",
      "PCEPI           0.5454   0.4779   81.22     52.85      0.2894       1.0120       43.88      1.3995    -0.894  \n",
      "AHETPI          0.7468   0.7251   64.11     100.05     0.4901       3.4209       63.74      3.1692    -22.475 \n",
      "DCOILWTICO      0.5174   0.4485   75.24     128.73     0.6915       1.3619       75.91      1.2865    -5.361  \n",
      "FEDFUNDS        0.9906   0.9490   98.44     86.38      0.4218       4.0816       70.43      6.8872    -105.422\n",
      "DGS10           0.3862   0.3053   88.65     46.69      0.2820       1.0319       37.41      0.9535    -1.132  \n",
      "M2SL            0.8745   0.7969   75.86     78.23      0.4197       1.4296       57.53      3.2471    -4.676  \n",
      "AAA             0.4530   0.3930   1680.53   127.35     0.6151       1.8425       242.45     1.6416    -7.289  \n",
      "\n",
      "\n",
      "DSGE-INFORMED FORECAST SUMMARY (8 periods ahead):\n",
      "==========================================================================================\n",
      "\n",
      "Variable             Latest Forecast CV RMSE    Original R¬≤ \n",
      "------------------------------------------------------------\n",
      "GDPC1                          1.99    0.6393       0.755\n",
      "PAYEMS                         0.68    0.6393       0.873\n",
      "INDPRO                         0.37    0.6393       0.579\n",
      "ICSA                         -12.69    0.6393       0.577\n",
      "CPIAUCSL                       2.47    0.6393       0.882\n",
      "PCEPI                          2.11    0.6393       0.897\n",
      "AHETPI                         3.17    0.6393       0.699\n",
      "DCOILWTICO                     4.06    0.6393       0.284\n",
      "FEDFUNDS                       2.17    0.6393       0.694\n",
      "DGS10                          3.52    0.6393       0.880\n",
      "M2SL                           5.39    0.6393       0.578\n",
      "AAA                            4.98    0.6393       0.799\n",
      "\n",
      "FIVE THETA STRATEGIES ANALYSIS COMPLETE\n",
      "Strategies implemented:\n",
      "‚Ä¢ FREQUENCY_DUAL: Multi-frequency decomposition with trend/cyclical/high-freq weights\n",
      "‚Ä¢ LAGGED: Multi-lag factor transformation with current/lag-1/lag-2 weights\n",
      "‚Ä¢ SEQUENTIAL: Factor-by-factor sequential optimization with convergence\n",
      "‚Ä¢ CONSTRAINED: DSGE-constrained optimization with economic theory penalties\n",
      "‚Ä¢ GLOBAL: Multi-algorithm global optimization with ensemble metrics\n"
     ]
    }
   ],
   "source": [
    "enhanced_dfm, results = enhance_dsge_dfm_with_five_theta_strategies(model, strategy='auto')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
